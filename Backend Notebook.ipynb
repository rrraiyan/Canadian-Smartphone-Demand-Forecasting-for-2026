{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48234db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# ENVIRONMENT SETUP\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import yfinance as yf\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Ridge  # used for robust multiplier\n",
    "from sklearn.metrics import mean_absolute_percentage_error  # used for error checking\n",
    "from pytrends.request import TrendReq\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pickle\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from io import StringIO\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "CONF = {\n",
    "    # Regex to capture both old (8517.12) and new (8517.13) smartphone codes\n",
    "    'HS_CODE_REGEX': r'8517\\.12|8517\\.13', \n",
    "    'TARGET_BRANDS': ['Apple', 'Samsung', 'Google', 'Motorola'],\n",
    "    'FORECAST_YEAR': 2026,\n",
    "    'LAG_MONTHS': 1, # Supply Chain Lag: Imports(t) -> Sales(t+1)\n",
    "    'MARKET_SHARE_FILE': 'canada_smartphone_market_share.csv',\n",
    "    'INPUT_PATTERN': 'report*.csv' \n",
    "}\n",
    "\n",
    "print(\"‚úÖ Environment Setup Complete.\")\n",
    "print(f\"   Targeting HS Codes: {CONF['HS_CODE_REGEX']}\")\n",
    "print(f\"   Forecasting Horizon: {CONF['FORECAST_YEAR']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# DATA INGESTION & AGGREGATION\n",
    "# ==========================================\n",
    "\n",
    "def load_and_aggregate_trade_data(file_pattern: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads multiple StatCan CSVs, filters for Smartphones, and aggregates to monthly totals.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"DATA INGESTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Find Files\n",
    "    files = sorted(glob.glob(file_pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"‚ùå No files found matching '{file_pattern}'\")\n",
    "    \n",
    "    print(f\"üìÇ Found {len(files)} files. Processing...\")\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for f in files:\n",
    "        try:\n",
    "            with open(f, 'r') as file_obj:\n",
    "                lines = [file_obj.readline() for _ in range(5)]\n",
    "            \n",
    "            header_row = 0\n",
    "            for i, line in enumerate(lines):\n",
    "                if 'Commodity' in line:\n",
    "                    header_row = i\n",
    "                    break\n",
    "            \n",
    "            # Load with correct header\n",
    "            temp = pd.read_csv(f, header=header_row)\n",
    "            \n",
    "            # 2. Filter for Smartphones (HS Codes)\n",
    "            if 'Commodity' in temp.columns:\n",
    "                mask = temp['Commodity'].astype(str).str.contains(CONF['HS_CODE_REGEX'], na=False, regex=True)\n",
    "                temp = temp[mask]\n",
    "            \n",
    "            # 3. Clean Numeric Columns (Remove commas)\n",
    "            for col in ['Value ($)', 'Quantity']:\n",
    "                if col in temp.columns and temp[col].dtype == object:\n",
    "                    temp[col] = temp[col].astype(str).str.replace(',', '').astype(float)\n",
    "            \n",
    "            # 4. Standardize Date\n",
    "            if 'Period' in temp.columns:\n",
    "                temp['Period'] = pd.to_datetime(temp['Period'])\n",
    "                \n",
    "            df_list.append(temp)\n",
    "            # print(f\"   ‚úì Loaded {os.path.basename(f)} ({len(temp)} rows)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error reading {os.path.basename(f)}: {e}\")\n",
    "\n",
    "    if not df_list:\n",
    "        raise ValueError(\"‚ùå No valid smartphone data extracted from files.\")\n",
    "\n",
    "    # 5. Concatenate\n",
    "    df_raw = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # 6. Aggregate to Monthly Level \n",
    "    df_monthly = df_raw.groupby('Period').agg({\n",
    "        'Value ($)': 'sum',\n",
    "        'Quantity': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename for clarity\n",
    "    df_monthly.rename(columns={\n",
    "        'Period': 'month', \n",
    "        'Value ($)': 'import_value_cad', \n",
    "        'Quantity': 'import_units'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    df_monthly = df_monthly.sort_values('month').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Aggregation Complete.\")\n",
    "    print(f\"   Total Months: {len(df_monthly)}\")\n",
    "    print(f\"   Date Range: {df_monthly['month'].min().date()} to {df_monthly['month'].max().date()}\")\n",
    "    print(f\"   Total Units: {df_monthly['import_units'].sum():,.0f}\")\n",
    "    \n",
    "    return df_monthly\n",
    "\n",
    "# Execute\n",
    "df_imports = load_and_aggregate_trade_data(CONF['INPUT_PATTERN'])\n",
    "df_imports.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Supply Chain Lag Detection \n",
    "# ==========================================\n",
    "def determine_optimal_lag(df_imports):\n",
    "    print(\"=\"*60)\n",
    "    print(\"PHASE 1.5: SCIENTIFIC LAG DETECTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    recommended_lag = 1  # Default fallback\n",
    "    \n",
    "    # ==========================================================================\n",
    "    # TEST A: MACRO-ECONOMIC CROSS-CORRELATION (Supply vs. Demand)\n",
    "    # ==========================================================================\n",
    "    print(\"\\n[A] Running Macro-Economic Correlation (Imports vs. Retail Sales)...\")\n",
    "    \n",
    "    url = \"https://www150.statcan.gc.ca/n1/tbl/csv/20100008-eng.zip\"\n",
    "    \n",
    "    try:\n",
    "        print(\"   ‚è≥ Downloading Retail Sales data from Statistics Canada...\")\n",
    "        r = requests.get(url, stream=True, timeout=30)\n",
    "        \n",
    "        with zipfile.ZipFile(io.BytesIO(r.content)) as z:\n",
    "            csv_name = [f for f in z.namelist() if f.endswith('.csv')][0]\n",
    "            \n",
    "            chunks = []\n",
    "            with z.open(csv_name) as f:\n",
    "                for chunk in pd.read_csv(f, chunksize=10000, encoding='utf-8', low_memory=False):\n",
    "                    mask = (\n",
    "                        (chunk['GEO'] == 'Canada') & \n",
    "                        (chunk['North American Industry Classification System (NAICS)'].str.contains('Electronics', na=False)) &\n",
    "                        (chunk['UOM'] == 'Dollars') & \n",
    "                        (chunk['Adjustments'] == 'Unadjusted')\n",
    "                    )\n",
    "                    if mask.any():\n",
    "                        chunks.append(chunk[mask])\n",
    "        \n",
    "        if not chunks:\n",
    "            raise ValueError(\"No electronics sales data found in StatCan file.\")\n",
    "            \n",
    "        df_sales = pd.concat(chunks)\n",
    "        df_sales['month'] = pd.to_datetime(df_sales['REF_DATE'])\n",
    "        df_sales = df_sales.groupby('month')['VALUE'].sum().reset_index()\n",
    "        df_sales.rename(columns={'VALUE': 'retail_sales_cad'}, inplace=True)\n",
    "        \n",
    "        print(f\"   ‚úì Loaded {len(df_sales)} months of Retail Sales data.\")\n",
    "\n",
    "        # Merge with Imports\n",
    "        df_corr = pd.merge(\n",
    "            df_imports[['month', 'import_value_cad']], \n",
    "            df_sales[['month', 'retail_sales_cad']], \n",
    "            on='month', \n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        # Stationarity fix: Use % change\n",
    "        df_corr['imports_pct'] = df_corr['import_value_cad'].pct_change()\n",
    "        df_corr['sales_pct'] = df_corr['retail_sales_cad'].pct_change()\n",
    "        df_corr = df_corr.dropna()\n",
    "        \n",
    "        print(\"\\n   üìä Correlation Analysis (Stationary Data):\")\n",
    "        print(f\"   {'Lag (Months)':<15} | {'Correlation (r)':<20} | {'Strength'}\")\n",
    "        print(\"   \" + \"-\"*50)\n",
    "        \n",
    "        best_r = -1\n",
    "        best_macro_lag = 0\n",
    "        \n",
    "        # Test wide range: 0-6 months\n",
    "        for lag in range(0, 7):\n",
    "            r = df_corr['imports_pct'].corr(df_corr['sales_pct'].shift(-lag))\n",
    "            \n",
    "            if pd.isna(r):\n",
    "                continue\n",
    "            \n",
    "            bar = \"‚ñà\" * int(max(0, r) * 20)\n",
    "            print(f\"   {lag:<15} | {r:.4f}               | {bar}\")\n",
    "            \n",
    "            if r > best_r:\n",
    "                best_r = r\n",
    "                best_macro_lag = lag\n",
    "        \n",
    "        # Statistical significance test\n",
    "        n = len(df_corr)\n",
    "        if best_r > 0 and n > 2:\n",
    "            t_stat = best_r * np.sqrt(n - 2) / np.sqrt(1 - best_r**2)\n",
    "            p_value = 2 * (1 - stats.t.cdf(abs(t_stat), n - 2))\n",
    "            \n",
    "            print(f\"   üèÜ Macro Winner: {best_macro_lag} Months (r={best_r:.4f}, p={p_value:.4f}, n={n})\")\n",
    "            \n",
    "            if p_value > 0.05:\n",
    "                print(f\"   ‚ö†Ô∏è Warning: Correlation not statistically significant\")\n",
    "        else:\n",
    "            print(f\"   üèÜ Macro Winner: {best_macro_lag} Months (r={best_r:.4f})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Macro Analysis Failed: {e}\")\n",
    "        best_macro_lag = None\n",
    "\n",
    "    # ==========================================================================\n",
    "    # TEST B: MICRO-ECONOMIC TURNOVER (Inventory Velocity)\n",
    "    # ==========================================================================\n",
    "    print(\"\\n[B] Running Micro-Economic Analysis (Inventory Turnover)...\")\n",
    "    \n",
    "    tickers = ['BCE.TO', 'RCI-B.TO', 'BBY'] \n",
    "    lags = []\n",
    "    \n",
    "    try:\n",
    "        for t in tickers:\n",
    "            try:\n",
    "                stock = yf.Ticker(t)\n",
    "                bs = stock.balance_sheet\n",
    "                fin = stock.financials\n",
    "                \n",
    "                if bs.empty or fin.empty:\n",
    "                    print(f\"   ‚ö†Ô∏è {t}: No financial data available\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract inventory and COGS\n",
    "                inv = bs.loc['Inventory'].iloc[0] if 'Inventory' in bs.index else None\n",
    "                cogs = fin.loc['Cost Of Revenue'].iloc[0] if 'Cost Of Revenue' in fin.index else None\n",
    "                \n",
    "                # Validate data\n",
    "                if inv is None or cogs is None or pd.isna(inv) or pd.isna(cogs):\n",
    "                    print(f\"   ‚ö†Ô∏è {t}: Missing inventory or COGS data\")\n",
    "                    continue\n",
    "                \n",
    "                if inv <= 0 or cogs <= 0:\n",
    "                    print(f\"   ‚ö†Ô∏è {t}: Invalid inventory or COGS values\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate Days Sales of Inventory (DSI)\n",
    "                dsi = (inv / cogs) * 365\n",
    "                months_inv = dsi / 30\n",
    "                lags.append(months_inv)\n",
    "                print(f\"   ‚úì {t}: {dsi:.0f} Days Inventory (~{months_inv:.1f} months)\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è {t}: Error ({e})\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate average from valid companies\n",
    "        if lags:\n",
    "            valid_lags = [l for l in lags if not np.isnan(l)]\n",
    "            \n",
    "            if valid_lags:\n",
    "                avg_micro_lag = np.mean(valid_lags)\n",
    "                print(f\"   üèÜ Micro Average: {avg_micro_lag:.1f} Months (from {len(valid_lags)}/{len(lags)} companies)\")\n",
    "                best_micro_lag = int(round(avg_micro_lag))\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è All companies returned NaN - Micro analysis unavailable\")\n",
    "                best_micro_lag = None\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è No valid inventory data found\")\n",
    "            best_micro_lag = None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Micro Analysis Failed: {e}\")\n",
    "        best_micro_lag = None\n",
    "\n",
    "    # ==========================================================================\n",
    "    # FINAL VERDICT\n",
    "    # ==========================================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    if best_macro_lag is not None and best_micro_lag is not None:\n",
    "        if best_macro_lag == best_micro_lag:\n",
    "            recommended_lag = best_macro_lag\n",
    "            confidence = \"High (Macro + Micro Agree)\"\n",
    "        else:\n",
    "            # Prioritize macro (real sales data)\n",
    "            recommended_lag = best_macro_lag\n",
    "            confidence = f\"Medium (Macro={best_macro_lag}, Micro={best_micro_lag})\"\n",
    "    elif best_macro_lag is not None:\n",
    "        recommended_lag = best_macro_lag\n",
    "        confidence = \"High (Macro Only)\"\n",
    "    elif best_micro_lag is not None:\n",
    "        recommended_lag = best_micro_lag\n",
    "        confidence = \"Medium (Micro Only)\"\n",
    "    else:\n",
    "        recommended_lag = 1\n",
    "        confidence = \"Low (Default Fallback)\"\n",
    "\n",
    "    print(f\"üéØ FINAL DECISION: Apply Lag of {recommended_lag} Month(s)\")\n",
    "    print(f\"   Confidence: {confidence}\")\n",
    "    print(f\"   Interpretation: {recommended_lag} month delay from port arrival to retail sale\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return recommended_lag\n",
    "\n",
    "# Execute and update configuration\n",
    "calculated_lag = determine_optimal_lag(df_imports)\n",
    "CONF['LAG_MONTHS'] = calculated_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b13e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# APPLY LAG & MERGE LAG & MARKET SHARE\n",
    "# ==========================================\n",
    "def apply_lag_and_merge_shares(df_trade: pd.DataFrame, share_file: str) -> pd.DataFrame:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LAG APPLICATION & BRAND SPLIT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Load Market Share\n",
    "    if not os.path.exists(share_file):\n",
    "        print(f\"‚ùå Market share file '{share_file}' not found.\")\n",
    "        return None\n",
    "        \n",
    "    df_share = pd.read_csv(share_file)\n",
    "    \n",
    "    # Standardize Date\n",
    "    date_col = 'Date' if 'Date' in df_share.columns else 'month'\n",
    "    df_share['month'] = pd.to_datetime(df_share[date_col])\n",
    "    \n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    # 2. EXTEND DATAFRAME TO CAPTURE LAGGED DATA\n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    df_trade = df_trade.copy()\n",
    "    lag = CONF['LAG_MONTHS']  # 1 month (scientifically derived)\n",
    "    \n",
    "    # Create extension row(s) for the lag period\n",
    "    last_date = df_trade['month'].max()\n",
    "    extension_dates = pd.date_range(\n",
    "        start=last_date + pd.DateOffset(months=1),\n",
    "        periods=lag,\n",
    "        freq='MS'\n",
    "    )\n",
    "    \n",
    "    df_extension = pd.DataFrame({\n",
    "        'month': extension_dates,\n",
    "        'import_units': [np.nan] * lag,  # No imports for future months\n",
    "        'import_value_cad': [np.nan] * lag\n",
    "    })\n",
    "    \n",
    "    # Append extension rows\n",
    "    df_trade = pd.concat([df_trade, df_extension], ignore_index=True)\n",
    "    \n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    # 3. APPLY SUPPLY CHAIN LAG (SHIFT FORWARD)\n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    # Logic: Imports in Oct become Sales in Nov (1-month lag)\n",
    "    df_trade['sales_proxy_units'] = df_trade['import_units'].shift(lag)\n",
    "    df_trade['sales_proxy_value'] = df_trade['import_value_cad'].shift(lag)\n",
    "    \n",
    "    # Drop initial rows where we have no sales signal yet\n",
    "    df_trade = df_trade.dropna(subset=['sales_proxy_units'])\n",
    "    \n",
    "    print(f\"‚úÖ Lag applied: Data extended to {df_trade['month'].max().strftime('%Y-%m')} (+{lag} month)\")\n",
    "    \n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    # 4. MERGE WITH MARKET SHARE (LEFT JOIN + FORWARD FILL)\n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    df_merged = pd.merge(df_trade, df_share, on='month', how='left')\n",
    "    \n",
    "    # Forward-fill market share for new month(s)\n",
    "    # Assumption: Nov 2025 share ‚âà Oct 2025 share\n",
    "    share_cols = [c for c in df_merged.columns if c in CONF['TARGET_BRANDS']]\n",
    "    if share_cols:\n",
    "        df_merged[share_cols] = df_merged[share_cols].ffill()\n",
    "        \n",
    "        missing_share_rows = df_merged[df_merged[share_cols[0]].isna()]\n",
    "        if len(missing_share_rows) > 0:\n",
    "            print(f\"‚ö†Ô∏è  Market share forward-filled for {len(missing_share_rows)} month(s): {missing_share_rows['month'].dt.strftime('%Y-%m').tolist()}\")\n",
    "    \n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    # 5. CALCULATE BRAND UNITS\n",
    "    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "    for brand in CONF['TARGET_BRANDS']:\n",
    "        if brand in df_merged.columns:\n",
    "            # Share is 0-100, convert to decimal\n",
    "            df_merged[f'{brand}_units'] = df_merged['sales_proxy_units'] * (df_merged[brand] / 100)\n",
    "    \n",
    "    print(f\"‚úÖ Merged & Lagged Data: {len(df_merged)} rows (from {df_merged['month'].min().strftime('%Y-%m')} to {df_merged['month'].max().strftime('%Y-%m')})\")\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "\n",
    "# Execute\n",
    "df_master = apply_lag_and_merge_shares(df_imports, CONF['MARKET_SHARE_FILE'])\n",
    "display(df_master.head())\n",
    "display(df_master.tail())  \n",
    "\n",
    "CONF['MARKET_SHARE_APPLIED'] = True\n",
    "CONF['LAG_APPLIED'] = True\n",
    "df_full_data = df_master.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# BEHAVIORAL LAG DETECTION (Google Trends ‚Üí Sales) \n",
    "# ===========================================================\n",
    "\"\"\"\n",
    "PURPOSE: Find lag between Google searches and actual purchases\n",
    "LOGIC:   Searches LEAD purchases (people search, then buy)\n",
    "         Expected: Negative lag (Trends at t-k ‚Üí Sales at t)\n",
    "\n",
    "FEATURES:\n",
    "- Granger causality testing for causal validation\n",
    "- Weighted trend contribution (strong/weak/none)\n",
    "- Bonferroni correction for multiple comparisons\n",
    "- Seasonal decomposition preprocessing\n",
    "- Brand-specific regime filtering\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BEHAVIORAL LAG DETECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ================================================================\n",
    "# BRAND-SPECIFIC START DATES (REGIME FILTERING)\n",
    "# ================================================================\n",
    "\n",
    "BRAND_START_DATES = {\n",
    "    'Apple': '2011-01-01',       # iPhone 4S era onwards\n",
    "    'Samsung': '2011-01-01',     # Galaxy S2 era onwards\n",
    "    'Google': '2016-10-01',      # Pixel 1 launch (NOT Nexus era)\n",
    "    'Motorola': '2014-01-01'     # Lenovo acquisition era\n",
    "}\n",
    "\n",
    "print(\"Regime filtering:\")\n",
    "for brand, date in BRAND_START_DATES.items():\n",
    "    print(f\"  {brand}: {date} onwards\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: FETCH GOOGLE TRENDS \n",
    "# ============================================================\n",
    "def fetch_trends_robust(brand, search_term, retries=5):\n",
    "    \"\"\"\n",
    "    Fetch Google Trends with exponential backoff\n",
    "    \"\"\"\n",
    "    from pytrends.request import TrendReq\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            pytrends = TrendReq(\n",
    "                hl='en-CA', \n",
    "                tz=300, \n",
    "                timeout=(10, 25), \n",
    "                retries=3,\n",
    "                backoff_factor=0.5\n",
    "            )\n",
    "            \n",
    "            pytrends.build_payload(\n",
    "                [search_term], \n",
    "                timeframe='2011-01-01 2025-12-31', \n",
    "                geo='CA'\n",
    "            )\n",
    "            \n",
    "            df = pytrends.interest_over_time()\n",
    "            \n",
    "            if not df.empty:\n",
    "                # Remove 'isPartial' column if present\n",
    "                if 'isPartial' in df.columns:\n",
    "                    df = df.drop('isPartial', axis=1)\n",
    "                \n",
    "                df = df.reset_index()\n",
    "                df.rename(columns={'date': 'month', search_term: 'trends_score'}, inplace=True)\n",
    "                df = df[['month', 'trends_score']]\n",
    "                df['month'] = pd.to_datetime(df['month'])\n",
    "                \n",
    "                # Monthly aggregation\n",
    "                df = df.groupby(df['month'].dt.to_period('M')).agg({\n",
    "                    'trends_score': 'mean'\n",
    "                }).reset_index()\n",
    "                df['month'] = df['month'].dt.to_timestamp()\n",
    "                \n",
    "                # Filter to valid date range\n",
    "                df = df[(df['month'] >= '2011-01-01') & (df['month'] <= '2025-12-31')]\n",
    "                \n",
    "                return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < retries - 1:\n",
    "                # Exponential backoff: 60, 120, 240 seconds\n",
    "                sleep_time = 60 * (2 ** attempt)\n",
    "                print(f\"    Attempt {attempt+1} failed, retrying in {sleep_time}s...\")\n",
    "                time.sleep(sleep_time)\n",
    "            else:\n",
    "                print(f\"    Failed after {retries} attempts: {e}\")\n",
    "                return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: PREPROCESSING (STATIONARITY + SEASONALITY REMOVAL)\n",
    "# ============================================================\n",
    "def preprocess_series(series, name, min_samples=36):\n",
    "    \"\"\"\n",
    "    Robust preprocessing for time series\n",
    "    \n",
    "    Steps:\n",
    "    1. Validate sufficient data\n",
    "    2. Test stationarity (ADF test)\n",
    "    3. Remove trend and seasonality\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(series) < min_samples:\n",
    "        raise ValueError(f\"{name}: Insufficient data ({len(series)} < {min_samples})\")\n",
    "    \n",
    "    # Remove any NaN/inf\n",
    "    series = series.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    # Stationarity test (ADF)\n",
    "    try:\n",
    "        adf_result = adfuller(series, autolag='AIC')\n",
    "        is_stationary = adf_result[1] < 0.05\n",
    "        \n",
    "        if not is_stationary:\n",
    "            # First difference to achieve stationarity\n",
    "            series = series.diff().dropna()\n",
    "            print(f\"    {name}: Differenced (non-stationary, p={adf_result[1]:.3f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"    {name}: ADF test failed ({e}), skipping stationarity check\")\n",
    "    \n",
    "    # Seasonal decomposition (if enough data after differencing)\n",
    "    if len(series) >= 36:\n",
    "        try:\n",
    "            decomp = seasonal_decompose(\n",
    "                series, \n",
    "                model='additive', \n",
    "                period=12,\n",
    "                extrapolate_trend='freq'\n",
    "            )\n",
    "            # Remove trend and seasonal components\n",
    "            residual = series - decomp.trend - decomp.seasonal\n",
    "            residual = residual.dropna()\n",
    "            print(f\"    {name}: Seasonal decomposition applied\")\n",
    "            return residual\n",
    "        except Exception as e:\n",
    "            print(f\"    {name}: Seasonal decomposition failed ({e}), using linear detrend\")\n",
    "    \n",
    "    # Fallback: Linear detrending\n",
    "    x = np.arange(len(series))\n",
    "    slope, intercept = np.polyfit(x, series.values, 1)\n",
    "    detrended = series - (slope * x + intercept)\n",
    "    print(f\"    {name}: Linear detrend applied\")\n",
    "    \n",
    "    return detrended\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: BEHAVIORAL LAG DETECTION WITH GRANGER CAUSALITY\n",
    "# ============================================================\n",
    "def detect_behavioral_lag_robust(df_sales, df_trends, brand_name):\n",
    "    \"\"\"\n",
    "    Detect lag between Google searches and purchases\n",
    "    \n",
    "    METHODOLOGY:\n",
    "    1. Granger causality test (causal validation)\n",
    "    2. Cross-correlation scan (lag estimation, negative only)\n",
    "    3. Bonferroni correction (multiple comparisons)\n",
    "    4. Statistical weight calculation (0.0 to 1.0)\n",
    "    \n",
    "    CRITICAL CONSTRAINTS:\n",
    "    - Lag must be NEGATIVE (searches lead purchases)\n",
    "    - Brand-specific regime filtering applied\n",
    "    \"\"\"\n",
    "    \n",
    "    sales_col = f'{brand_name}_units'\n",
    "    \n",
    "    # Validate inputs\n",
    "    if sales_col not in df_sales.columns:\n",
    "        print(f\"  {brand_name}: Sales column not found\")\n",
    "        return {\n",
    "            'lag': 0, \n",
    "            'correlation': 0.0, \n",
    "            'p_value': 1.0, \n",
    "            'granger_pval': 1.0,\n",
    "            'trend_weight': 0.0,\n",
    "            'method': 'missing_data', \n",
    "            'significant': False\n",
    "        }\n",
    "    \n",
    "    if df_trends is None or df_trends.empty:\n",
    "        print(f\"  {brand_name}: No trends data available\")\n",
    "        return {\n",
    "            'lag': 0, \n",
    "            'correlation': 0.0, \n",
    "            'p_value': 1.0, \n",
    "            'granger_pval': 1.0,\n",
    "            'trend_weight': 0.0,\n",
    "            'method': 'no_trends', \n",
    "            'significant': False\n",
    "        }\n",
    "    \n",
    "    # ============================================================\n",
    "    # APPLY REGIME FILTERING\n",
    "    # ============================================================\n",
    "    start_date = BRAND_START_DATES.get(brand_name, '2011-01-01')\n",
    "    \n",
    "    df_sales_filtered = df_sales[df_sales['month'] >= start_date].copy()\n",
    "    df_trends_filtered = df_trends[df_trends['month'] >= start_date].copy()\n",
    "    \n",
    "    print(f\"\\n  {brand_name} (regime: {start_date} onwards):\")\n",
    "    print(f\"    Sales: {len(df_sales_filtered)} months\")\n",
    "    print(f\"    Trends: {len(df_trends_filtered)} months\")\n",
    "    \n",
    "    # Merge on filtered data\n",
    "    df = pd.merge(\n",
    "        df_trends_filtered[['month', 'trends_score']],\n",
    "        df_sales_filtered[['month', sales_col]].rename(columns={sales_col: 'sales'}),\n",
    "        on='month',\n",
    "        how='inner'\n",
    "    ).sort_values('month').reset_index(drop=True)\n",
    "    \n",
    "    if len(df) < 36:\n",
    "        print(f\"    Insufficient overlap ({len(df)} months < 36)\")\n",
    "        return {\n",
    "            'lag': 0, \n",
    "            'correlation': 0.0, \n",
    "            'p_value': 1.0, \n",
    "            'granger_pval': 1.0,\n",
    "            'trend_weight': 0.0,\n",
    "            'method': 'insufficient_overlap', \n",
    "            'significant': False\n",
    "        }\n",
    "    \n",
    "    print(f\"    Merged: {len(df)} months overlap\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # PREPROCESS BOTH SERIES\n",
    "    # ============================================================\n",
    "    try:\n",
    "        trends_clean = preprocess_series(\n",
    "            df.set_index('month')['trends_score'], \n",
    "            'Trends',\n",
    "            min_samples=36\n",
    "        )\n",
    "        sales_clean = preprocess_series(\n",
    "            df.set_index('month')['sales'], \n",
    "            'Sales',\n",
    "            min_samples=36\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"    Preprocessing failed: {e}\")\n",
    "        return {\n",
    "            'lag': 0, \n",
    "            'correlation': 0.0, \n",
    "            'p_value': 1.0, \n",
    "            'granger_pval': 1.0,\n",
    "            'trend_weight': 0.0,\n",
    "            'method': 'preprocessing_failed', \n",
    "            'significant': False\n",
    "        }\n",
    "    \n",
    "    # ============================================================\n",
    "    # ALIGN SERIES (HANDLE LENGTH MISMATCH)\n",
    "    # ============================================================\n",
    "    common_dates = trends_clean.index.intersection(sales_clean.index)\n",
    "    \n",
    "    if len(common_dates) < 24:\n",
    "        print(f\"    Insufficient common dates after preprocessing ({len(common_dates)} < 24)\")\n",
    "        return {\n",
    "            'lag': 0, \n",
    "            'correlation': 0.0, \n",
    "            'p_value': 1.0, \n",
    "            'granger_pval': 1.0,\n",
    "            'trend_weight': 0.0,\n",
    "            'method': 'insufficient_common_dates', \n",
    "            'significant': False\n",
    "        }\n",
    "    \n",
    "    trends_aligned = trends_clean.loc[common_dates]\n",
    "    sales_aligned = sales_clean.loc[common_dates]\n",
    "    \n",
    "    print(f\"    Aligned: {len(common_dates)} months\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # GRANGER CAUSALITY TEST\n",
    "    # ============================================================\n",
    "    print(f\"  Granger Causality Test:\")\n",
    "    \n",
    "    gc_data = pd.DataFrame({\n",
    "        'sales': sales_aligned.values,\n",
    "        'trends': trends_aligned.values\n",
    "    })\n",
    "    \n",
    "    best_gc_pval = 1.0\n",
    "    \n",
    "    try:\n",
    "        gc_result = grangercausalitytests(\n",
    "            gc_data[['sales', 'trends']], \n",
    "            maxlag=6,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        for lag in range(1, 7):\n",
    "            # F-test p-value\n",
    "            p_value = gc_result[lag][0]['ssr_ftest'][1]\n",
    "            print(f\"    Lag {lag}: p={p_value:.4f}\")\n",
    "            \n",
    "            if p_value < best_gc_pval:\n",
    "                best_gc_pval = p_value\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"    ‚úó Granger test failed: {e}\")\n",
    "        best_gc_pval = 1.0\n",
    "    \n",
    "    # ============================================================\n",
    "    # CALCULATE TREND WEIGHT (BASED ON GRANGER P-VALUE)\n",
    "    # ============================================================\n",
    "    if best_gc_pval < 0.01:\n",
    "        trend_weight = 1.0\n",
    "        causality_status = \"Strong\"\n",
    "    elif best_gc_pval < 0.50:\n",
    "        # Continuous exponential decay\n",
    "        # This ensures weak signals still contribute\n",
    "        trend_weight = max(0.1, 1.0 - (best_gc_pval / 0.5) ** 0.5)\n",
    "        if trend_weight >= 0.5:\n",
    "            causality_status = \"Moderate\"\n",
    "        elif trend_weight >= 0.2:\n",
    "            causality_status = \"Weak\"\n",
    "        else:\n",
    "            causality_status = \"Very Weak\"\n",
    "    else:\n",
    "        trend_weight = 0.0\n",
    "        causality_status = \"None\"\n",
    "    \n",
    "    print(f\"    ‚Üí {causality_status} causality (p={best_gc_pval:.4f}) ‚Üí weight={trend_weight:.2f}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # CROSS-CORRELATION (ONLY IF SOME CAUSALITY DETECTED)\n",
    "    # ============================================================\n",
    "    if trend_weight > 0:\n",
    "        print(f\"  Cross-Correlation Scan (negative lags only):\")\n",
    "        \n",
    "        best_lag = 0\n",
    "        best_corr = 0.0\n",
    "        best_p = 1.0\n",
    "        \n",
    "        # CRITICAL: Only test NEGATIVE lags (searches LEAD)\n",
    "        for lag in range(-12, 0):\n",
    "            shifted_sales = sales_aligned.shift(-lag)\n",
    "            valid = trends_aligned.notna() & shifted_sales.notna()\n",
    "            \n",
    "            if valid.sum() < 12:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                r, p = stats.pearsonr(\n",
    "                    trends_aligned[valid].values, \n",
    "                    shifted_sales[valid].values\n",
    "                )\n",
    "                \n",
    "                print(f\"    Lag {lag:+3d}: r={r:+.3f}, p={p:.4f}\")\n",
    "                \n",
    "                # Bonferroni correction: 0.05 / 12 lags\n",
    "                if abs(r) > abs(best_corr) and p < 0.0042:\n",
    "                    best_lag = lag\n",
    "                    best_corr = r\n",
    "                    best_p = p\n",
    "            \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        is_significant = best_p < 0.0042\n",
    "        \n",
    "        if is_significant:\n",
    "            print(f\"  ‚Üí Selected lag: {best_lag} months (searches LEAD by {abs(best_lag)} months)\")\n",
    "        else:\n",
    "            print(f\"  ‚Üí No significant lag detected, using concurrent (lag=0)\")\n",
    "            best_lag = 0\n",
    "    else:\n",
    "        # No causality, skip cross-correlation\n",
    "        print(f\"  ‚Üí No causality detected, defaulting to lag=0\")\n",
    "        best_lag = 0\n",
    "        best_corr = 0.0\n",
    "        best_p = 1.0\n",
    "        is_significant = False\n",
    "    \n",
    "    return {\n",
    "        'lag': best_lag,\n",
    "        'correlation': best_corr,\n",
    "        'p_value': best_p,\n",
    "        'granger_pval': best_gc_pval,\n",
    "        'trend_weight': trend_weight,\n",
    "        'method': 'granger_validated' if trend_weight > 0 else 'no_causality',\n",
    "        'significant': is_significant\n",
    "    }\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTION\n",
    "# ================================================================\n",
    "\n",
    "SEARCH_TERMS = {\n",
    "    'Apple': 'iPhone',\n",
    "    'Samsung': 'Samsung Galaxy',\n",
    "    'Google': 'Pixel',\n",
    "    'Motorola': 'Moto'\n",
    "}\n",
    "\n",
    "print(\"\\n[1/3] Fetching Google Trends...\")\n",
    "\n",
    "trends_dict_raw = {}\n",
    "\n",
    "for brand in CONF['TARGET_BRANDS']:\n",
    "    print(f\"\\n{brand} ({SEARCH_TERMS[brand]}):\")\n",
    "    df = fetch_trends_robust(brand, SEARCH_TERMS[brand], retries=3)\n",
    "    \n",
    "    if df is not None:\n",
    "        print(f\"  ‚úì Fetched {len(df)} months ({df['month'].min().date()} to {df['month'].max().date()})\")\n",
    "        trends_dict_raw[brand] = df\n",
    "    else:\n",
    "        print(f\"  ‚úó Failed to fetch\")\n",
    "        trends_dict_raw[brand] = None\n",
    "\n",
    "print(f\"\\n‚úì Trends fetched: {sum(1 for v in trends_dict_raw.values() if v is not None)}/{len(CONF['TARGET_BRANDS'])} brands\")\n",
    "\n",
    "# ================================================================\n",
    "# DETECT LAGS & CALCULATE WEIGHTS\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[2/3] Detecting behavioral lags & calculating weights...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "behavioral_lags = {}\n",
    "trend_weights = {}\n",
    "\n",
    "for brand in CONF['TARGET_BRANDS']:\n",
    "    result = detect_behavioral_lag_robust(\n",
    "        df_full_data,\n",
    "        trends_dict_raw[brand],\n",
    "        brand\n",
    "    )\n",
    "    behavioral_lags[brand] = result\n",
    "    trend_weights[brand] = result['trend_weight']\n",
    "\n",
    "# ================================================================\n",
    "# ALIGN TRENDS TO PURCHASE TIMING\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[3/3] Aligning trends to purchase timing...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "trends_dict_aligned = {}\n",
    "\n",
    "for brand in CONF['TARGET_BRANDS']:\n",
    "    df_trends = trends_dict_raw.get(brand)\n",
    "    \n",
    "    if df_trends is None:\n",
    "        trends_dict_aligned[brand] = None\n",
    "        print(f\"  {brand}: No trends data\")\n",
    "        continue\n",
    "    \n",
    "    lag = behavioral_lags[brand]['lag']\n",
    "    df_aligned = df_trends.copy()\n",
    "    \n",
    "    if lag != 0:\n",
    "        # Negative lag means searches LEAD\n",
    "        # Shift trends FORWARD by |lag| months\n",
    "        df_aligned['month'] = df_aligned['month'] + pd.DateOffset(months=abs(lag))\n",
    "        print(f\"  {brand}: Shifted {abs(lag)} months FORWARD (searches lead)\")\n",
    "    else:\n",
    "        print(f\"  {brand}: No shift (lag=0)\")\n",
    "    \n",
    "    trends_dict_aligned[brand] = df_aligned\n",
    "\n",
    "# ================================================================\n",
    "# SAVE TO CONF\n",
    "# ================================================================\n",
    "\n",
    "CONF['TRENDS_DICT_RAW'] = trends_dict_raw\n",
    "CONF['TRENDS_DICT_ALIGNED'] = trends_dict_aligned\n",
    "CONF['BEHAVIORAL_LAGS'] = behavioral_lags\n",
    "CONF['TREND_WEIGHTS'] = trend_weights  # NEW: Statistical weights for Cell 4.6\n",
    "\n",
    "# ================================================================\n",
    "# SUMMARY\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ BEHAVIORAL LAG DETECTION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nGranger Causality & Weights:\")\n",
    "for brand, result in behavioral_lags.items():\n",
    "    weight = result['trend_weight']\n",
    "    granger_p = result['granger_pval']\n",
    "    \n",
    "    if weight == 1.0:\n",
    "        status = \"Strong\"\n",
    "    elif weight > 0:\n",
    "        status = \"Weak\"\n",
    "    else:\n",
    "        status = \"None\"\n",
    "    \n",
    "    print(f\"  {brand}: {status} (p={granger_p:.4f}) ‚Üí weight={weight:.2f}\")\n",
    "\n",
    "print(\"\\nLag Detection:\")\n",
    "for brand, result in behavioral_lags.items():\n",
    "    if result['significant']:\n",
    "        lag = result['lag']\n",
    "        print(f\"  {brand}: Searches LEAD by {abs(lag)} months\")\n",
    "    else:\n",
    "        print(f\"  {brand}: Concurrent (lag=0)\")\n",
    "\n",
    "print(\"\\n‚úì Trends aligned to purchase timing\")\n",
    "print(\"‚úì Statistical weights saved to CONF['TREND_WEIGHTS']\")\n",
    "print(\"‚úì Ready for Cell 4.6 (Calibration)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# VOLUME CALIBRATION (Synthetic Signal Method)\n",
    "# =======================================================\n",
    "\"\"\"\n",
    "PURPOSE: Calibrate sales volumes using a composite signal of:\n",
    "- Lagged import data (primary signal)\n",
    "- Aligned Google Trends (behavioral signal)\n",
    "- Market share (brand split)\n",
    "\"\"\"\n",
    "if CONF.get('CALIBRATION_COMPLETE', False):\n",
    "    print(\"‚ö†Ô∏è CALIBRATION SKIPPED: Already applied. To re-run, set CONF['CALIBRATION_COMPLETE'] = False\")\n",
    "else:\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"VOLUME CALIBRATION (Synthetic Signal Method)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # =============================================================================\n",
    "    # CONFIGURATION\n",
    "    # =============================================================================\n",
    "\n",
    "    ACTUAL_ANNUAL_SALES = {\n",
    "        2014: 14.1 * 1_000_000,\n",
    "        2015: 13.3 * 1_000_000,\n",
    "        2016: 13.4 * 1_000_000,\n",
    "        2017: 13.5 * 1_000_000,\n",
    "        2018: 13.6 * 1_000_000,\n",
    "        2019: 13.6 * 1_000_000,\n",
    "        2020: 12.1 * 1_000_000,\n",
    "        2021: 12.9 * 1_000_000,\n",
    "        2022: 13.2 * 1_000_000,\n",
    "        2023: 13.8 * 1_000_000,\n",
    "        2024: 14.1 * 1_000_000,\n",
    "        2025: 14.6 * 1_000_000,\n",
    "    }\n",
    "\n",
    "    ACTUAL_ANNUAL_SALES.update({\n",
    "        2011: 9 * 1_000_000,\n",
    "        2012: 10.5 * 1_000_000,\n",
    "        2013: 12.9 * 1_000_000,\n",
    "    })\n",
    "\n",
    "    SKIP_CALIBRATION_YEARS = [2011, 2012, 2013]\n",
    "    PARTIAL_DATA_YEARS = {2025: 11}  # Have data through Nov after lag\n",
    "\n",
    "    supply_chain_lag = CONF.get('LAG_MONTHS', 1)\n",
    "    trends_dict_aligned = CONF.get('TRENDS_DICT_ALIGNED', {})\n",
    "    behavioral_lags = CONF.get('BEHAVIORAL_LAGS', {})\n",
    "\n",
    "    print(f\"\\nConfiguration:\")\n",
    "    print(f\"  Supply chain lag: {supply_chain_lag} month (ALREADY APPLIED in Cell 4)\")\n",
    "    print(f\"  2025 Target: {ACTUAL_ANNUAL_SALES[2025]:,.0f} units\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # STEP 1: CREATE COMPOSITE SIGNAL & CALCULATE CALIBRATED SALES\n",
    "    # =============================================================================\n",
    "\n",
    "    print(\"\\n[1/3] Calculating calibrated sales via Weighted Distribution...\")\n",
    "\n",
    "    df_market_share = pd.read_csv(CONF['MARKET_SHARE_FILE'])\n",
    "    if 'Date' in df_market_share.columns:\n",
    "        df_market_share.rename(columns={'Date': 'month'}, inplace=True)\n",
    "    df_market_share['month'] = pd.to_datetime(df_market_share['month'])\n",
    "\n",
    "    calibrated_sales = {}\n",
    "    composite_signals = {}\n",
    "\n",
    "    for brand in CONF['TARGET_BRANDS']:\n",
    "        print(f\"\\n  {brand}:\")\n",
    "        \n",
    "        brand_col = f'{brand}_units'\n",
    "        if brand_col not in df_full_data.columns:\n",
    "            print(f\"    ‚úó No data column '{brand_col}'\")\n",
    "            continue\n",
    "        \n",
    "        # =======================================================\n",
    "        # CREATE TIMELINE \n",
    "        # =======================================================\n",
    "        years = sorted(ACTUAL_ANNUAL_SALES.keys())\n",
    "        months = pd.date_range(f'{years[0]}-01-01', f'{years[-1]}-12-31', freq='MS')\n",
    "        \n",
    "        df = pd.DataFrame({'month': months})\n",
    "        df['year'] = df['month'].dt.year\n",
    "        df['annual_total'] = df['year'].map(ACTUAL_ANNUAL_SALES)\n",
    "        \n",
    "        # =======================================================\n",
    "        # GET SALES PROXY DATA \n",
    "        # =======================================================\n",
    "        df_sales_proxy = df_full_data[['month', brand_col]].copy()\n",
    "        df = pd.merge(df, df_sales_proxy, on='month', how='left')\n",
    "        df = df.rename(columns={brand_col: 'sales_proxy'})\n",
    "        \n",
    "        # =======================================================\n",
    "        # GET ALIGNED TRENDS\n",
    "        # =======================================================\n",
    "        df_trends = trends_dict_aligned.get(brand)\n",
    "        trend_weights = CONF.get('TREND_WEIGHTS', {})\n",
    "        weight = trend_weights.get(brand, 1.0)  # Default to 1.0 for backward compatibility\n",
    "\n",
    "        if df_trends is not None and not df_trends.empty:\n",
    "            df = pd.merge(df, df_trends[['month', 'trends_score']], on='month', how='left')\n",
    "            df['trends_score'].fillna(df['trends_score'].median(), inplace=True)\n",
    "    \n",
    "            # Apply statistical weighting based on Granger causality\n",
    "            if weight < 1.0:\n",
    "                # Blend trends with neutral (1.0) based on Granger strength\n",
    "                df['trends_score'] = weight * df['trends_score'] + (1 - weight) * 1.0\n",
    "                granger_p = behavioral_lags.get(brand, {}).get('granger_pval', 1.0)\n",
    "                print(f\"    ‚úì Trends weighted at {weight:.1%} (Granger p={granger_p:.4f})\")\n",
    "            else:\n",
    "                print(f\"    ‚úì Trends at full strength (strong causality)\")\n",
    "    \n",
    "            has_trends = True\n",
    "        else:\n",
    "            df['trends_score'] = 1.0\n",
    "            has_trends = False\n",
    "            print(f\"    ‚ÑπÔ∏è No trends data\")\n",
    "        \n",
    "        # =======================================================\n",
    "        # CALCULATE COMPOSITE SIGNAL \n",
    "        # =======================================================\n",
    "        df['composite_signal'] = df['sales_proxy'] * df['trends_score']\n",
    "        df['composite_signal'].fillna(0, inplace=True)\n",
    "        df['composite_signal'] = df['composite_signal'].clip(lower=0)\n",
    "        \n",
    "        # =======================================================\n",
    "        # GET MARKET SHARE \n",
    "        # =======================================================\n",
    "        share_col = brand if brand in df_market_share.columns else f'{brand}_share'\n",
    "        \n",
    "        if share_col not in df_market_share.columns:\n",
    "            print(f\"    ‚úó No market share column '{share_col}'\")\n",
    "            continue\n",
    "        \n",
    "        df = pd.merge(df, df_market_share[['month', share_col]], on='month', how='left')\n",
    "        \n",
    "        # Forward-fill Dec 2025 share if missing\n",
    "        if df[share_col].isna().any():\n",
    "            df[share_col] = df[share_col].ffill()\n",
    "            missing_count = df[df['month'].dt.year == 2025][share_col].isna().sum()\n",
    "            if missing_count > 0:\n",
    "                print(f\"    ‚ÑπÔ∏è Forward-filled {missing_count} missing 2025 market share values\")\n",
    "        \n",
    "        # =======================================================\n",
    "        # WEIGHTED DISTRIBUTION\n",
    "        # =======================================================\n",
    "        for year in years:\n",
    "            year_mask = df['year'] == year\n",
    "            year_data = df[year_mask].copy()\n",
    "            \n",
    "            if len(year_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # -------------------------------------------------------\n",
    "            # SPECIAL CASE 1: SKIP YEARS (2011-2013)\n",
    "            # --------------------------------------------------------\n",
    "            if year in SKIP_CALIBRATION_YEARS:\n",
    "                df.loc[year_mask, 'calibrated_sales'] = year_data['sales_proxy']\n",
    "                continue\n",
    "            \n",
    "            # CALCULATE TARGET\n",
    "            avg_share = year_data[share_col].mean()\n",
    "            brand_annual_target = ACTUAL_ANNUAL_SALES[year] * (avg_share / 100)\n",
    "            \n",
    "            # -------------------------------------------------------\n",
    "            # SPECIAL CASE 2: PARTIAL YEAR (2025)\n",
    "            # -------------------------------------------------------\n",
    "            if year in PARTIAL_DATA_YEARS:\n",
    "                last_valid_month = PARTIAL_DATA_YEARS[year]  \n",
    "                \n",
    "                # Calculate known signal (Jan-Nov)\n",
    "                valid_mask = year_mask & (df['month'].dt.month <= last_valid_month)\n",
    "                signal_sum_known = df.loc[valid_mask, 'composite_signal'].sum()\n",
    "                \n",
    "                print(f\"    ‚ÑπÔ∏è {year}: Have data through month {last_valid_month}\")\n",
    "                \n",
    "                # Estimate December signal using historical pattern\n",
    "                missing_mask = year_mask & (df['month'].dt.month > last_valid_month)\n",
    "                \n",
    "                if missing_mask.any():\n",
    "                    # Calculate Nov‚ÜíDec signal ratios from previous 3 years\n",
    "                    prev_years = [year - 1, year - 2, year - 3]\n",
    "                    signal_ratios = []\n",
    "                    \n",
    "                    for py in prev_years:\n",
    "                        if py in df['year'].values:\n",
    "                            nov_sig = df[(df['year'] == py) & (df['month'].dt.month == 11)]['composite_signal'].sum()\n",
    "                            dec_sig = df[(df['year'] == py) & (df['month'].dt.month == 12)]['composite_signal'].sum()\n",
    "                            \n",
    "                            if nov_sig > 0:\n",
    "                                signal_ratios.append(dec_sig / nov_sig)\n",
    "                    \n",
    "                    if signal_ratios:\n",
    "                        avg_signal_ratio = np.mean(signal_ratios)\n",
    "                        print(f\"    ‚ÑπÔ∏è Historical Nov‚ÜíDec signal ratio: {avg_signal_ratio:.3f} (avg of {len(signal_ratios)} years)\")\n",
    "                    else:\n",
    "                        avg_signal_ratio = 0.95\n",
    "                        print(f\"    ‚ö†Ô∏è No historical data - using default ratio: {avg_signal_ratio:.3f}\")\n",
    "                    \n",
    "                    # Synthesize December signal\n",
    "                    nov_2025_signal = df[(df['year'] == year) & (df['month'].dt.month == 11)]['composite_signal'].sum()\n",
    "                    estimated_dec_signal = nov_2025_signal * avg_signal_ratio\n",
    "                    \n",
    "                    # Add to total for multiplier calculation\n",
    "                    signal_sum_total = signal_sum_known + estimated_dec_signal\n",
    "                    \n",
    "                    print(f\"    ‚ÑπÔ∏è Nov 2025 signal: {nov_2025_signal:,.0f}\")\n",
    "                    print(f\"    ‚ÑπÔ∏è Dec 2025 signal (estimated): {estimated_dec_signal:,.0f}\")\n",
    "                else:\n",
    "                    signal_sum_total = signal_sum_known\n",
    "                \n",
    "                # Calculate 2025-specific multiplier\n",
    "                if signal_sum_total > 0:\n",
    "                    multiplier_2025 = brand_annual_target / signal_sum_total\n",
    "                else:\n",
    "                    multiplier_2025 = 1.0\n",
    "                    print(f\"    ‚ö†Ô∏è Zero signal sum - using multiplier 1.0\")\n",
    "                \n",
    "                print(f\"    ‚ÑπÔ∏è 2025 Multiplier: {multiplier_2025:.4f}x\")\n",
    "                \n",
    "                # Apply multiplier to Jan-Nov\n",
    "                df.loc[valid_mask, 'calibrated_sales'] = (\n",
    "                    df.loc[valid_mask, 'composite_signal'] * multiplier_2025\n",
    "                )\n",
    "                \n",
    "                # Calculate December as residual\n",
    "                jan_nov_sum = df.loc[valid_mask, 'calibrated_sales'].sum()\n",
    "                dec_residual = brand_annual_target - jan_nov_sum\n",
    "                \n",
    "                if dec_residual > 0:\n",
    "                    implied_dec_share = dec_residual / brand_annual_target\n",
    "                    \n",
    "                    if implied_dec_share <= 0.18:\n",
    "                        # Residual is reasonable\n",
    "                        df.loc[missing_mask, 'calibrated_sales'] = dec_residual\n",
    "                        print(f\"    ‚úì Dec 2025: {dec_residual:,.0f} units ({implied_dec_share*100:.1f}% of year)\")\n",
    "                    else:\n",
    "                        # Cap and scale\n",
    "                        print(f\"    ‚ö†Ô∏è Dec residual high ({implied_dec_share*100:.1f}%) - applying cap\")\n",
    "                        dec_capped = brand_annual_target * 0.15\n",
    "                        df.loc[missing_mask, 'calibrated_sales'] = dec_capped\n",
    "                        \n",
    "                        total_with_cap = jan_nov_sum + dec_capped\n",
    "                        if total_with_cap > 0:\n",
    "                            scale_factor = brand_annual_target / total_with_cap\n",
    "                            df.loc[year_mask, 'calibrated_sales'] *= scale_factor\n",
    "                            print(f\"    ‚ÑπÔ∏è Scaled all months by {scale_factor:.3f}x\")\n",
    "                else:\n",
    "                    # Target exceeded\n",
    "                    print(f\"    ‚ö†Ô∏è Target exceeded - scaling down\")\n",
    "                    df.loc[missing_mask, 'calibrated_sales'] = 0\n",
    "                    if jan_nov_sum > 0:\n",
    "                        scale_factor = brand_annual_target / jan_nov_sum\n",
    "                        df.loc[valid_mask, 'calibrated_sales'] *= scale_factor\n",
    "                \n",
    "                # Validation\n",
    "                final_sum = df.loc[year_mask, 'calibrated_sales'].sum()\n",
    "                final_error = abs(final_sum - brand_annual_target) / brand_annual_target\n",
    "                \n",
    "                if final_error < 0.01:\n",
    "                    print(f\"    ‚úì Validation: {final_sum:,.0f} vs target {brand_annual_target:,.0f} (¬±{final_error*100:.2f}%)\")\n",
    "                else:\n",
    "                    print(f\"    ‚ö†Ô∏è Validation: Error {final_error*100:.2f}%\")\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            # ------------------------------------------------------\n",
    "            # STANDARD WEIGHTED DISTRIBUTION (2014-2024)\n",
    "            # ------------------------------------------------------\n",
    "            signal_sum = year_data['composite_signal'].sum()\n",
    "            \n",
    "            if signal_sum > 0:\n",
    "                df.loc[year_mask, 'calibrated_sales'] = (\n",
    "                    brand_annual_target * (year_data['composite_signal'] / signal_sum)\n",
    "                )\n",
    "            else:\n",
    "                df.loc[year_mask, 'calibrated_sales'] = brand_annual_target / len(year_data)\n",
    "        \n",
    "        calibrated_sales[brand] = df[['month', 'calibrated_sales']].copy()\n",
    "        composite_signals[brand] = df[['month', 'composite_signal']].copy()\n",
    "        \n",
    "        total = df['calibrated_sales'].sum()\n",
    "        print(f\"    Total: {total:,.0f} units across {len(df)} months\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # STEP 2: CALCULATE EFFECTIVE MULTIPLIERS\n",
    "    # =============================================================================\n",
    "\n",
    "    print(\"\\n[2/3] Calculating effective multipliers...\")\n",
    "\n",
    "    calibration_multipliers = {}\n",
    "\n",
    "    for brand in CONF['TARGET_BRANDS']:\n",
    "        if brand not in calibrated_sales:\n",
    "            continue\n",
    "        \n",
    "        brand_col = f'{brand}_units'\n",
    "        if brand_col not in df_full_data.columns:\n",
    "            continue\n",
    "        \n",
    "        df_imp = df_full_data[['month', brand_col]].copy()\n",
    "        df_cal = calibrated_sales[brand]\n",
    "        \n",
    "        df_merged = pd.merge(df_imp, df_cal, on='month', how='inner')\n",
    "        df_merged = df_merged[(df_merged[brand_col] > 0) & (df_merged['calibrated_sales'] > 0)]\n",
    "        df_merged['year'] = df_merged['month'].dt.year\n",
    "        \n",
    "        if len(df_merged) == 0:\n",
    "            continue\n",
    "        \n",
    "        effective_mult = df_merged['calibrated_sales'].sum() / df_merged[brand_col].sum()\n",
    "        \n",
    "        skip_data = df_merged[df_merged['year'].isin(SKIP_CALIBRATION_YEARS)]\n",
    "        skip_mult = skip_data['calibrated_sales'].sum() / skip_data[brand_col].sum() if len(skip_data) > 0 else 1.0\n",
    "        \n",
    "        std_data = df_merged[~df_merged['year'].isin(SKIP_CALIBRATION_YEARS + list(PARTIAL_DATA_YEARS.keys()))]\n",
    "        std_mult = std_data['calibrated_sales'].sum() / std_data[brand_col].sum() if len(std_data) > 0 else effective_mult\n",
    "        \n",
    "        partial_data = df_merged[df_merged['year'].isin(PARTIAL_DATA_YEARS.keys())]\n",
    "        partial_mult = partial_data['calibrated_sales'].sum() / partial_data[brand_col].sum() if len(partial_data) > 0 else effective_mult\n",
    "        \n",
    "        calibration_multipliers[brand] = {\n",
    "            'multiplier': effective_mult,\n",
    "            'skip_years_mult': skip_mult,\n",
    "            'standard_mult': std_mult,\n",
    "            'partial_mult': partial_mult,\n",
    "            'data_points': len(df_merged)\n",
    "        }\n",
    "        \n",
    "        print(f\"  {brand}:\")\n",
    "        print(f\"    Standard: {std_mult:.3f}x | Partial (2025): {partial_mult:.3f}x\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # STEP 3: APPLY CALIBRATION TO df_full_data\n",
    "    # =============================================================================\n",
    "\n",
    "    print(\"\\n[3/3] Applying calibration to df_full_data...\")\n",
    "\n",
    "    for brand in CONF['TARGET_BRANDS']:\n",
    "        if brand not in calibrated_sales:\n",
    "            continue\n",
    "        \n",
    "        brand_col = f'{brand}_units'\n",
    "        if brand_col not in df_full_data.columns:\n",
    "            continue\n",
    "        \n",
    "        df_cal = calibrated_sales[brand]\n",
    "        \n",
    "        df_full_data = df_full_data.drop(brand_col, axis=1)\n",
    "        df_full_data = pd.merge(\n",
    "            df_full_data,\n",
    "            df_cal.rename(columns={'calibrated_sales': brand_col}),\n",
    "            on='month',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        df_full_data[brand_col].fillna(0, inplace=True)\n",
    "        \n",
    "        total = df_full_data[brand_col].sum()\n",
    "        print(f\"  {brand}: {total:>12,.0f} units\")\n",
    "\n",
    "    if 'import_units' in df_full_data.columns:\n",
    "        avg_mult = np.mean([m['standard_mult'] for m in calibration_multipliers.values()])\n",
    "        df_full_data['import_units'] *= avg_mult\n",
    "        \n",
    "        if 'import_value_cad' in df_full_data.columns:\n",
    "            df_full_data['import_value_cad'] *= avg_mult\n",
    "\n",
    "    CONF['CALIBRATION_MULTIPLIERS'] = calibration_multipliers\n",
    "    CONF['CALIBRATION_COMPLETE'] = True\n",
    "    \n",
    "    df_master = df_full_data.copy()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ CALIBRATION COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"‚úì 2025 Target: {ACTUAL_ANNUAL_SALES[2025]:,.0f} units\")\n",
    "    print(f\"‚úì Method: Synthetic Signal Completion\")\n",
    "    print(f\"‚úì NO double shifting - data used as-is from Cell 4\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1de6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Get External Regressors (CPI)\n",
    "# ================================================================\n",
    "\n",
    "def fetch_cpi_history(start_year=2011):\n",
    "    \"\"\"\n",
    "    Fetches official CPI data (Series V41690914) dynamically from Bank of Canada.\n",
    "    \"\"\"\n",
    "    print(\"üì° Connecting to Bank of Canada API...\")\n",
    "    \n",
    "    # Series V41690914 = Consumer Price Index \n",
    "    url = \"https://www.bankofcanada.ca/valet/observations/V41690914/json\"\n",
    "    params = {\"start_date\": f\"{start_year}-01-01\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Parse observations\n",
    "        observations = data.get('observations', [])\n",
    "        cpi_data = []\n",
    "        \n",
    "        for obs in observations:\n",
    "            cpi_data.append({\n",
    "                'month': pd.to_datetime(obs['d']),\n",
    "                'cpi_index': float(obs['V41690914']['v'])\n",
    "            })\n",
    "            \n",
    "        df = pd.DataFrame(cpi_data)\n",
    "        print(f\"   ‚úÖ Retrieved {len(df)} months of actual CPI data.\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå API Failure: {e}\")\n",
    "        return pd.DataFrame(columns=['month', 'cpi_index'])\n",
    "\n",
    "def fetch_boc_cpi_forecast():\n",
    "    \"\"\"\n",
    "    Fetches Bank of Canada's CPI forecast from their Monetary Policy Report.\n",
    "    Falls back to 2% target if API unavailable.\n",
    "    \"\"\"\n",
    "    print(\"üì° Fetching BoC CPI forecast...\")\n",
    "    \n",
    "    # Bank of Canada publishes CPI forecasts in their Monetary Policy Report\n",
    "    \n",
    "    try:\n",
    "        # Try fetching forecast series\n",
    "        url = \"https://www.bankofcanada.ca/valet/observations/STATIC_CPIXRATE/json\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        observations = data.get('observations', [])\n",
    "        \n",
    "        if observations:\n",
    "            # Get most recent forecast\n",
    "            latest = observations[-1]\n",
    "            forecast_rate = float(latest['STATIC_CPIXRATE']['v'])\n",
    "            print(f\"   ‚úÖ Retrieved BoC forecast: {forecast_rate:.2f}% annual inflation\")\n",
    "            return forecast_rate / 100  # Convert to decimal\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è BoC forecast API unavailable: {e}\")\n",
    "    \n",
    "    # Fallback: Use BoC's explicit 2% target\n",
    "    print(\"   ‚ÑπÔ∏è Using BoC's 2% inflation target as fallback\")\n",
    "    return 0.02\n",
    "\n",
    "def enrich_with_cpi(df_main):\n",
    "    # 1. GET ACTUALS (2011 - Present)\n",
    "    df_cpi = fetch_cpi_history(start_year=2011)\n",
    "    \n",
    "    if df_cpi.empty:\n",
    "        print(\"CRITICAL: No CPI data fetched. Cannot proceed.\")\n",
    "        return df_main\n",
    "        \n",
    "    # 2. MERGE\n",
    "    # Left join ensures we don't lose any rows from master df\n",
    "    df_merged = pd.merge(df_main, df_cpi, on='month', how='left')\n",
    "    \n",
    "    # 3. PROJECT FUTURE MONTHS (2026 and beyond)\n",
    "    last_real_val = df_cpi['cpi_index'].iloc[-1]\n",
    "    last_real_date = df_cpi['month'].max()\n",
    "    \n",
    "    # Fetch BoC's published forecast dynamically\n",
    "    annual_inflation_forecast = fetch_boc_cpi_forecast()\n",
    "    \n",
    "    # Convert annual to monthly growth rate\n",
    "    monthly_growth = (1 + annual_inflation_forecast) ** (1/12) - 1\n",
    "    \n",
    "    print(f\"   üìà Projecting CPI with {annual_inflation_forecast*100:.2f}% annual inflation\")\n",
    "    print(f\"      Monthly growth rate: {monthly_growth*100:.3f}%\")\n",
    "    \n",
    "    # Fill missing future values\n",
    "    for idx, row in df_merged.iterrows():\n",
    "        if pd.isna(row['cpi_index']) and row['month'] > last_real_date:\n",
    "            # Calculate months difference\n",
    "            months_ahead = (row['month'].year - last_real_date.year) * 12 + \\\n",
    "                          (row['month'].month - last_real_date.month)\n",
    "            \n",
    "            # Project forward using compound growth\n",
    "            projected_cpi = last_real_val * ((1 + monthly_growth) ** months_ahead)\n",
    "            df_merged.at[idx, 'cpi_index'] = projected_cpi\n",
    "    \n",
    "    # 4. Calculate Year-over-Year Change\n",
    "    df_merged = df_merged.sort_values('month').reset_index(drop=True)\n",
    "    df_merged['cpi_yoy'] = df_merged['cpi_index'].pct_change(periods=12) * 100\n",
    "    \n",
    "    print(f\"‚úÖ CPI Enrichment Complete.\")\n",
    "    print(f\"   Last Actual: {last_real_date.strftime('%Y-%m')} = {last_real_val:.2f}\")\n",
    "    \n",
    "    # Show projection sample\n",
    "    future = df_merged[df_merged['month'] > last_real_date].head(6)\n",
    "    if not future.empty:\n",
    "        print(f\"   Future Projection Sample:\")\n",
    "        print(future[['month', 'cpi_index', 'cpi_yoy']].to_string(index=False))\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "# Execute\n",
    "df_master = enrich_with_cpi(df_master)\n",
    "df_master.tail()\n",
    "\n",
    "df_full_data = df_master.copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# FINALIZE FEATURES\n",
    "# ================================================================\n",
    "\n",
    "def finalize_features(df):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PHASE 4: FINAL FEATURE SELECTION & ENRICHMENT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Select & Rename Core Columns\n",
    "    keep_cols = [\n",
    "        'month', \n",
    "        'Apple_units', 'Samsung_units', 'Google_units', 'Motorola_units', \n",
    "        'cpi_index'\n",
    "    ]\n",
    "    \n",
    "    # Create a copy to avoid SettingWithCopy warnings\n",
    "    df_final = df[keep_cols].copy()\n",
    "    \n",
    "    # 2. Add Basic Date Features\n",
    "    df_final['month_num'] = df_final['month'].dt.month\n",
    "    df_final['year'] = df_final['month'].dt.year\n",
    "    df_final['quarter'] = df_final['month'].dt.quarter\n",
    "    \n",
    "    # 3. Add Strategic Forecasting Events\n",
    "    # Holiday Season: November (Black Friday prep) & December (Xmas)\n",
    "    df_final['is_holiday_season'] = df_final['month_num'].apply(lambda x: 1 if x in [11, 12] else 0)\n",
    "    \n",
    "    # Back to School: August (Major sales driver for students/parents)\n",
    "    df_final['is_back_to_school'] = df_final['month_num'].apply(lambda x: 1 if x == 8 else 0)\n",
    "    \n",
    "    # Black Friday Specific: Strictly November\n",
    "    df_final['is_black_friday'] = df_final['month_num'].apply(lambda x: 1 if x == 11 else 0)\n",
    "    \n",
    "    # New Year / Boxing Day Clearance: January\n",
    "    df_final['is_new_year_promo'] = df_final['month_num'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "    # 4. Add Hardcoded Launch Cycles \n",
    "    # APPLE: September standard. \n",
    "    # Includes critical splits: 4S (Oct), X (Nov), XR (Oct), 12 Mini/ProMax (Nov), 14 Plus (Oct)\n",
    "    apple_dates = {\n",
    "        (2011, 10), (2012, 9), (2013, 9), (2014, 9), (2015, 9), (2016, 9), \n",
    "        (2017, 9), (2017, 11), # 8 vs X\n",
    "        (2018, 9), (2018, 10), # XS vs XR\n",
    "        (2019, 9),\n",
    "        (2020, 10), (2020, 11), # 12 vs 12 Mini/Pro Max\n",
    "        (2021, 9), \n",
    "        (2022, 9), (2022, 10), # 14 vs 14 Plus\n",
    "        (2023, 9), (2024, 9), \n",
    "        (2025, 3), (2025, 9)   # Forecast: SE4 (Spring) + 17 (Fall)\n",
    "    }\n",
    "\n",
    "    # SAMSUNG: S-Series (Spring/Jan) + Note/Z-Series (Summer/Fall)\n",
    "    samsung_dates = {\n",
    "        # S-Series (Flagship 1)\n",
    "        (2011, 4), (2011, 5), (2012, 5), (2013, 4), (2014, 4), (2015, 4), \n",
    "        (2016, 3), (2017, 4), (2018, 3), (2019, 3), \n",
    "        (2020, 3), (2021, 1), (2022, 2), (2023, 2), (2024, 1), (2025, 1),\n",
    "        \n",
    "        # Note/Fold Series (Flagship 2)\n",
    "        (2011, 10), (2012, 9), (2013, 9), (2014, 10), (2015, 8), \n",
    "        (2016, 8), (2017, 9), (2018, 8), (2019, 8), \n",
    "        (2019, 9), (2020, 2), (2020, 8), (2020, 9), \n",
    "        (2021, 8), (2022, 8), (2023, 8), (2024, 7), (2025, 7)\n",
    "    }\n",
    "\n",
    "    # GOOGLE: Nexus (Nov) -> Pixel (Oct) -> Strategic Shift (Aug) + Mid-cycle (May)\n",
    "    google_dates = {\n",
    "        # Nexus Era\n",
    "        (2011, 11), (2012, 11), (2013, 10), (2013, 11), (2014, 11), (2015, 9), (2015, 10),\n",
    "        # Pixel Era\n",
    "        (2016, 10), (2017, 10), (2018, 10), (2019, 5), (2019, 10),\n",
    "        (2020, 8), (2020, 10), (2021, 10), \n",
    "        (2022, 7), (2022, 10), (2023, 5), (2023, 6), (2023, 10),\n",
    "        # Modern Era (August Shift)\n",
    "        (2024, 5), (2024, 8), \n",
    "        (2025, 4), (2025, 8), (2025, 10)\n",
    "    }\n",
    "    \n",
    "    # MOTOROLA: Flagships + High Volume G-Series\n",
    "    motorola_dates = {\n",
    "        # Early Flagships\n",
    "        (2011, 11), (2012, 9), (2013, 8), (2014, 9), (2015, 9),\n",
    "        \n",
    "        # The G-Series Volume Drivers \n",
    "        (2013, 11), (2014, 5), (2014, 9), # G1, E1, G2\n",
    "        (2015, 2), (2015, 7),             # E2, G3\n",
    "        (2016, 5), (2017, 4), (2018, 5),  # G4, G5, G6 (Spring Pulse)\n",
    "        (2019, 2), (2020, 4), (2021, 1),  # G7, G Power 2020, G Power 2021\n",
    "        (2022, 2), (2023, 5), (2024, 3),  # Modern G-Series Spring Pulse\n",
    "        \n",
    "        # Modern Flagships (Razr / Edge / Z)\n",
    "        (2016, 7), (2017, 7), (2018, 8), (2019, 11), # Z Series / Razr 1\n",
    "        (2020, 9), (2021, 8), (2022, 8), (2022, 9),  # Razr 5G / Edge\n",
    "        (2023, 6), (2024, 6), (2025, 6)              # Razr+ / Razr 50 / Razr 60\n",
    "    }\n",
    "\n",
    "    # Vectorized check\n",
    "    def check_launch(row, date_set):\n",
    "        return 1 if (row['year'], row['month_num']) in date_set else 0\n",
    "\n",
    "    df_final['launch_apple'] = df_final.apply(lambda x: check_launch(x, apple_dates), axis=1)\n",
    "    df_final['launch_samsung'] = df_final.apply(lambda x: check_launch(x, samsung_dates), axis=1)\n",
    "    df_final['launch_google'] = df_final.apply(lambda x: check_launch(x, google_dates), axis=1)\n",
    "    df_final['launch_motorola'] = df_final.apply(lambda x: check_launch(x, motorola_dates), axis=1)\n",
    "    \n",
    "    print(f\"   ‚úÖ Final Dataset Ready: {len(df_final)} rows, {len(df_final.columns)} columns.\")\n",
    "    return df_final\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "df_modeling = finalize_features(df_master)\n",
    "\n",
    "# Display\n",
    "print(\"\\nüîé MODELING DATASET SAMPLE (Recent Months):\")\n",
    "# Show specific columns to verify structure\n",
    "print(df_modeling.tail(10))\n",
    "\n",
    "# Save checkpoint for production pipeline\n",
    "df_modeling = df_modeling.copy()\n",
    "print(f\"\\n‚úÖ Checkpoint saved: df_modeling ready for production testing\")\n",
    "\n",
    "df_full_data = df_modeling.copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ed72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Comprehensive Diagnosis & Visualization\n",
    "# ================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def comprehensive_diagnosis_and_visualization(df):\n",
    "    \"\"\"\n",
    "    Production-grade data diagnosis with statistical tests and visualization\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"COMPREHENSIVE DATA DIAGNOSIS & VALIDATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # =====================================================\n",
    "    # SECTION 1: STRUCTURAL VALIDATION\n",
    "    # =====================================================\n",
    "    print(\"\\n[1/6] STRUCTURAL VALIDATION\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    print(f\"üìä Dataset Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üìÖ Time Range: {df['month'].min().date()} to {df['month'].max().date()}\")\n",
    "    print(f\"üìÜ Total Months: {len(df)}\")\n",
    "    \n",
    "    # Check chronological order\n",
    "    if df['month'].is_monotonic_increasing:\n",
    "        print(\"‚úì Data is chronologically sorted\")\n",
    "    else:\n",
    "        print(\"‚ùå WARNING: Data not chronologically sorted\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    dupes = df[df.duplicated('month', keep=False)]\n",
    "    if len(dupes) == 0:\n",
    "        print(\"‚úì No duplicate months\")\n",
    "    else:\n",
    "        print(f\"‚ùå CRITICAL: {len(dupes)} duplicate months found\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # SECTION 2: COMPLETENESS CHECK\n",
    "    # =====================================================\n",
    "    print(\"\\n[2/6] COMPLETENESS CHECK\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Missing values by column\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"‚ö†Ô∏è Missing Values Detected:\")\n",
    "        for col, count in missing[missing > 0].items():\n",
    "            print(f\"   {col}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"‚úì No missing values\")\n",
    "    \n",
    "    # Time gaps\n",
    "    full_range = pd.date_range(df['month'].min(), df['month'].max(), freq='MS')\n",
    "    gaps = set(full_range) - set(df['month'])\n",
    "    if gaps:\n",
    "        print(f\"‚ö†Ô∏è {len(gaps)} time gaps detected:\")\n",
    "        print(f\"   {sorted([d.strftime('%Y-%m') for d in gaps])[:5]}...\")\n",
    "    else:\n",
    "        print(\"‚úì No time gaps - continuous monthly series\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # SECTION 3: DATA QUALITY METRICS\n",
    "    # =====================================================\n",
    "    print(\"\\n[3/6] DATA QUALITY METRICS\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    sales_cols = ['Apple_units', 'Samsung_units', 'Google_units', 'Motorola_units']\n",
    "    \n",
    "    print(\"\\nDescriptive Statistics:\")\n",
    "    stats = df[sales_cols].describe().round(0)\n",
    "    print(stats)\n",
    "    \n",
    "    # Check for zero/negative values\n",
    "    print(\"\\nZero/Negative Value Check:\")\n",
    "    for col in sales_cols:\n",
    "        zeros = len(df[df[col] <= 0])\n",
    "        if zeros > 0:\n",
    "            print(f\"   ‚ö†Ô∏è {col}: {zeros} months with zero/negative values\")\n",
    "        else:\n",
    "            print(f\"   ‚úì {col}: All positive values\")\n",
    "    \n",
    "    # Outlier detection (IQR method)\n",
    "    print(\"\\nOutlier Detection (IQR Method):\")\n",
    "    for col in sales_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        outliers = df[(df[col] < Q1 - 3*IQR) | (df[col] > Q3 + 3*IQR)]\n",
    "        \n",
    "        if len(outliers) > 0:\n",
    "            print(f\"   ‚ÑπÔ∏è {col}: {len(outliers)} outliers detected (¬±3 IQR)\")\n",
    "            # Show outlier months\n",
    "            outlier_months = outliers['month'].dt.strftime('%Y-%m').tolist()\n",
    "            print(f\"      Months: {', '.join(outlier_months[:3])}{'...' if len(outlier_months) > 3 else ''}\")\n",
    "        else:\n",
    "            print(f\"   ‚úì {col}: No extreme outliers\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # SECTION 4: STATIONARITY TESTS\n",
    "    # =====================================================\n",
    "    print(\"\\n[4/6] STATIONARITY TESTS (ADF)\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for col in sales_cols:\n",
    "        result = adfuller(df[col].dropna())\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"   ADF Statistic: {result[0]:.4f}\")\n",
    "        print(f\"   p-value: {result[1]:.4f}\")\n",
    "        \n",
    "        if result[1] < 0.05:\n",
    "            print(f\"   ‚úì STATIONARY (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è NON-STATIONARY (p ‚â• 0.05)\")\n",
    "            print(f\"   ‚Üí Use d=1 (differencing) in SARIMA models\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # SECTION 5: SEASONALITY ANALYSIS\n",
    "    # =====================================================\n",
    "    print(\"\\n[5/6] SEASONALITY ANALYSIS\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Quarterly patterns\n",
    "    quarterly_avg = df.groupby(df['month'].dt.quarter)['Apple_units'].mean()\n",
    "    \n",
    "    print(\"\\nQuarterly Patterns (Apple as proxy):\")\n",
    "    for q in [1, 2, 3, 4]:\n",
    "        pct_of_avg = (quarterly_avg[q] / quarterly_avg.mean() - 1) * 100\n",
    "        print(f\"   Q{q}: {quarterly_avg[q]:,.0f} units ({pct_of_avg:+.1f}% vs avg)\")\n",
    "    \n",
    "    q4_premium = (quarterly_avg[4] / quarterly_avg[1] - 1) * 100\n",
    "    \n",
    "    if q4_premium > 15:\n",
    "        print(f\"\\n‚úì Strong Q4 seasonality detected (+{q4_premium:.1f}% vs Q1)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Weak Q4 seasonality (+{q4_premium:.1f}% vs Q1)\")\n",
    "    \n",
    "    # Monthly patterns\n",
    "    monthly_avg = df.groupby(df['month'].dt.month)['Apple_units'].mean()\n",
    "    peak_month = monthly_avg.idxmax()\n",
    "    trough_month = monthly_avg.idxmin()\n",
    "    \n",
    "    month_names = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',\n",
    "                   7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    \n",
    "    print(f\"\\nMonthly Patterns:\")\n",
    "    print(f\"   Peak month: {month_names[peak_month]} ({monthly_avg[peak_month]:,.0f} units)\")\n",
    "    print(f\"   Trough month: {month_names[trough_month]} ({monthly_avg[trough_month]:,.0f} units)\")\n",
    "    print(f\"   Seasonality range: {(monthly_avg.max() / monthly_avg.min() - 1) * 100:.1f}%\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # SECTION 6: FEATURE VALIDATION\n",
    "    # =====================================================\n",
    "    print(\"\\n[6/6] FEATURE VALIDATION\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Launch indicators\n",
    "    launch_cols = ['launch_apple', 'launch_samsung', 'launch_google', 'launch_motorola']\n",
    "    existing_launch_cols = [c for c in launch_cols if c in df.columns]\n",
    "    \n",
    "    print(\"\\nLaunch Indicator Coverage:\")\n",
    "    for col in existing_launch_cols:\n",
    "        launch_count = df[col].sum()\n",
    "        print(f\"   {col.replace('launch_', '').title()}: {launch_count} launch months\")\n",
    "    \n",
    "    # Regressor availability\n",
    "    print(\"\\nExternal Regressors:\")\n",
    "    regressors = ['cpi_index', 'is_holiday_season', 'is_q4', 'is_back_to_school']\n",
    "    for reg in regressors:\n",
    "        if reg in df.columns:\n",
    "            non_null = df[reg].notna().sum()\n",
    "            print(f\"   ‚úì {reg}: {non_null}/{len(df)} values\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {reg}: NOT FOUND\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # VISUALIZATION\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERATING VISUALIZATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Brand colors\n",
    "    brand_configs = {\n",
    "        'Apple': {'color': '#555555', 'launch': 'launch_apple'},\n",
    "        'Samsung': {'color': '#034EA2', 'launch': 'launch_samsung'},\n",
    "        'Google': {'color': '#34A853', 'launch': 'launch_google'},\n",
    "        'Motorola': {'color': '#FF6900', 'launch': 'launch_motorola'}\n",
    "    }\n",
    "    \n",
    "    # Plot 1-4: Individual brand trends with launches (2x2 grid)\n",
    "    for idx, (brand, config) in enumerate(brand_configs.items()):\n",
    "        ax = fig.add_subplot(gs[idx // 2, idx % 2])\n",
    "        \n",
    "        col = f'{brand}_units'\n",
    "        launch_col = config['launch']\n",
    "        \n",
    "        # Sales line\n",
    "        ax.plot(df['month'], df[col], color=config['color'], linewidth=2, label='Sales')\n",
    "        \n",
    "        # Launch indicators\n",
    "        if launch_col in df.columns:\n",
    "            launches = df[df[launch_col] == 1]\n",
    "            for launch_date in launches['month']:\n",
    "                ax.axvline(x=launch_date, color='red', linestyle=':', alpha=0.4, linewidth=1)\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_title(f'{brand} Monthly Sales', fontsize=12, weight='bold')\n",
    "        ax.set_ylabel('Units', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1e6:.1f}M'))\n",
    "        \n",
    "        # Add trend line\n",
    "        from scipy import stats\n",
    "        x_numeric = np.arange(len(df))\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x_numeric, df[col])\n",
    "        trend_line = slope * x_numeric + intercept\n",
    "        ax.plot(df['month'], trend_line, '--', color='gray', alpha=0.5, linewidth=1, label=f'Trend (R¬≤={r_value**2:.2f})')\n",
    "        \n",
    "        ax.legend(loc='upper left', fontsize=8)\n",
    "    \n",
    "    # Plot 5: Market share evolution\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    \n",
    "    df_plot = df.copy()\n",
    "    df_plot['total'] = df_plot[sales_cols].sum(axis=1)\n",
    "    \n",
    "    for brand, config in brand_configs.items():\n",
    "        col = f'{brand}_units'\n",
    "        df_plot[f'{brand}_share'] = (df_plot[col] / df_plot['total'] * 100)\n",
    "        ax5.plot(df_plot['month'], df_plot[f'{brand}_share'], \n",
    "                color=config['color'], linewidth=2, label=brand)\n",
    "    \n",
    "    ax5.set_title('Market Share Evolution (%)', fontsize=12, weight='bold')\n",
    "    ax5.set_ylabel('Market Share (%)', fontsize=10)\n",
    "    ax5.legend(loc='best', fontsize=8)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Seasonality heatmap\n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    \n",
    "    df_pivot = df.copy()\n",
    "    df_pivot['year'] = df_pivot['month'].dt.year\n",
    "    df_pivot['month_num'] = df_pivot['month'].dt.month\n",
    "    \n",
    "    pivot_data = df_pivot.pivot_table(\n",
    "        values='Apple_units', \n",
    "        index='year', \n",
    "        columns='month_num',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    sns.heatmap(pivot_data, cmap='YlOrRd', ax=ax6, cbar_kws={'label': 'Units'}, fmt='.0f')\n",
    "    ax6.set_title('Seasonality Heatmap (Apple)', fontsize=12, weight='bold')\n",
    "    ax6.set_xlabel('Month', fontsize=10)\n",
    "    ax6.set_ylabel('Year', fontsize=10)\n",
    "    \n",
    "    # Plot 7: Distribution comparison\n",
    "    ax7 = fig.add_subplot(gs[2, 2])\n",
    "    \n",
    "    box_data = [df[col].dropna() for col in sales_cols]\n",
    "    box_labels = [col.replace('_units', '') for col in sales_cols]\n",
    "    \n",
    "    bp = ax7.boxplot(box_data, labels=box_labels, patch_artist=True)\n",
    "    \n",
    "    for patch, brand in zip(bp['boxes'], brand_configs.keys()):\n",
    "        patch.set_facecolor(brand_configs[brand]['color'])\n",
    "        patch.set_alpha(0.6)\n",
    "    \n",
    "    ax7.set_title('Sales Distribution by Brand', fontsize=12, weight='bold')\n",
    "    ax7.set_ylabel('Units', fontsize=10)\n",
    "    ax7.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1e6:.1f}M'))\n",
    "    ax7.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('Canadian Smartphone Market: Comprehensive Analysis (2011-2025)', \n",
    "                 fontsize=16, weight='bold', y=0.98)\n",
    "    \n",
    "    plt.savefig('comprehensive_diagnosis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # =====================================================\n",
    "    # FINAL REPORT CARD\n",
    "    # =====================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DIAGNOSIS REPORT CARD\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    score = 0\n",
    "    total_checks = 8\n",
    "    \n",
    "    # Scoring\n",
    "    if df['month'].is_monotonic_increasing: score += 1\n",
    "    if len(dupes) == 0: score += 1\n",
    "    if missing.sum() == 0: score += 1\n",
    "    if not gaps: score += 1\n",
    "    if all(df[col].min() > 0 for col in sales_cols): score += 1\n",
    "    if q4_premium > 10: score += 1\n",
    "    if all(c in df.columns for c in existing_launch_cols): score += 1\n",
    "    if 'cpi_index' in df.columns: score += 1\n",
    "    \n",
    "    grade = (score / total_checks) * 100\n",
    "    \n",
    "    if grade >= 90:\n",
    "        status = \"‚úÖ EXCELLENT\"\n",
    "    elif grade >= 75:\n",
    "        status = \"‚úì GOOD\"\n",
    "    elif grade >= 60:\n",
    "        status = \"‚ö†Ô∏è ACCEPTABLE\"\n",
    "    else:\n",
    "        status = \"‚ùå NEEDS IMPROVEMENT\"\n",
    "    \n",
    "    print(f\"\\nData Quality Score: {score}/{total_checks} ({grade:.0f}%)\")\n",
    "    print(f\"Status: {status}\")\n",
    "    \n",
    "    if grade >= 75:\n",
    "        print(\"\\n‚úÖ DATA READY FOR PRODUCTION MODELING\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è REVIEW ISSUES BEFORE PROCEEDING\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    filename = \"canada_smartphones_VALIDATED.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"\\nüíæ Validated dataset saved: {filename}\")\n",
    "    \n",
    "    return grade >= 75\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "if 'df_modeling' in globals():\n",
    "    is_ready = comprehensive_diagnosis_and_visualization(df_modeling)\n",
    "    \n",
    "    if is_ready:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"READY TO PROCEED TO MODEL TESTING\")\n",
    "        print(\"=\"*70)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'df_modeling' not found. Please run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Statistical Validation (Stationarity, Outliers, Seasonality)\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "class StatisticalValidator:\n",
    "    \"\"\"\n",
    "    Statistical validation focused on:\n",
    "    - Stationarity (ADF tests)\n",
    "    - Outlier detection (IQR method)\n",
    "    - Seasonality verification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, config: Dict):\n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.results = {}\n",
    "        \n",
    "    def validate_all(self) -> Tuple[bool, Dict]:\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"STATISTICAL VALIDATION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        self._check_stationarity()\n",
    "        self._check_outliers()\n",
    "        self._check_seasonality()\n",
    "        \n",
    "        # Generate summary\n",
    "        self._print_summary()\n",
    "        \n",
    "        return True, self.results\n",
    "    \n",
    "    def _check_stationarity(self):\n",
    "        print(\"\\n[1/3] STATIONARITY TESTS (Augmented Dickey-Fuller)\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        stationarity_results = {}\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            col = f'{brand}_units'\n",
    "            if col not in self.df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Run ADF test\n",
    "            result = adfuller(self.df[col].dropna(), autolag='AIC')\n",
    "            \n",
    "            adf_stat = result[0]\n",
    "            p_value = result[1]\n",
    "            critical_values = result[4]\n",
    "            \n",
    "            is_stationary = p_value < 0.05\n",
    "            \n",
    "            print(f\"\\n{brand}:\")\n",
    "            print(f\"   ADF Statistic: {adf_stat:.4f}\")\n",
    "            print(f\"   p-value: {p_value:.4f}\")\n",
    "            print(f\"   Critical Values:\")\n",
    "            for key, value in critical_values.items():\n",
    "                print(f\"      {key}: {value:.4f}\")\n",
    "            \n",
    "            if is_stationary:\n",
    "                print(f\"   ‚úì STATIONARY (reject H0 at Œ±=0.05)\")\n",
    "                print(f\"   ‚Üí Can use SARIMA with d=0\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è NON-STATIONARY (fail to reject H0)\")\n",
    "                print(f\"   ‚Üí Use SARIMA with d=1 (first-order differencing)\")\n",
    "            \n",
    "            stationarity_results[brand] = {\n",
    "                'adf_statistic': adf_stat,\n",
    "                'p_value': p_value,\n",
    "                'is_stationary': is_stationary,\n",
    "                'recommended_d': 0 if is_stationary else 1,\n",
    "                'critical_values': critical_values\n",
    "            }\n",
    "        \n",
    "        self.results['stationarity'] = stationarity_results\n",
    "    \n",
    "    def _check_outliers(self):\n",
    "        \"\"\"IQR-based outlier detection with detailed reporting\"\"\"\n",
    "        print(\"\\n[2/3] OUTLIER DETECTION (Tukey's IQR Method)\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        outlier_results = {}\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            col = f'{brand}_units'\n",
    "            if col not in self.df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Calculate IQR\n",
    "            Q1 = self.df[col].quantile(0.25)\n",
    "            Q2 = self.df[col].quantile(0.50)  # Median\n",
    "            Q3 = self.df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            # Define outlier boundaries (3 √ó IQR for extreme outliers)\n",
    "            lower_fence = Q1 - 3 * IQR\n",
    "            upper_fence = Q3 + 3 * IQR\n",
    "            \n",
    "            # Identify outliers\n",
    "            outliers = self.df[(self.df[col] < lower_fence) | (self.df[col] > upper_fence)]\n",
    "            \n",
    "            print(f\"\\n{brand}:\")\n",
    "            print(f\"   Q1 (25th percentile): {Q1:,.0f}\")\n",
    "            print(f\"   Q2 (median): {Q2:,.0f}\")\n",
    "            print(f\"   Q3 (75th percentile): {Q3:,.0f}\")\n",
    "            print(f\"   IQR: {IQR:,.0f}\")\n",
    "            print(f\"   Lower fence: {lower_fence:,.0f}\")\n",
    "            print(f\"   Upper fence: {upper_fence:,.0f}\")\n",
    "            \n",
    "            if len(outliers) > 0:\n",
    "                print(f\"   ‚ö†Ô∏è {len(outliers)} extreme outliers detected\")\n",
    "                \n",
    "                # Show outlier details\n",
    "                outlier_months = outliers[['month', col]].copy()\n",
    "                outlier_months['deviation'] = outlier_months[col].apply(\n",
    "                    lambda x: f\"{((x - Q2) / IQR):.2f}œÉ (IQR)\"\n",
    "                )\n",
    "                \n",
    "                print(f\"\\n   Outlier months:\")\n",
    "                for _, row in outlier_months.head(5).iterrows():\n",
    "                    print(f\"      {row['month'].strftime('%Y-%m')}: {row[col]:,.0f} units ({row['deviation']})\")\n",
    "                \n",
    "                if len(outliers) > 5:\n",
    "                    print(f\"      ... and {len(outliers) - 5} more\")\n",
    "                \n",
    "                print(f\"\\n   ‚ÑπÔ∏è NOTE: Outliers retained in dataset (may be real events like COVID)\")\n",
    "            else:\n",
    "                print(f\"   ‚úì No extreme outliers\")\n",
    "            \n",
    "            outlier_results[brand] = {\n",
    "                'Q1': Q1,\n",
    "                'Q2': Q2,\n",
    "                'Q3': Q3,\n",
    "                'IQR': IQR,\n",
    "                'lower_fence': lower_fence,\n",
    "                'upper_fence': upper_fence,\n",
    "                'outlier_count': len(outliers),\n",
    "                'outlier_months': outliers['month'].tolist() if len(outliers) > 0 else []\n",
    "            }\n",
    "        \n",
    "        self.results['outliers'] = outlier_results\n",
    "    \n",
    "    def _check_seasonality(self):\n",
    "        \"\"\"Comprehensive seasonality analysis\"\"\"\n",
    "        print(\"\\n[3/3] SEASONALITY ANALYSIS\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        seasonality_results = {}\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            col = f'{brand}_units'\n",
    "            if col not in self.df.columns:\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n{brand}:\")\n",
    "            \n",
    "            # Quarterly analysis\n",
    "            quarterly = self.df.groupby(self.df['month'].dt.quarter)[col].agg(['mean', 'std'])\n",
    "            overall_mean = quarterly['mean'].mean()\n",
    "            \n",
    "            print(f\"   Quarterly Patterns:\")\n",
    "            for q in [1, 2, 3, 4]:\n",
    "                q_mean = quarterly.loc[q, 'mean']\n",
    "                q_std = quarterly.loc[q, 'std']\n",
    "                deviation = (q_mean / overall_mean - 1) * 100\n",
    "                \n",
    "                print(f\"      Q{q}: {q_mean:>8,.0f} units (¬±{q_std:>6,.0f}) | {deviation:+6.1f}% vs avg\")\n",
    "            \n",
    "            # Calculate Q4 premium\n",
    "            q4_premium = (quarterly.loc[4, 'mean'] / quarterly.loc[1, 'mean'] - 1) * 100\n",
    "            \n",
    "            if q4_premium > 20:\n",
    "                seasonality_strength = \"STRONG\"\n",
    "                icon = \"‚úì\"\n",
    "            elif q4_premium > 10:\n",
    "                seasonality_strength = \"MODERATE\"\n",
    "                icon = \"‚ÑπÔ∏è\"\n",
    "            else:\n",
    "                seasonality_strength = \"WEAK\"\n",
    "                icon = \"‚ö†Ô∏è\"\n",
    "            \n",
    "            print(f\"\\n   {icon} Q4 Premium: {q4_premium:+.1f}% vs Q1\")\n",
    "            print(f\"   Seasonality Strength: {seasonality_strength}\")\n",
    "            \n",
    "            # Monthly analysis (identify peak and trough)\n",
    "            monthly = self.df.groupby(self.df['month'].dt.month)[col].mean()\n",
    "            peak_month = monthly.idxmax()\n",
    "            trough_month = monthly.idxmin()\n",
    "            \n",
    "            month_names = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',\n",
    "                          7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "            \n",
    "            peak_trough_ratio = (monthly[peak_month] / monthly[trough_month] - 1) * 100\n",
    "            \n",
    "            print(f\"   Peak month: {month_names[peak_month]} ({monthly[peak_month]:,.0f} units)\")\n",
    "            print(f\"   Trough month: {month_names[trough_month]} ({monthly[trough_month]:,.0f} units)\")\n",
    "            print(f\"   Peak-to-trough range: {peak_trough_ratio:.1f}%\")\n",
    "            \n",
    "            # Coefficient of variation (measure of seasonality)\n",
    "            cv = (quarterly['mean'].std() / quarterly['mean'].mean()) * 100\n",
    "            print(f\"   Coefficient of Variation: {cv:.1f}%\")\n",
    "            \n",
    "            seasonality_results[brand] = {\n",
    "                'quarterly_mean': quarterly['mean'].to_dict(),\n",
    "                'q4_premium': q4_premium,\n",
    "                'seasonality_strength': seasonality_strength,\n",
    "                'peak_month': peak_month,\n",
    "                'trough_month': trough_month,\n",
    "                'peak_trough_ratio': peak_trough_ratio,\n",
    "                'coefficient_of_variation': cv\n",
    "            }\n",
    "        \n",
    "        self.results['seasonality'] = seasonality_results\n",
    "    \n",
    "    def _print_summary(self):\n",
    "        \"\"\"Print validation summary\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"STATISTICAL VALIDATION SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Stationarity summary\n",
    "        print(\"\\nStationarity Status:\")\n",
    "        for brand, results in self.results['stationarity'].items():\n",
    "            status = \"STATIONARY\" if results['is_stationary'] else \"NON-STATIONARY\"\n",
    "            rec_d = results['recommended_d']\n",
    "            print(f\"   {brand:12s}: {status:15s} | Recommended d={rec_d}\")\n",
    "        \n",
    "        # Outlier summary\n",
    "        print(\"\\nOutlier Summary:\")\n",
    "        for brand, results in self.results['outliers'].items():\n",
    "            count = results['outlier_count']\n",
    "            if count > 0:\n",
    "                print(f\"   {brand:12s}: {count} extreme outliers detected (retained)\")\n",
    "            else:\n",
    "                print(f\"   {brand:12s}: No extreme outliers\")\n",
    "        \n",
    "        # Seasonality summary\n",
    "        print(\"\\nSeasonality Summary:\")\n",
    "        for brand, results in self.results['seasonality'].items():\n",
    "            strength = results['seasonality_strength']\n",
    "            q4_prem = results['q4_premium']\n",
    "            print(f\"   {brand:12s}: {strength:10s} | Q4 Premium: {q4_prem:+.1f}%\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Statistical validation complete\")\n",
    "        print(\"   Results saved for model configuration\")\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "validator = StatisticalValidator(df_modeling, CONF)\n",
    "is_valid, statistical_results = validator.validate_all()\n",
    "\n",
    "# Store results \n",
    "stat_validation_results = statistical_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Essential Feature Engineering\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class EssentialFeatureEngineer:\n",
    "    \"\"\"\n",
    "    Add critical features for production models\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "    \n",
    "    def engineer_all(self) -> pd.DataFrame:\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"ESSENTIAL FEATURE ENGINEERING\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        self.df = self._add_time_index()\n",
    "        self.df = self._add_lag_features()\n",
    "        self.df = self._add_rolling_features()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Total features: {len(self.df.columns)}\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def _add_time_index(self) -> pd.DataFrame:\n",
    "        print(\"\\n[1/3] Time Index (for trend)\")\n",
    "        \n",
    "        df = self.df.copy()\n",
    "        \n",
    "        # Linear time index (0, 1, 2, ...)\n",
    "        df['time_index'] = range(len(df))\n",
    "        \n",
    "        print(f\"   ‚úì Added time_index (captures long-term trend)\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _add_lag_features(self) -> pd.DataFrame:\n",
    "        print(\"\\n[2/3] Lag Features\")\n",
    "        \n",
    "        df = self.df.copy()\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            col = f'{brand}_units'\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Lag 1 month (recent history)\n",
    "            df[f'{brand}_lag1'] = df[col].shift(1)\n",
    "            \n",
    "            # Lag 12 months (year-over-year comparison)\n",
    "            df[f'{brand}_lag12'] = df[col].shift(12)\n",
    "            \n",
    "            print(f\"   ‚úì {brand}: lag1, lag12\")\n",
    "        \n",
    "        print(f\"   ‚úì Added 8 lag features (2 per brand)\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _add_rolling_features(self) -> pd.DataFrame:\n",
    "        print(\"\\n[3/3] Rolling Statistics\")\n",
    "        \n",
    "        df = self.df.copy()\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            col = f'{brand}_units'\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            # 3-month moving average (short-term trend)\n",
    "            df[f'{brand}_ma3'] = df[col].rolling(3, min_periods=1).mean()\n",
    "            \n",
    "            # 12-month moving average (annual trend)\n",
    "            df[f'{brand}_ma12'] = df[col].rolling(12, min_periods=1).mean()\n",
    "            \n",
    "            print(f\"   ‚úì {brand}: ma3, ma12\")\n",
    "        \n",
    "        print(f\"   ‚úì Added 8 rolling features (2 per brand)\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "engineer = EssentialFeatureEngineer(df_modeling)\n",
    "df_features = engineer.engineer_all()\n",
    "\n",
    "# Handle NaN from lags (first 12 rows will have NaN in lag12)\n",
    "print(f\"\\nBefore dropna: {len(df_features)} rows\")\n",
    "df_features = df_features.dropna()\n",
    "print(f\"After dropna: {len(df_features)} rows\")\n",
    "\n",
    "print(f\"\\n‚úÖ Feature engineering complete\")\n",
    "print(f\"Final columns: {list(df_features.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRANSFORMATION HELPERS (For Log-Transform + Split-then-Scale)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Log-transform + Split-then-Scale pattern for all 8 models\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def transform_target(y):\n",
    "    \"\"\"\n",
    "    Log-transform target\n",
    "    \"\"\"\n",
    "    return np.log1p(y)\n",
    "\n",
    "\n",
    "def inverse_transform_target(y_log):\n",
    "    \"\"\"\n",
    "    Inverse log-transform\n",
    "    \"\"\"\n",
    "    return np.clip(np.expm1(y_log), 0, None)\n",
    "\n",
    "\n",
    "def scale_data_split(X_train, X_test, y_train_log, y_test_log):\n",
    "    \"\"\"\n",
    "    Scale features and target AFTER split (prevents leakage)\n",
    "    \"\"\"\n",
    "    # Fit scalers on TRAIN only\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    \n",
    "    # Transform train\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train_log.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    # Transform test (using TRAIN scaler)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    y_test_scaled = scaler_y.transform(y_test_log.reshape(-1, 1)).ravel()\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_X, scaler_y\n",
    "\n",
    "\n",
    "def inverse_scale_predictions(y_scaled, scaler_y):\n",
    "    \"\"\"\n",
    "    Inverse scale predictions \n",
    "    \"\"\"\n",
    "    return scaler_y.inverse_transform(y_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "print(\"‚úÖ Transformation helpers loaded (log + split-then-scale)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f87c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Train/Test Split for Validation\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Brand-Specific Data Start Dates                      \n",
    "# Filters regime changes and pre-era noise for cleaner training  \n",
    "# ------------------------------------------------\n",
    "\n",
    "# START DATES (Based on Product Line Changes):\n",
    "BRAND_START_DATES = {\n",
    "    'Apple': '2011-01-01',    # Keep full history\n",
    "                              # Reasoning: iPhone 4S (Oct 2011) onwards - consistent product line\n",
    "                              # All iPhones follow same premium positioning\n",
    "    \n",
    "    'Samsung': '2011-01-01',  # Keep full history  \n",
    "                              # Reasoning: Galaxy S2 era onwards - flagship strategy consistent\n",
    "                              # S-series + Note/Fold dual strategy maintained throughout\n",
    "    \n",
    "    'Google': '2016-10-01',   # ‚Üê CRITICAL: Pixel 1 launch (October 2016)\n",
    "                              # Reasoning: Nexus era (2011-2016) was fundamentally different:\n",
    "                              #   - Developer phones, not mass market\n",
    "                              #   - Different pricing ($349-$499 vs $699-$999)\n",
    "                              #   - Different distribution (Google Store only vs carriers)\n",
    "                              #   - Inconsistent launch cadence\n",
    "                              # Pixel era has consistent premium strategy\n",
    "    \n",
    "    'Motorola': '2014-01-01'  # ‚Üê Lenovo acquisition era (January 2014)\n",
    "                              # Reasoning: Pre-2014 was Google ownership with erratic strategy\n",
    "                              # Post-2014 Lenovo brought consistent G-series volume strategy\n",
    "                              # G-series (budget/mid-range) became Canada volume driver\n",
    "}\n",
    "\n",
    "def create_train_test_split(df, test_months=12):\n",
    "    \"\"\"\n",
    "    Create train/test split for time series\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"TRAIN/TEST SPLIT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Find split point (last N months = test)\n",
    "    cutoff_date = df['month'].max() - pd.DateOffset(months=test_months-1)\n",
    "    \n",
    "    df_train = df[df['month'] < cutoff_date].copy()\n",
    "    df_test = df[df['month'] >= cutoff_date].copy()\n",
    "    \n",
    "    print(f\"\\nGlobal Train Set:\")\n",
    "    print(f\"  Date range: {df_train['month'].min().date()} to {df_train['month'].max().date()}\")\n",
    "    print(f\"  Months: {len(df_train)}\")\n",
    "    \n",
    "    print(f\"\\nGlobal Test Set:\")\n",
    "    print(f\"  Date range: {df_test['month'].min().date()} to {df_test['month'].max().date()}\")\n",
    "    print(f\"  Months: {len(df_test)}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Split created: {len(df_train)} train, {len(df_test)} test\")\n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # Show brand-specific effective training lengths \n",
    "    # ----------------------------------------------------------------\n",
    "    print(f\"\\nüìä Brand-Specific Training Lengths (after regime filters):\")\n",
    "    print(f\"{'Brand':<12} {'Start Date':<12} {'Train Months':<15} {'Test Months':<12}\")\n",
    "    print(\"‚îÄ\" * 55)\n",
    "    \n",
    "    for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        \n",
    "        # Calculate effective training length\n",
    "        brand_train = df_train[df_train['month'] >= start_date]\n",
    "        brand_test = df_test[df_test['month'] >= start_date]\n",
    "        \n",
    "        print(f\"{brand:<12} {start_date:<12} {len(brand_train):<15} {len(brand_test):<12}\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  Models will apply these filters automatically during training\")\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "# Execute\n",
    "df_train, df_test = create_train_test_split(df_features, test_months=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Baseline Forecast Generation\n",
    "# ================================================================\n",
    "\"\"\"\n",
    "PURPOSE: Establish \"dumb baseline\" forecasts to prove ML adds value\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BASELINE FORECAST GENERATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"Creating simple forecasts to benchmark ML models against\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ================================================================\n",
    "# VALIDATION: Ensure prerequisites exist\n",
    "# ================================================================\n",
    "\n",
    "if 'df_train' not in globals() or 'df_test' not in globals():\n",
    "    raise RuntimeError(\n",
    "        \"‚ùå ERROR: df_train and df_test not found.\\n\"\n",
    "        \"   Action: Run Cell 11 (Train/Test Split) first!\"\n",
    "    )\n",
    "\n",
    "# ================================================================\n",
    "# CONFIGURATION\n",
    "# ================================================================\n",
    "\n",
    "# Define baseline methods\n",
    "BASELINE_METHODS = {\n",
    "    'naive': 'Last month carried forward',\n",
    "    'seasonal_naive': 'Same month last year (SPLY)',\n",
    "    'moving_avg_3': '3-month moving average',\n",
    "    'moving_avg_6': '6-month moving average'\n",
    "}\n",
    "\n",
    "# Brands to forecast\n",
    "BRANDS = CONF.get('TARGET_BRANDS', ['Apple', 'Samsung', 'Google', 'Motorola'])\n",
    "\n",
    "# ================================================================\n",
    "# BASELINE GENERATOR CLASS\n",
    "# ================================================================\n",
    "\n",
    "class BaselineForecaster:\n",
    "    \"\"\"\n",
    "    Generates simple baseline forecasts for benchmarking ML models\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_train, df_test):\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "        self.n_forecast = len(df_test)\n",
    "        \n",
    "        print(f\"\\nInitializing Baseline Forecaster:\")\n",
    "        print(f\"  Training data: {len(df_train)} months\")\n",
    "        print(f\"  Test data: {len(df_test)} months\")\n",
    "        print(f\"  Train period: {df_train['month'].min().date()} to {df_train['month'].max().date()}\")\n",
    "        print(f\"  Test period: {df_test['month'].min().date()} to {df_test['month'].max().date()}\")\n",
    "    \n",
    "    def generate_all_baselines(self, brands):\n",
    "        \"\"\"\n",
    "        Generate all baseline forecasts for all brands\n",
    "        \"\"\"\n",
    "        \n",
    "        baselines = {}\n",
    "        \n",
    "        for brand in brands:\n",
    "            print(f\"\\n{'‚îÄ'*70}\")\n",
    "            print(f\"GENERATING BASELINES: {brand}\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "            \n",
    "            target_col = self._get_target_col(brand)\n",
    "            \n",
    "            if target_col not in self.df_train.columns:\n",
    "                print(f\"  ‚ö†Ô∏è  Column '{target_col}' not found, skipping {brand}\")\n",
    "                continue\n",
    "            \n",
    "            baselines[brand] = {}\n",
    "            \n",
    "            # Generate each baseline method\n",
    "            baselines[brand]['naive'] = self._naive_forecast(target_col)\n",
    "            baselines[brand]['seasonal_naive'] = self._seasonal_naive_forecast(target_col)\n",
    "            baselines[brand]['moving_avg_3'] = self._moving_average_forecast(target_col, window=3)\n",
    "            baselines[brand]['moving_avg_6'] = self._moving_average_forecast(target_col, window=6)\n",
    "            \n",
    "            # Calculate metrics for each baseline\n",
    "            if target_col in self.df_test.columns:\n",
    "                y_test = self.df_test[target_col].values\n",
    "                \n",
    "                print(f\"\\n  Baseline Performance Summary:\")\n",
    "                print(f\"  {'Method':<25} {'MAPE':>8} {'RMSE':>12} {'MAE':>12}\")\n",
    "                print(f\"  {'-'*68}\")\n",
    "                \n",
    "                for method, forecast in baselines[brand].items():\n",
    "                    mape = mean_absolute_percentage_error(y_test, forecast) * 100\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test, forecast))\n",
    "                    mae = np.mean(np.abs(y_test - forecast))\n",
    "                    \n",
    "                    method_display = BASELINE_METHODS.get(method, method)\n",
    "                    print(f\"  {method_display:<25} {mape:>7.2f}% {rmse:>11,.0f} {mae:>11,.0f}\")\n",
    "        \n",
    "        return baselines\n",
    "    \n",
    "    def _naive_forecast(self, target_col):\n",
    "        \"\"\"\n",
    "        Naive forecast: Last value in training set repeated\n",
    "        \"\"\"\n",
    "        \n",
    "        last_value = self.df_train[target_col].iloc[-1]\n",
    "        forecast = np.full(self.n_forecast, last_value)\n",
    "        \n",
    "        print(f\"  ‚úì Naive: Last value = {last_value:,.0f} units\")\n",
    "        \n",
    "        return forecast\n",
    "    \n",
    "    def _seasonal_naive_forecast(self, target_col):\n",
    "        \"\"\"\n",
    "        Seasonal Naive (SPLY): Same month last year\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get last 12 months of training data\n",
    "        train_values = self.df_train[target_col].values\n",
    "        \n",
    "        if len(train_values) >= 12:\n",
    "            last_12_months = train_values[-12:]\n",
    "        else:\n",
    "            # Fallback for brands with < 12 months (shouldn't happen)\n",
    "            print(f\"  ‚ö†Ô∏è  Warning: Only {len(train_values)} months available, using all data\")\n",
    "            last_12_months = np.tile(train_values, 12 // len(train_values) + 1)[:12]\n",
    "        \n",
    "        # Repeat pattern for test period\n",
    "        n_repeats = int(np.ceil(self.n_forecast / 12))\n",
    "        forecast = np.tile(last_12_months, n_repeats)[:self.n_forecast]\n",
    "        \n",
    "        print(f\"  ‚úì Seasonal Naive: Using last 12 months pattern\")\n",
    "        print(f\"    Range: {last_12_months.min():,.0f} - {last_12_months.max():,.0f} units\")\n",
    "        \n",
    "        return forecast\n",
    "    \n",
    "    def _moving_average_forecast(self, target_col, window=3):\n",
    "        \"\"\"\n",
    "        Moving Average: Average of last N months repeated\n",
    "        \"\"\"\n",
    "        \n",
    "        train_values = self.df_train[target_col].values\n",
    "        \n",
    "        if len(train_values) < window:\n",
    "            print(f\"  ‚ö†Ô∏è  Warning: Training data ({len(train_values)} months) < window ({window})\")\n",
    "            window = max(1, len(train_values))  # Use all available data\n",
    "        \n",
    "        ma_value = np.mean(train_values[-window:])\n",
    "        forecast = np.full(self.n_forecast, ma_value)\n",
    "        \n",
    "        print(f\"  ‚úì Moving Average ({window}-month): {ma_value:,.0f} units\")\n",
    "        \n",
    "        return forecast\n",
    "    \n",
    "    def _get_target_col(self, brand):\n",
    "        \"\"\"Auto-detect target column name\"\"\"\n",
    "        col = f'{brand}_units'\n",
    "        return col if col in self.df_train.columns else f'{brand.lower()}_units'\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE BASELINE GENERATION\n",
    "# ================================================================\n",
    "\n",
    "baseline_forecaster = BaselineForecaster(df_train, df_test)\n",
    "baseline_forecasts = baseline_forecaster.generate_all_baselines(BRANDS)\n",
    "\n",
    "# ================================================================\n",
    "# STORE RESULTS IN CONF\n",
    "# ================================================================\n",
    "\n",
    "CONF['BASELINE_FORECASTS'] = baseline_forecasts\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE GENERATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚úÖ Generated {len(baseline_forecasts)} brand baselines\")\n",
    "print(f\"‚úÖ {len(BASELINE_METHODS)} methods per brand\")\n",
    "print(f\"‚úÖ Stored in CONF['BASELINE_FORECASTS']\")\n",
    "print(\"\\nüí° Next: Run Cell 11.6 to evaluate baseline performance\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2291bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Baseline Performance Benchmark\n",
    "# ================================================================\n",
    "\"\"\"\n",
    "PURPOSE: Evaluate and visualize baseline forecast performance\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BASELINE PERFORMANCE BENCHMARK\")\n",
    "print(\"=\"*70)\n",
    "print(\"Establishing the 'floor' that ML models must beat\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ================================================================\n",
    "# VALIDATION: Ensure previous Cell was run\n",
    "# ================================================================\n",
    "\n",
    "if 'BASELINE_FORECASTS' not in CONF:\n",
    "    raise RuntimeError(\n",
    "        \"‚ùå ERROR: BASELINE_FORECASTS not found in CONF.\\n\"\n",
    "        \"   Action: Run Cell: Baseline Generation first!\"\n",
    "    )\n",
    "\n",
    "if 'df_test' not in globals():\n",
    "    raise RuntimeError(\n",
    "        \"‚ùå ERROR: df_test not found.\\n\"\n",
    "        \"   Action: Run Train/Test Split Cell first!\"\n",
    "    )\n",
    "\n",
    "# ================================================================\n",
    "# CONFIGURATION\n",
    "# ================================================================\n",
    "\n",
    "BRANDS = CONF.get('TARGET_BRANDS', ['Apple', 'Samsung', 'Google', 'Motorola'])\n",
    "baseline_forecasts = CONF['BASELINE_FORECASTS']\n",
    "\n",
    "# Thresholds for \"beating baseline\"\n",
    "IMPROVEMENT_THRESHOLDS = {\n",
    "    'strong': 15,      # >15% improvement = clearly better\n",
    "    'good': 5,     # 5-15% improvement = good gain\n",
    "    'needs review': 0  # <5% improvement = needs review\n",
    "}\n",
    "\n",
    "# ================================================================\n",
    "# BASELINE EVALUATOR CLASS\n",
    "# ================================================================\n",
    "\n",
    "class BaselineEvaluator:\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of baseline forecast performance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, baseline_forecasts, df_test):\n",
    "        self.baseline_forecasts = baseline_forecasts\n",
    "        self.df_test = df_test\n",
    "        self.results = {}\n",
    "        self.best_baselines = {}\n",
    "    \n",
    "    def evaluate_all(self):\n",
    "        \"\"\"\n",
    "        Evaluate all baselines and store results\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\nüìä DETAILED BASELINE EVALUATION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for brand in self.baseline_forecasts.keys():\n",
    "            print(f\"\\n{brand}:\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "            \n",
    "            target_col = self._get_target_col(brand)\n",
    "            \n",
    "            if target_col not in self.df_test.columns:\n",
    "                print(f\"  ‚ö†Ô∏è  Test data missing '{target_col}', skipping\")\n",
    "                continue\n",
    "            \n",
    "            y_test = self.df_test[target_col].values\n",
    "            \n",
    "            self.results[brand] = {}\n",
    "            \n",
    "            # Header\n",
    "            print(f\"{'Method':<25} {'MAPE':>8} {'RMSE':>12} {'MAE':>12} {'Status':<12}\")\n",
    "            print(f\"{'-'*72}\")\n",
    "            \n",
    "            # Evaluate each method\n",
    "            method_mapes = {}\n",
    "            \n",
    "            for method, forecast in self.baseline_forecasts[brand].items():\n",
    "                metrics = self._calculate_metrics(y_test, forecast)\n",
    "                self.results[brand][method] = metrics\n",
    "                method_mapes[method] = metrics['mape']\n",
    "                \n",
    "                # Determine status\n",
    "                if metrics['mape'] < 15:\n",
    "                    status = \"‚úÖ Excellent\"\n",
    "                elif metrics['mape'] < 25:\n",
    "                    status = \"‚úì Good\"\n",
    "                elif metrics['mape'] < 35:\n",
    "                    status = \"‚ö†Ô∏è Fair\"\n",
    "                else:\n",
    "                    status = \"‚ùå Poor\"\n",
    "                \n",
    "                # Display name\n",
    "                method_name = {\n",
    "                    'naive': 'Naive (Last Month)',\n",
    "                    'seasonal_naive': 'Seasonal Naive (SPLY)',\n",
    "                    'moving_avg_3': 'Moving Avg (3-month)',\n",
    "                    'moving_avg_6': 'Moving Avg (6-month)'\n",
    "                }.get(method, method)\n",
    "                \n",
    "                print(f\"{method_name:<25} {metrics['mape']:>7.2f}% \"\n",
    "                      f\"{metrics['rmse']:>11,.0f} {metrics['mae']:>11,.0f} {status:<12}\")\n",
    "            \n",
    "            # Identify best baseline\n",
    "            best_method = min(method_mapes, key=method_mapes.get)\n",
    "            best_mape = method_mapes[best_method]\n",
    "            self.best_baselines[brand] = {\n",
    "                'method': best_method,\n",
    "                'mape': best_mape\n",
    "            }\n",
    "            \n",
    "            best_name = {\n",
    "                'naive': 'Naive',\n",
    "                'seasonal_naive': 'SPLY',\n",
    "                'moving_avg_3': 'MA-3',\n",
    "                'moving_avg_6': 'MA-6'\n",
    "            }.get(best_method, best_method)\n",
    "            \n",
    "            print(f\"{'-'*72}\")\n",
    "            print(f\"üèÜ BEST BASELINE: {best_name} ({best_mape:.2f}% MAPE)\")\n",
    "            print(f\"   ‚Üí ML models must beat this to justify complexity\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def _calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"Calculate comprehensive error metrics\"\"\"\n",
    "        \n",
    "        # Handle potential zero values\n",
    "        mask = y_true > 0\n",
    "        y_true_safe = y_true[mask]\n",
    "        y_pred_safe = y_pred[mask]\n",
    "        \n",
    "        if len(y_true_safe) == 0:\n",
    "            return {\n",
    "                'mape': 999.0,\n",
    "                'rmse': 999999.0,\n",
    "                'mae': 999999.0,\n",
    "                'bias': 0.0\n",
    "            }\n",
    "        \n",
    "        mape = mean_absolute_percentage_error(y_true_safe, y_pred_safe) * 100\n",
    "        rmse = np.sqrt(mean_squared_error(y_true_safe, y_pred_safe))\n",
    "        mae = mean_absolute_error(y_true_safe, y_pred_safe)\n",
    "        \n",
    "        # Also calculate bias (mean percentage error)\n",
    "        bias = np.mean((y_pred_safe - y_true_safe) / y_true_safe) * 100\n",
    "        \n",
    "        return {\n",
    "            'mape': mape,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'bias': bias\n",
    "        }\n",
    "    \n",
    "    def create_summary_table(self):\n",
    "        \"\"\"\n",
    "        Create comparison summary table\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"BASELINE SUMMARY: ML TARGET\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nTo justify ML complexity, models should beat these.\")\n",
    "        print(f\"\\n{'Brand':<12} {'Best Method':<20} {'MAPE':>8} {'Target MAPE':>12}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "        \n",
    "        summary_data = []\n",
    "        \n",
    "        for brand in sorted(self.best_baselines.keys()):\n",
    "            best = self.best_baselines[brand]\n",
    "            method_name = {\n",
    "                'naive': 'Naive',\n",
    "                'seasonal_naive': 'SPLY',\n",
    "                'moving_avg_3': 'MA-3',\n",
    "                'moving_avg_6': 'MA-6'\n",
    "            }.get(best['method'], best['method'])\n",
    "            \n",
    "            target_mape = best['mape'] \n",
    "            \n",
    "            print(f\"{brand:<12} {method_name:<20} {best['mape']:>7.2f}% \"\n",
    "                  f\"<{target_mape:>10.2f}%\")\n",
    "            \n",
    "            summary_data.append({\n",
    "                'Brand': brand,\n",
    "                'Best_Method': best['method'],\n",
    "                'Best_MAPE': best['mape'],\n",
    "                'ML_Target': target_mape\n",
    "            })\n",
    "        \n",
    "        print(f\"{'-'*70}\")\n",
    "        \n",
    "        # Calculate average\n",
    "        avg_best = np.mean([b['mape'] for b in self.best_baselines.values()])\n",
    "        avg_target = avg_best \n",
    "        \n",
    "        print(f\"\\n{'AVERAGE':<12} {'':<20} {avg_best:>7.2f}% <{avg_target:>10.2f}%\")\n",
    "        print(\"\\n‚úì These targets stored in CONF['BASELINE_TARGETS']\")\n",
    "        \n",
    "        return pd.DataFrame(summary_data)\n",
    "    \n",
    "    def visualize_comparison(self):\n",
    "        \"\"\"\n",
    "        Create visualization of baseline performance\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\nüìä Generating visualization...\")\n",
    "        \n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            # Prepare data for plotting\n",
    "            plot_data = []\n",
    "            \n",
    "            for brand in self.results.keys():\n",
    "                for method, metrics in self.results[brand].items():\n",
    "                    method_name = {\n",
    "                        'naive': 'Naive',\n",
    "                        'seasonal_naive': 'SPLY',\n",
    "                        'moving_avg_3': 'MA-3',\n",
    "                        'moving_avg_6': 'MA-6'\n",
    "                    }.get(method, method)\n",
    "                    \n",
    "                    plot_data.append({\n",
    "                        'Brand': brand,\n",
    "                        'Method': method_name,\n",
    "                        'MAPE': metrics['mape']\n",
    "                    })\n",
    "            \n",
    "            df_plot = pd.DataFrame(plot_data)\n",
    "            \n",
    "            # Create figure\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            \n",
    "            # Grouped bar chart\n",
    "            brands = sorted(df_plot['Brand'].unique())\n",
    "            methods = ['Naive', 'SPLY', 'MA-3', 'MA-6']\n",
    "            x = np.arange(len(brands))\n",
    "            width = 0.2\n",
    "            \n",
    "            colors = ['#FF6B6B', '#4ECDC4', '#95E1D3', '#FFA07A']\n",
    "            \n",
    "            for i, method in enumerate(methods):\n",
    "                method_data = df_plot[df_plot['Method'] == method]\n",
    "                values = []\n",
    "                for b in brands:\n",
    "                    brand_data = method_data[method_data['Brand'] == b]\n",
    "                    if len(brand_data) > 0:\n",
    "                        values.append(brand_data['MAPE'].values[0])\n",
    "                    else:\n",
    "                        values.append(0)\n",
    "                \n",
    "                ax.bar(x + i*width, values, width, label=method, alpha=0.8, color=colors[i])\n",
    "            \n",
    "            # Formatting\n",
    "            ax.set_xlabel('Brand', fontsize=12, weight='bold')\n",
    "            ax.set_ylabel('MAPE (%)', fontsize=12, weight='bold')\n",
    "            ax.set_title('Baseline Forecast Performance by Brand', fontsize=14, weight='bold')\n",
    "            ax.set_xticks(x + width * 1.5)\n",
    "            ax.set_xticklabels(brands)\n",
    "            ax.legend(title='Method', loc='upper right')\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            ax.axhline(y=20, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('baseline_performance.png', dpi=300, bbox_inches='tight')\n",
    "            print(\"  ‚úì Saved: baseline_performance.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"  ‚ö†Ô∏è  Matplotlib not available - skipping visualization\")\n",
    "            return False\n",
    "    \n",
    "    def _get_target_col(self, brand):\n",
    "        \"\"\"Auto-detect target column name\"\"\"\n",
    "        col = f'{brand}_units'\n",
    "        return col if col in self.df_test.columns else f'{brand.lower()}_units'\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE EVALUATION\n",
    "# ================================================================\n",
    "\n",
    "evaluator = BaselineEvaluator(baseline_forecasts, df_test)\n",
    "\n",
    "# Run evaluation\n",
    "baseline_results = evaluator.evaluate_all()\n",
    "\n",
    "# Create summary\n",
    "summary_df = evaluator.create_summary_table()\n",
    "\n",
    "# Create visualization\n",
    "evaluator.visualize_comparison()\n",
    "\n",
    "# ================================================================\n",
    "# STORE RESULTS \n",
    "# ================================================================\n",
    "\n",
    "# Store detailed results\n",
    "CONF['BASELINE_RESULTS'] = baseline_results\n",
    "\n",
    "# Store best baseline per brand (for ML comparison)\n",
    "CONF['BASELINE_TARGETS'] = {\n",
    "    brand: {\n",
    "        'method': evaluator.best_baselines[brand]['method'],\n",
    "        'mape': evaluator.best_baselines[brand]['mape'],\n",
    "        'target_mape': evaluator.best_baselines[brand]['mape'] \n",
    "    }\n",
    "    for brand in evaluator.best_baselines.keys()\n",
    "}\n",
    "\n",
    "# Calculate overall average target\n",
    "avg_baseline_mape = np.mean([b['mape'] for b in evaluator.best_baselines.values()])\n",
    "CONF['BASELINE_TARGET_AVG'] = avg_baseline_mape\n",
    "\n",
    "# ================================================================\n",
    "# FINAL SUMMARY\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE BENCHMARK COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Key Findings:\")\n",
    "for brand in sorted(evaluator.best_baselines.keys()):\n",
    "    best = evaluator.best_baselines[brand]\n",
    "    method_name = {\n",
    "        'naive': 'Naive',\n",
    "        'seasonal_naive': 'Same Period Last Year',\n",
    "        'moving_avg_3': '3-Month Average',\n",
    "        'moving_avg_6': '6-Month Average'\n",
    "    }.get(best['method'], best['method'])\n",
    "    \n",
    "    print(f\"  {brand:>10}: Best = {method_name} ({best['mape']:.2f}% MAPE)\")\n",
    "\n",
    "# Calculate what \"beating baseline\" means\n",
    "avg_baseline = np.mean([b['mape'] for b in evaluator.best_baselines.values()])\n",
    "\n",
    "print(f\"\\nüéØ ML Target Performance:\")\n",
    "print(f\"  Average best baseline: {avg_baseline:.2f}% MAPE\")\n",
    "\n",
    "print(f\"\\n‚úÖ Results stored in:\")\n",
    "print(f\"  - CONF['BASELINE_RESULTS']: Detailed metrics\")\n",
    "print(f\"  - CONF['BASELINE_TARGETS']: Targets for ML comparison\")\n",
    "print(f\"  - CONF['BASELINE_TARGET_AVG']: Overall average ({avg_baseline:.2f}%)\")\n",
    "\n",
    "print(\"\\nüí° Next Step: Comparison Cell will compare ML models against these baselines\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ML Training 1: SARIMAX with Optuna \n",
    "# ================================================================\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Check if already trained\n",
    "SARIMAX_CACHE_FILE = 'sarimax_results.pkl'\n",
    "run_training = True \n",
    "\n",
    "if os.path.exists(SARIMAX_CACHE_FILE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING CACHED SARIMAX RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    with open(SARIMAX_CACHE_FILE, 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    sarimax_cv_results = cached['cv_results']\n",
    "    sarimax_holdout_results = cached['holdout_results']\n",
    "    sarimax_best_params = cached['best_params']\n",
    "    sarimax_trained_models = cached['trained_models']\n",
    "    run_training = False\n",
    "    print(\"‚úÖ Loaded cached SARIMAX results\")\n",
    "    print(\"To retrain, delete:\", SARIMAX_CACHE_FILE)\n",
    "else:\n",
    "    print(\"No cache found - training SARIMAX from scratch...\")\n",
    "\n",
    "class SARIMAXOptimizer:\n",
    "    \"\"\"\n",
    "    SARIMAX with Optuna-based hyperparameter optimization\n",
    "    Uses df_train for walk-forward CV, df_test for final validation\n",
    "    \n",
    "    ARCHITECTURE:\n",
    "    - Log-transformed targets \n",
    "    - Scaled exogenous variables \n",
    "    - Brand-specific regime filtering \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_train, df_test, stat_results):\n",
    "        self.df_train = df_train  # Train set for CV\n",
    "        self.df_test = df_test    # Holdout test set\n",
    "        self.stat_results = stat_results\n",
    "        self.cv_results = {}      # Walk-forward CV results\n",
    "        self.holdout_results = {} # Final holdout results\n",
    "        self.best_params = {}\n",
    "        self.best_models = {}\n",
    "        self.scalers = {}         # Store scalers for exog variables\n",
    "    \n",
    "    def optimize_brand(self, brand: str, n_trials: int = 100):\n",
    "        \"\"\"Optimize SARIMAX using walk-forward CV on training data\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"SARIMAX OPTIMIZATION: {brand}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Using Optuna TPE Sampler | {n_trials} trials | Walk-Forward CV\")\n",
    "        \n",
    "        # Get recommended d\n",
    "        recommended_d = self.stat_results['stationarity'][brand]['recommended_d']\n",
    "        print(f\"Stationarity: d={recommended_d}\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # REGIME FILTERING: Apply brand-specific start dates\n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        print(f\"üìÖ Regime: {start_date} ‚Üí {len(df_brand_train)} train months\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # TARGET: Log-transform\n",
    "        # ===========================================================\n",
    "        target_col = f'{brand}_units'\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        y = transform_target(y_raw)  # ‚Üê Log-transform\n",
    "        print(f\"Target: {target_col} ‚Üí log-transformed (range: {y.min():.2f} to {y.max():.2f})\")\n",
    "        \n",
    "        # ===========================================================   \n",
    "        # EXOGENOUS: Scale to prevent solver instability\n",
    "        #  ===========================================================\n",
    "        exog_cols = [\n",
    "            f'launch_{brand.lower()}',\n",
    "            'is_holiday_season',\n",
    "            'is_back_to_school',\n",
    "            'is_black_friday',\n",
    "            'cpi_index'\n",
    "        ]\n",
    "        exog_cols = [c for c in exog_cols if c in df_brand_train.columns]\n",
    "        \n",
    "        if exog_cols:\n",
    "            X_raw = df_brand_train[exog_cols].values\n",
    "            # Scale X to prevent L-BFGS-B instability\n",
    "            scaler = StandardScaler()\n",
    "            X = scaler.fit_transform(X_raw)\n",
    "            self.scalers[brand] = scaler  # Save for holdout/production\n",
    "            print(f\"Exogenous variables: {exog_cols} (scaled)\")\n",
    "        else:\n",
    "            X = None\n",
    "            self.scalers[brand] = None\n",
    "            print(f\"Exogenous variables: None\")\n",
    "        \n",
    "        # Create walk-forward splits \n",
    "        splits = self._create_walk_forward_splits(len(y))\n",
    "        print(f\"Walk-forward CV: {len(splits)} folds on training data\")\n",
    "        \n",
    "        # Store for objective function\n",
    "        self.current_brand = brand\n",
    "        self.current_y = y  # Log-transformed\n",
    "        self.current_X = X  # Scaled\n",
    "        self.current_splits = splits\n",
    "        self.current_d = recommended_d\n",
    "        self.current_exog_cols = exog_cols\n",
    "        self.current_target_col = target_col\n",
    "        \n",
    "        # Create Optuna study\n",
    "        study = optuna.create_study(\n",
    "            direction='minimize',\n",
    "            sampler=TPESampler(seed=42),\n",
    "            study_name=f'SARIMAX_{brand}'\n",
    "        )\n",
    "        \n",
    "        # Optimize\n",
    "        print(f\"\\nüöÄ Starting optimization (Log-Target + Scaled-Exog)...\")\n",
    "        study.optimize(\n",
    "            self._objective_sarimax,\n",
    "            n_trials=n_trials,\n",
    "            show_progress_bar=True,\n",
    "            callbacks=[self._optuna_callback]\n",
    "        )\n",
    "        \n",
    "        # Get best results\n",
    "        best_params = study.best_params\n",
    "        best_cv_mape = study.best_value\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"WALK-FORWARD CV COMPLETE\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        print(f\"Best CV MAPE: {best_cv_mape:.2f}%\")\n",
    "        print(f\"Best parameters:\")\n",
    "        for param, value in best_params.items():\n",
    "            print(f\"  {param}: {value}\")\n",
    "        \n",
    "        # Convert to SARIMAX format\n",
    "        order, seasonal_order = self._params_to_sarimax_format(best_params, recommended_d)\n",
    "        \n",
    "        # Evaluate on CV folds with detailed metrics\n",
    "        cv_metrics = self._evaluate_best_params_cv(\n",
    "            brand, order, seasonal_order, splits, exog_cols\n",
    "        )\n",
    "        \n",
    "        # Store CV results\n",
    "        self.cv_results[brand] = cv_metrics\n",
    "        self.best_params[brand] = {\n",
    "            'order': order,\n",
    "            'seasonal_order': seasonal_order,\n",
    "            'exog_cols': exog_cols\n",
    "        }\n",
    "        \n",
    "        # Train final model on FULL training data\n",
    "        print(f\"\\nüîß Training final model on full training set...\")\n",
    "        final_model = SARIMAX(\n",
    "            y,  # Log-transformed\n",
    "            exog=X,  # Scaled\n",
    "            order=order,\n",
    "            seasonal_order=seasonal_order,\n",
    "            enforce_stationarity=False,\n",
    "            enforce_invertibility=False\n",
    "        )\n",
    "        final_fit = final_model.fit(disp=False, maxiter=200, method='lbfgs')\n",
    "        self.best_models[brand] = final_fit\n",
    "        \n",
    "        print(f\"‚úì Final model trained on {len(y)} training months\")\n",
    "        \n",
    "        return cv_metrics, order, seasonal_order\n",
    "    \n",
    "    def evaluate_on_holdout(self, brand: str):\n",
    "        \"\"\"Evaluate best model on held-out test set\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"HOLDOUT TEST EVALUATION: {brand}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        # Get best parameters\n",
    "        params = self.best_params[brand]\n",
    "        order = params['order']\n",
    "        seasonal_order = params['seasonal_order']\n",
    "        exog_cols = params['exog_cols']\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Use FULL test set \n",
    "        # ===========================================================\n",
    "        target_col = f'{brand}_units'\n",
    "        y_test_raw = self.df_test[target_col].values\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Use saved scaler to transform test exog\n",
    "        # ===========================================================\n",
    "        if exog_cols and self.scalers[brand] is not None:\n",
    "            X_test_raw = self.df_test[exog_cols].values\n",
    "            X_test = self.scalers[brand].transform(X_test_raw)  # Use fitted scaler\n",
    "        else:\n",
    "            X_test = None\n",
    "        \n",
    "        # Get trained model\n",
    "        model_fit = self.best_models[brand]\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Forecast in log-space, then inverse transform\n",
    "        # ===========================================================\n",
    "        pred_log = model_fit.forecast(steps=len(y_test_raw), exog=X_test)\n",
    "        pred = inverse_transform_target(pred_log)  # ‚Üê Back to original scale\n",
    "        \n",
    "        # Calculate metrics on original scale\n",
    "        mape = mean_absolute_percentage_error(y_test_raw, pred) * 100\n",
    "        rmse = np.sqrt(np.mean((y_test_raw - pred)**2))\n",
    "        mae = np.mean(np.abs(y_test_raw - pred))\n",
    "        \n",
    "        print(f\"Test Set Results:\")\n",
    "        print(f\"  MAPE: {mape:.2f}%\")\n",
    "        print(f\"  RMSE: {rmse:,.0f}\")\n",
    "        print(f\"  MAE: {mae:,.0f}\")\n",
    "        \n",
    "        holdout_metrics = {\n",
    "            'test_mape': mape,\n",
    "            'test_rmse': rmse,\n",
    "            'test_mae': mae,\n",
    "            'predictions': pred\n",
    "        }\n",
    "        \n",
    "        self.holdout_results[brand] = holdout_metrics\n",
    "        \n",
    "        return holdout_metrics\n",
    "    \n",
    "    def _objective_sarimax(self, trial):\n",
    "        \"\"\"Optuna objective function\"\"\"\n",
    "        \n",
    "        p = trial.suggest_int('p', 0, 3)\n",
    "        q = trial.suggest_int('q', 0, 3)\n",
    "        P = trial.suggest_int('P', 0, 2)\n",
    "        Q = trial.suggest_int('Q', 0, 2)\n",
    "        \n",
    "        d = self.current_d\n",
    "        D = 1\n",
    "        s = 12\n",
    "        \n",
    "        order = (p, d, q)\n",
    "        seasonal_order = (P, D, Q, s)\n",
    "        \n",
    "        fold_scores = []\n",
    "        \n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                train_idx = split['train']\n",
    "                test_idx = split['test']\n",
    "                \n",
    "                # Work in log-space with scaled exog\n",
    "                y_train_log = self.current_y[train_idx]\n",
    "                y_test_log = self.current_y[test_idx]\n",
    "                \n",
    "                X_train = self.current_X[train_idx] if self.current_X is not None else None\n",
    "                X_test = self.current_X[test_idx] if self.current_X is not None else None\n",
    "                \n",
    "                model = SARIMAX(\n",
    "                    y_train_log,  # Log-transformed\n",
    "                    exog=X_train,  # Scaled\n",
    "                    order=order,\n",
    "                    seasonal_order=seasonal_order,\n",
    "                    enforce_stationarity=False,\n",
    "                    enforce_invertibility=False\n",
    "                )\n",
    "                \n",
    "                fit = model.fit(disp=False, maxiter=100, method='lbfgs')\n",
    "                pred_log = fit.forecast(steps=len(test_idx), exog=X_test)\n",
    "                \n",
    "                # Inverse transform for MAPE calculation\n",
    "                pred = inverse_transform_target(pred_log)\n",
    "                y_test_original = inverse_transform_target(y_test_log)\n",
    "                \n",
    "                mape = mean_absolute_percentage_error(y_test_original, pred) * 100\n",
    "                fold_scores.append(mape)\n",
    "                \n",
    "            except:\n",
    "                fold_scores.append(999.0)\n",
    "        \n",
    "        return np.mean(fold_scores)\n",
    "    \n",
    "    def _optuna_callback(self, study, trial):\n",
    "        \"\"\"Progress callback (Crash-proof)\"\"\"\n",
    "        if trial.number % 10 == 0:\n",
    "            val = trial.value\n",
    "            best = study.best_value\n",
    "            \n",
    "            val_str = f\"{val:.2f}%\" if val is not None else \"Failed\"\n",
    "            best_str = f\"{best:.2f}%\" if best is not None else \"N/A\"\n",
    "            \n",
    "            print(f\"  Trial {trial.number}: MAPE = {val_str} | Best: {best_str}\")\n",
    "    \n",
    "    def _params_to_sarimax_format(self, params, d):\n",
    "        \"\"\"Convert Optuna params to SARIMAX format\"\"\"\n",
    "        order = (params['p'], d, params['q'])\n",
    "        seasonal_order = (params['P'], 1, params['Q'], 12)\n",
    "        return order, seasonal_order\n",
    "    \n",
    "    def _create_walk_forward_splits(self, n_samples: int):\n",
    "        \"\"\"\n",
    "        Anchored walk-forward CV ending at most recent training data\n",
    "        \n",
    "        Design:\n",
    "        - Last fold ALWAYS tests the most recent 12 months\n",
    "        - Expanding window (training grows chronologically)\n",
    "        - Non-overlapping 12-month test sets\n",
    "        - Auto-adjusts fold count if insufficient data\n",
    "        \"\"\"\n",
    "        test_size = 12  # Full seasonal cycle\n",
    "        n_folds = 5\n",
    "        min_train = 60  # 5 years minimum for SARIMAX seasonal\n",
    "        \n",
    "        # Anchor: last test set ends at most recent data\n",
    "        last_test_end = n_samples\n",
    "        last_test_start = last_test_end - test_size\n",
    "        \n",
    "        # Calculate where first fold would start\n",
    "        first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        # Safety: ensure minimum training data\n",
    "        if first_train_end < min_train:\n",
    "            # Reduce folds to fit\n",
    "            max_possible_folds = (last_test_start - min_train) // test_size + 1\n",
    "            n_folds = max(2, int(max_possible_folds))\n",
    "            first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "            print(f\"  ‚ö†Ô∏è Reduced to {n_folds} folds (insufficient data for 5)\")\n",
    "        \n",
    "        # Build splits chronologically\n",
    "        splits = []\n",
    "        for i in range(n_folds):\n",
    "            train_end = first_train_end + (i * test_size)\n",
    "            test_start = train_end\n",
    "            test_end = test_start + test_size\n",
    "            \n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "            \n",
    "            # Validate\n",
    "            if train_end < min_train:\n",
    "                print(f\"  ‚ö†Ô∏è Skipping fold {i+1}: insufficient training data ({train_end} < {min_train})\")\n",
    "                continue\n",
    "            \n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(test_start, test_end))\n",
    "            })\n",
    "        \n",
    "        if not splits:\n",
    "            # Emergency fallback: single split\n",
    "            print(f\"  ‚ö†Ô∏è Emergency fallback: using single train/test split\")\n",
    "            train_end = max(min_train, n_samples - test_size)\n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(train_end, n_samples))\n",
    "            })\n",
    "        \n",
    "        return splits\n",
    "    \n",
    "    def _evaluate_best_params_cv(self, brand, order, seasonal_order, splits, exog_cols):\n",
    "        \"\"\"Evaluate best parameters on CV folds\"\"\"\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Apply regime filter to match optimize_brand()\n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        \n",
    "        target_col = f'{brand}_units'\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        y_log = transform_target(y_raw)  # Log-transform\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Use fitted scaler for exog variables\n",
    "        # ===========================================================\n",
    "        if exog_cols and self.scalers[brand] is not None:\n",
    "            X_raw = df_brand_train[exog_cols].values\n",
    "            X = self.scalers[brand].transform(X_raw)  # Use fitted scaler\n",
    "        else:\n",
    "            X = None\n",
    "        \n",
    "        mape_scores = []\n",
    "        rmse_scores = []\n",
    "        mae_scores = []\n",
    "        \n",
    "        print(f\"\\nEvaluating on {len(splits)} CV folds...\")\n",
    "        \n",
    "        for i, split in enumerate(splits):\n",
    "            train_idx = split['train']\n",
    "            test_idx = split['test']\n",
    "            \n",
    "            # Train on log, evaluate on original scale\n",
    "            y_train_log = y_log[train_idx]\n",
    "            y_test_log = y_log[test_idx]\n",
    "            y_test_raw = y_raw[test_idx]  # For metrics\n",
    "            \n",
    "            X_train = X[train_idx] if X is not None else None\n",
    "            X_test = X[test_idx] if X is not None else None\n",
    "            \n",
    "            model = SARIMAX(\n",
    "                y_train_log,  # Log-transformed\n",
    "                exog=X_train,  # Scaled\n",
    "                order=order,\n",
    "                seasonal_order=seasonal_order,\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            \n",
    "            fit = model.fit(disp=False, maxiter=200, method='lbfgs')\n",
    "            pred_log = fit.forecast(steps=len(test_idx), exog=X_test)\n",
    "            pred = inverse_transform_target(pred_log)  # Back to original\n",
    "            \n",
    "            # Calculate metrics on original scale\n",
    "            mape = mean_absolute_percentage_error(y_test_raw, pred) * 100\n",
    "            rmse = np.sqrt(np.mean((y_test_raw - pred)**2))\n",
    "            mae = np.mean(np.abs(y_test_raw - pred))\n",
    "            \n",
    "            mape_scores.append(mape)\n",
    "            rmse_scores.append(rmse)\n",
    "            mae_scores.append(mae)\n",
    "            \n",
    "            print(f\"  Fold {i+1}: MAPE={mape:.2f}%, RMSE={rmse:,.0f}\")\n",
    "        \n",
    "        return {\n",
    "            'cv_mape_mean': np.mean(mape_scores),\n",
    "            'cv_mape_std': np.std(mape_scores),\n",
    "            'cv_rmse_mean': np.mean(rmse_scores),\n",
    "            'cv_mae_mean': np.mean(mae_scores),\n",
    "            'fold_scores': mape_scores\n",
    "        }\n",
    "    \n",
    "    def optimize_and_evaluate_all(self, n_trials: int = 100):\n",
    "        \"\"\"Optimize all brands and evaluate on holdout\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"SARIMAX: OPTIMIZATION + HOLDOUT EVALUATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Architecture: Log-Transform + Scaled-Exog + Regime-Filter\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        brands = ['Apple', 'Samsung', 'Google', 'Motorola']\n",
    "        \n",
    "        for brand in brands:\n",
    "            # Optimize on training data\n",
    "            self.optimize_brand(brand, n_trials=n_trials)\n",
    "            \n",
    "            # Evaluate on holdout test set\n",
    "            self.evaluate_on_holdout(brand)\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\\n\" + \"=\"*70)\n",
    "        print(\"SARIMAX FINAL RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary = []\n",
    "        for brand in brands:\n",
    "            cv = self.cv_results[brand]\n",
    "            holdout = self.holdout_results[brand]\n",
    "            params = self.best_params[brand]\n",
    "            \n",
    "            summary.append({\n",
    "                'Brand': brand,\n",
    "                'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "                'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "                'Order': str(params['order']),\n",
    "                'Seasonal': str(params['seasonal_order'])\n",
    "            })\n",
    "        \n",
    "        df_summary = pd.DataFrame(summary)\n",
    "        print(\"\\n\" + df_summary.to_string(index=False))\n",
    "        \n",
    "        return self.cv_results, self.holdout_results, self.best_params, self.best_models\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE\n",
    "# ================================================================\n",
    "\n",
    "if run_training:  \n",
    "    print(\"\\n‚è∞ Expected runtime: 20-30 minutes\")\n",
    "\n",
    "    sarimax_optimizer = SARIMAXOptimizer(df_train, df_test, stat_validation_results)\n",
    "\n",
    "    sarimax_cv_results, sarimax_holdout_results, sarimax_best_params, sarimax_trained_models = \\\n",
    "        sarimax_optimizer.optimize_and_evaluate_all(n_trials=50)\n",
    "\n",
    "    print(\"\\n‚úÖ SARIMAX complete\")\n",
    "\n",
    "    # Save results\n",
    "    with open(SARIMAX_CACHE_FILE, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'cv_results': sarimax_cv_results,\n",
    "                'holdout_results': sarimax_holdout_results,\n",
    "                'best_params': sarimax_best_params,\n",
    "                'trained_models': sarimax_trained_models\n",
    "            }, f)\n",
    "    print(f\"\\nüíæ Saved SARIMAX results to {SARIMAX_CACHE_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reconstruct the summary dataframe from the SARIMAX results dictionaries\n",
    "sarimax_summary_list = []\n",
    "\n",
    "for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "    cv = sarimax_cv_results[brand]\n",
    "    holdout = sarimax_holdout_results[brand]\n",
    "    params = sarimax_best_params[brand]\n",
    "    \n",
    "    sarimax_summary_list.append({\n",
    "        'Brand': brand,\n",
    "        'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "        'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "        'Holdout RMSE': f\"{holdout['test_rmse']:,.0f}\",\n",
    "        'Order (p,d,q)': str(params['order']),\n",
    "        'Seasonal (P,D,Q,s)': str(params['seasonal_order'])\n",
    "    })\n",
    "\n",
    "df_sarimax_results = pd.DataFrame(sarimax_summary_list)\n",
    "print(\"SARIMAX Optimization Results:\")\n",
    "display(df_sarimax_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ML Training 2: XGBoost \n",
    "# ================================================================\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Check if already trained\n",
    "XGBOOST_CACHE_FILE = 'xgboost_results.pkl'\n",
    "run_training = True\n",
    "\n",
    "if os.path.exists(XGBOOST_CACHE_FILE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING CACHED XGBOOST RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    with open(XGBOOST_CACHE_FILE, 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    xgboost_cv_results = cached['cv_results']\n",
    "    xgboost_holdout_results = cached['holdout_results']\n",
    "    xgboost_best_params = cached['best_params']\n",
    "    xgboost_trained_models = cached['trained_models']\n",
    "    xgboost_scalers = cached.get('scalers', {})\n",
    "    run_training = False\n",
    "    print(\"‚úÖ Loaded cached XGBoost results\")\n",
    "    print(\"To retrain, delete:\", XGBOOST_CACHE_FILE)\n",
    "else:\n",
    "    print(\"No cache found - training XGBoost from scratch...\")\n",
    "\n",
    "class XGBoostOptimizer:\n",
    "    \"\"\"\n",
    "    XGBoost with Optuna-based hyperparameter optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_train, df_test):\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "        self.cv_results = {}\n",
    "        self.holdout_results = {}\n",
    "        self.best_params = {}\n",
    "        self.best_models = {}\n",
    "        self.scalers = {}  # Store fitted scalers for holdout/production\n",
    "        self.feature_importance = {}\n",
    "    \n",
    "    def optimize_brand(self, brand: str, n_trials: int = 100):\n",
    "        \"\"\"Optimize XGBoost using robust transformation pipeline\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"XGBOOST OPTIMIZATION: {brand}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Using Optuna TPE Sampler | {n_trials} trials | Walk-Forward CV\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 1: REGIME FILTERING\n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        print(f\"üìÖ Regime: {start_date} ‚Üí {len(df_brand_train)} train months\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 2: FEATURE PREPARATION\n",
    "        # ===========================================================\n",
    "        feature_cols = [\n",
    "            f'{brand}_lag1', f'{brand}_lag12', \n",
    "            f'{brand}_ma3', f'{brand}_ma12',\n",
    "            f'launch_{brand.lower()}', 'is_holiday_season', \n",
    "            'is_back_to_school', 'is_black_friday', \n",
    "            'month_num', 'quarter', 'time_index', 'cpi_index'\n",
    "        ]\n",
    "        feature_cols = [c for c in feature_cols if c in df_brand_train.columns]\n",
    "        \n",
    "        # Get RAW Target\n",
    "        target_col = f'{brand}_units'\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 3: LOG-TRANSFORM TARGET\n",
    "        # ===========================================================\n",
    "        y_log = transform_target(y_raw)\n",
    "        print(f\"Target: {target_col} ‚Üí Log-Transformed (Range: {y_log.min():.2f} - {y_log.max():.2f})\")\n",
    "        \n",
    "        # Get Raw Features\n",
    "        X_raw = df_brand_train[feature_cols].values\n",
    "        \n",
    "        # Store for objective\n",
    "        self.current_X = X_raw\n",
    "        self.current_y_log = y_log\n",
    "        self.current_y_raw = y_raw  # For fold evaluation\n",
    "        self.current_feature_cols = feature_cols  # Store for holdout\n",
    "        self.current_splits = self._create_walk_forward_splits(len(y_raw))\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 4: OPTUNA OPTIMIZATION\n",
    "        # ===========================================================\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        \n",
    "        print(f\"üöÄ Starting optimization (Log-Target + Scaled-Features)...\")\n",
    "        study.optimize(\n",
    "            self._objective_xgboost, \n",
    "            n_trials=n_trials, \n",
    "            show_progress_bar=True,\n",
    "            callbacks=[self._optuna_callback]\n",
    "        )\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        print(f\"‚úÖ Best CV MAPE: {study.best_value:.2f}%\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 5: TRAIN FINAL MODEL (On Full Training Set)\n",
    "        # ===========================================================\n",
    "        \n",
    "        # 1. Fit Scaler on Full Training Data\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_raw)\n",
    "        self.scalers[brand] = scaler  # Store for holdout/production\n",
    "        \n",
    "        # 2. Train Model on Scaled X, Log y\n",
    "        print(f\"üîß Training final model on full training set...\")\n",
    "        final_model = xgb.XGBRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "        final_model.fit(X_scaled, y_log)\n",
    "        \n",
    "        self.best_models[brand] = final_model\n",
    "        self.best_params[brand] = best_params\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 6: RE-RUN CV TO CAPTURE STANDARD DEVIATION\n",
    "        # =========================================================== \n",
    "        fold_scores = []\n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                # Reconstruct fold data (Leakage Proof)\n",
    "                X_tr = self.current_X[split['train']]\n",
    "                X_te = self.current_X[split['test']]\n",
    "                y_tr_log = self.current_y_log[split['train']]\n",
    "                y_te_raw = self.current_y_raw[split['test']]\n",
    "                \n",
    "                # Scale\n",
    "                sc = StandardScaler()\n",
    "                X_tr_sc = sc.fit_transform(X_tr)\n",
    "                X_te_sc = sc.transform(X_te)\n",
    "                \n",
    "                # Train & Predict\n",
    "                m = xgb.XGBRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "                m.fit(X_tr_sc, y_tr_log, verbose=False)\n",
    "                \n",
    "                # Inverse Transform\n",
    "                pred_real = inverse_transform_target(m.predict(X_te_sc))\n",
    "                fold_scores.append(mean_absolute_percentage_error(y_te_raw, pred_real) * 100)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        cv_std = np.std(fold_scores) if fold_scores else 0.0\n",
    "\n",
    "        # Store metadata with actual standard deviation\n",
    "        self.cv_results[brand] = {\n",
    "            'cv_mape_mean': study.best_value,\n",
    "            'cv_mape_std': cv_std \n",
    "        }\n",
    "        \n",
    "        # Feature Importance\n",
    "        imp = final_model.feature_importances_\n",
    "        self.feature_importance[brand] = dict(zip(feature_cols, imp))\n",
    "        \n",
    "        print(f\"‚úì Final model trained on {len(y_raw)} training months\")\n",
    "        \n",
    "        return study.best_value, best_params\n",
    "    \n",
    "    def evaluate_on_holdout(self, brand: str):\n",
    "        \"\"\"Evaluate on Holdout Test Set using Fitted Scaler\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"HOLDOUT TEST EVALUATION: {brand}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Use FULL test set (no date filtering)\n",
    "        # ===========================================================\n",
    "        feature_cols = list(self.feature_importance[brand].keys())\n",
    "        target_col = f'{brand}_units'\n",
    "        \n",
    "        X_test_raw = self.df_test[feature_cols].values\n",
    "        y_test_raw = self.df_test[target_col].values\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Use saved scaler\n",
    "        # ===========================================================\n",
    "        scaler = self.scalers[brand]\n",
    "        X_test_scaled = scaler.transform(X_test_raw)\n",
    "        \n",
    "        # Predict (Log Space)\n",
    "        model = self.best_models[brand]\n",
    "        pred_log = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Inverse Transform\n",
    "        pred_real = inverse_transform_target(pred_log)\n",
    "        \n",
    "        # Metrics\n",
    "        mape = mean_absolute_percentage_error(y_test_raw, pred_real) * 100\n",
    "        rmse = np.sqrt(np.mean((y_test_raw - pred_real)**2))\n",
    "        r2 = 1 - (np.sum((y_test_raw - pred_real)**2) / np.sum((y_test_raw - y_test_raw.mean())**2))\n",
    "        \n",
    "        print(f\"Test Results (Real Units):\")\n",
    "        print(f\"  MAPE: {mape:.2f}%\")\n",
    "        print(f\"  RMSE: {rmse:,.0f}\")\n",
    "        print(f\"  R¬≤:   {r2:.4f}\")\n",
    "        \n",
    "        self.holdout_results[brand] = {\n",
    "            'test_mape': mape,\n",
    "            'test_rmse': rmse,\n",
    "            'test_r2': r2,\n",
    "            'predictions': pred_real\n",
    "        }\n",
    "        return self.holdout_results[brand]\n",
    "\n",
    "    def _objective_xgboost(self, trial):\n",
    "        \"\"\"Objective with Internal Scaling\"\"\"\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        fold_scores = []\n",
    "        \n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                # Raw Split\n",
    "                X_train_raw = self.current_X[split['train']]\n",
    "                X_test_raw = self.current_X[split['test']]\n",
    "                y_train_log = self.current_y_log[split['train']]\n",
    "                y_test_raw = self.current_y_raw[split['test']]  # For Eval\n",
    "                \n",
    "                # ===========================================================\n",
    "                # INTERNAL SPLIT-THEN-SCALE (Leakage Proof)\n",
    "                # ===========================================================\n",
    "                scaler = StandardScaler()\n",
    "                X_train_sc = scaler.fit_transform(X_train_raw)\n",
    "                X_test_sc = scaler.transform(X_test_raw)\n",
    "                \n",
    "                # Train\n",
    "                model = xgb.XGBRegressor(**params)\n",
    "                model.fit(X_train_sc, y_train_log, verbose=False)\n",
    "                \n",
    "                # Predict\n",
    "                pred_log = model.predict(X_test_sc)\n",
    "                pred_real = inverse_transform_target(pred_log)\n",
    "                \n",
    "                # Score\n",
    "                mape = mean_absolute_percentage_error(y_test_raw, pred_real) * 100\n",
    "                fold_scores.append(mape)\n",
    "            except:\n",
    "                fold_scores.append(999)\n",
    "        \n",
    "        return np.mean(fold_scores) if fold_scores else 999\n",
    "\n",
    "    def _create_walk_forward_splits(self, n_samples: int):\n",
    "        \"\"\"\n",
    "        Anchored walk-forward CV ending at most recent training data\n",
    "        \n",
    "        Design:\n",
    "        - Last fold ALWAYS tests the most recent 12 months\n",
    "        - Expanding window (training grows chronologically)\n",
    "        - Non-overlapping 12-month test sets\n",
    "        - Auto-adjusts fold count if insufficient data\n",
    "        \"\"\"\n",
    "        test_size = 12  # Full seasonal cycle\n",
    "        n_folds = 5\n",
    "        min_train = 60  # 5 years minimum \n",
    "        \n",
    "        # Anchor: last test set ends at most recent data\n",
    "        last_test_end = n_samples\n",
    "        last_test_start = last_test_end - test_size\n",
    "        \n",
    "        # Calculate where first fold would start\n",
    "        first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        # Safety: ensure minimum training data\n",
    "        if first_train_end < min_train:\n",
    "            # Reduce folds to fit\n",
    "            max_possible_folds = (last_test_start - min_train) // test_size + 1\n",
    "            n_folds = max(2, int(max_possible_folds))\n",
    "            first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "            print(f\"  ‚ö†Ô∏è Reduced to {n_folds} folds (insufficient data for 5)\")\n",
    "        \n",
    "        # Build splits chronologically\n",
    "        splits = []\n",
    "        for i in range(n_folds):\n",
    "            train_end = first_train_end + (i * test_size)\n",
    "            test_start = train_end\n",
    "            test_end = test_start + test_size\n",
    "            \n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "            \n",
    "            # Validate\n",
    "            if train_end < min_train:\n",
    "                print(f\"  ‚ö†Ô∏è Skipping fold {i+1}: insufficient training data ({train_end} < {min_train})\")\n",
    "                continue\n",
    "            \n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(test_start, test_end))\n",
    "            })\n",
    "        \n",
    "        if not splits:\n",
    "            # Emergency fallback: single split\n",
    "            print(f\"  ‚ö†Ô∏è Emergency fallback: using single train/test split\")\n",
    "            train_end = max(min_train, n_samples - test_size)\n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(train_end, n_samples))\n",
    "            })\n",
    "        \n",
    "        return splits\n",
    "\n",
    "    def _optuna_callback(self, study, trial):\n",
    "        \"\"\"Progress callback (Crash-proof)\"\"\"\n",
    "        if trial.number % 10 == 0:\n",
    "            val = trial.value\n",
    "            best = study.best_value\n",
    "            \n",
    "            # Safe string formatting handling None\n",
    "            val_str = f\"{val:.2f}%\" if val is not None else \"Failed\"\n",
    "            best_str = f\"{best:.2f}%\" if best is not None else \"N/A\"\n",
    "            \n",
    "            print(f\"  Trial {trial.number}: MAPE = {val_str} | Best: {best_str}\")\n",
    "\n",
    "    def optimize_and_evaluate_all(self, n_trials=100):\n",
    "        \"\"\"Optimize all brands and evaluate on holdout\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"XGBOOST: OPTIMIZATION + HOLDOUT EVALUATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Architecture: Log-Transform + Scaled-Features + Regime-Filter\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            self.optimize_brand(brand, n_trials)\n",
    "            self.evaluate_on_holdout(brand)\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"XGBOOST FINAL RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary = []\n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            cv = self.cv_results[brand]\n",
    "            holdout = self.holdout_results[brand]\n",
    "            \n",
    "            summary.append({\n",
    "                'Brand': brand,\n",
    "                'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "                'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "                'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "                'n_estimators': self.best_params[brand]['n_estimators']\n",
    "            })\n",
    "        \n",
    "        print(\"\\n\" + pd.DataFrame(summary).to_string(index=False))\n",
    "        \n",
    "        return self.cv_results, self.holdout_results, self.best_params, self.best_models\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE\n",
    "# ================================================================\n",
    "if run_training:\n",
    "    print(\"\\n‚è∞ Expected runtime: 10-15 minutes\")\n",
    "    \n",
    "    xgboost_optimizer = XGBoostOptimizer(df_train, df_test)\n",
    "    xgboost_cv_results, xgboost_holdout_results, xgboost_best_params, xgboost_trained_models = \\\n",
    "        xgboost_optimizer.optimize_and_evaluate_all(n_trials=100)\n",
    "    \n",
    "    with open(XGBOOST_CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'cv_results': xgboost_cv_results,\n",
    "            'holdout_results': xgboost_holdout_results,\n",
    "            'best_params': xgboost_best_params,\n",
    "            'trained_models': xgboost_trained_models,\n",
    "            'scalers': xgboost_optimizer.scalers  # Save scalers!\n",
    "        }, f)\n",
    "    print(f\"\\nüíæ Results saved to {XGBOOST_CACHE_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77346aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# Display Summary\n",
    "# ===========================================================\n",
    "\n",
    "# Reconstruct the summary dataframe from the saved results dictionaries\n",
    "summary_list = []\n",
    "\n",
    "for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "    cv = xgboost_cv_results[brand]\n",
    "    holdout = xgboost_holdout_results[brand]\n",
    "    params = xgboost_best_params[brand]\n",
    "    \n",
    "    summary_list.append({\n",
    "        'Brand': brand,\n",
    "        'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "        'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "        'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "        'Best n_estimators': params['n_estimators'],\n",
    "        'Best max_depth': params['max_depth'],\n",
    "        'Best Learning Rate': f\"{params['learning_rate']:.4f}\"\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(summary_list)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6504a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ML Training 3: Multivariate Prophet with Optuna \n",
    "# ================================================================\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress Prophet's verbose output\n",
    "import logging\n",
    "logging.getLogger('prophet').setLevel(logging.WARNING)\n",
    "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Check if already trained\n",
    "PROPHET_CACHE_FILE = 'prophet_results.pkl'\n",
    "run_training = True\n",
    "\n",
    "if os.path.exists(PROPHET_CACHE_FILE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING CACHED PROPHET RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    with open(PROPHET_CACHE_FILE, 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    prophet_cv_results = cached['cv_results']\n",
    "    prophet_holdout_results = cached['holdout_results']\n",
    "    prophet_best_params = cached['best_params']\n",
    "    prophet_trained_models = cached['trained_models']\n",
    "    run_training = False\n",
    "    print(\"‚úÖ Loaded cached Prophet results\")\n",
    "    print(\"To retrain, delete:\", PROPHET_CACHE_FILE)\n",
    "else:\n",
    "    print(\"No cache found - training Prophet from scratch...\")\n",
    "\n",
    "class ProphetOptimizer:\n",
    "    \"\"\"\n",
    "    Prophet with Optuna-based hyperparameter optimization and log-transformed targets\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_train, df_test):\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "        self.cv_results = {}\n",
    "        self.holdout_results = {}\n",
    "        self.best_params = {}\n",
    "        self.best_models = {}\n",
    "    \n",
    "    def optimize_brand(self, brand: str, n_trials: int = 50):\n",
    "        \"\"\"Optimize Prophet with log-transformed targets\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"PROPHET OPTIMIZATION: {brand}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Using Optuna TPE Sampler | {n_trials} trials | Walk-Forward CV\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 1: REGIME FILTERING\n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        print(f\"üìÖ Regime: {start_date} ‚Üí {len(df_brand_train)} train months\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 2: GET RAW TARGET & LOG-TRANSFORM\n",
    "        # ===========================================================\n",
    "        target_col = f'{brand}_units'\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        y_log = transform_target(y_raw)  # Apply np.log1p\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 3: PREPARE PROPHET FORMAT (with log-transformed y)\n",
    "        # ===========================================================\n",
    "        df_prophet = pd.DataFrame({\n",
    "            'ds': df_brand_train['month'],\n",
    "            'y': y_log  # LOG-TRANSFORMED TARGET\n",
    "        })\n",
    "        \n",
    "        # Add regressors (Prophet handles scaling internally)\n",
    "        regressor_cols = []\n",
    "        \n",
    "        # Launch indicator\n",
    "        launch_col = f'launch_{brand.lower()}'\n",
    "        if launch_col in df_brand_train.columns:\n",
    "            df_prophet[launch_col] = df_brand_train[launch_col].values\n",
    "            regressor_cols.append(launch_col)\n",
    "        \n",
    "        # Holiday season\n",
    "        if 'is_holiday_season' in df_brand_train.columns:\n",
    "            df_prophet['is_holiday_season'] = df_brand_train['is_holiday_season'].values\n",
    "            regressor_cols.append('is_holiday_season')\n",
    "        \n",
    "        # Back to school\n",
    "        if 'is_back_to_school' in df_brand_train.columns:\n",
    "            df_prophet['is_back_to_school'] = df_brand_train['is_back_to_school'].values\n",
    "            regressor_cols.append('is_back_to_school')\n",
    "        \n",
    "        # Black Friday\n",
    "        if 'is_black_friday' in df_brand_train.columns:\n",
    "            df_prophet['is_black_friday'] = df_brand_train['is_black_friday'].values\n",
    "            regressor_cols.append('is_black_friday')\n",
    "        \n",
    "        # CPI\n",
    "        if 'cpi_index' in df_brand_train.columns:\n",
    "            df_prophet['cpi_index'] = df_brand_train['cpi_index'].values\n",
    "            regressor_cols.append('cpi_index')\n",
    "        \n",
    "        print(f\"Target: {target_col} ‚Üí Log-Transformed (Range: {y_log.min():.2f} - {y_log.max():.2f})\")\n",
    "        print(f\"Regressors: {regressor_cols}\")\n",
    "        \n",
    "        # Create walk-forward splits\n",
    "        splits = self._create_walk_forward_splits(len(df_prophet))\n",
    "        print(f\"Walk-forward CV: {len(splits)} folds on training data\")\n",
    "        \n",
    "        # Store for objective function\n",
    "        self.current_brand = brand\n",
    "        self.current_df = df_prophet\n",
    "        self.current_y_raw = y_raw  # Store for evaluation\n",
    "        self.current_splits = splits\n",
    "        self.current_regressors = regressor_cols\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 4: OPTUNA OPTIMIZATION\n",
    "        # ===========================================================\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        \n",
    "        print(f\"üöÄ Starting optimization (Log-Target)...\")\n",
    "        \n",
    "        study.optimize(\n",
    "            self._objective_prophet,\n",
    "            n_trials=n_trials,\n",
    "            show_progress_bar=True,\n",
    "            callbacks=[self._optuna_callback]\n",
    "        )\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        print(f\"‚úÖ Best CV MAPE: {study.best_value:.2f}%\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 5: TRAIN FINAL MODEL ON FULL TRAINING DATA\n",
    "        # ===========================================================\n",
    "        print(f\"üîß Training final model on full training set (log-transformed target)...\")\n",
    "        final_model = self._create_prophet_model(best_params, regressor_cols)\n",
    "        final_model.fit(df_prophet)\n",
    "        \n",
    "        self.best_models[brand] = final_model\n",
    "        self.best_params[brand] = {\n",
    "            'hyperparams': best_params,\n",
    "            'regressors': regressor_cols\n",
    "        }\n",
    "\n",
    "        # ===========================================================\n",
    "        # STEP 6: RE-RUN CV TO CAPTURE STANDARD DEVIATION\n",
    "        # ===========================================================\n",
    "        fold_scores = []\n",
    "        for split in splits:\n",
    "            try:\n",
    "                # Prepare data splits\n",
    "                df_train_fold = self.current_df.iloc[split['train']].copy()\n",
    "                df_test_fold = self.current_df.iloc[split['test']].copy()\n",
    "                y_test_raw = self.current_y_raw[split['test']]\n",
    "\n",
    "                # Train with BEST params\n",
    "                m = self._create_prophet_model(best_params, self.current_regressors)\n",
    "                m.fit(df_train_fold)\n",
    "\n",
    "                # Predict\n",
    "                future = df_test_fold[['ds'] + self.current_regressors].copy()\n",
    "                forecast = m.predict(future)\n",
    "                pred_real = inverse_transform_target(forecast['yhat'].values)\n",
    "\n",
    "                # Score\n",
    "                fold_scores.append(mean_absolute_percentage_error(y_test_raw, pred_real) * 100)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        cv_std = np.std(fold_scores) if fold_scores else 0.0\n",
    "\n",
    "        # Store metadata with actual standard deviation\n",
    "        self.cv_results[brand] = {\n",
    "            'cv_mape_mean': study.best_value,\n",
    "            'cv_mape_std': cv_std \n",
    "        }\n",
    "        \n",
    "        print(f\"‚úì Final model trained on {len(df_prophet)} training months\")\n",
    "        \n",
    "        return study.best_value, best_params\n",
    "    \n",
    "    def evaluate_on_holdout(self, brand: str):\n",
    "        \"\"\"Evaluate on holdout test set with inverse transform\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"HOLDOUT TEST EVALUATION: {brand}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Use FULL test set (no date filtering)\n",
    "        # ===========================================================\n",
    "        params = self.best_params[brand]\n",
    "        regressor_cols = params['regressors']\n",
    "        \n",
    "        # ===========================================================\n",
    "        # PREPARE TEST DATA\n",
    "        # ===========================================================\n",
    "        df_test_prophet = pd.DataFrame({'ds': self.df_test['month']})\n",
    "        \n",
    "        # Add regressors\n",
    "        for reg in regressor_cols:\n",
    "            if reg in self.df_test.columns:\n",
    "                df_test_prophet[reg] = self.df_test[reg].values\n",
    "        \n",
    "        # Get actual values (RAW scale)\n",
    "        target_col = f'{brand}_units'\n",
    "        y_test_raw = self.df_test[target_col].values\n",
    "        \n",
    "        # ===========================================================\n",
    "        # PREDICT & INVERSE TRANSFORM\n",
    "        # ===========================================================\n",
    "        model = self.best_models[brand]\n",
    "        forecast = model.predict(df_test_prophet)\n",
    "        pred_log = forecast['yhat'].values\n",
    "        \n",
    "        # Inverse transform to original scale\n",
    "        pred_real = inverse_transform_target(pred_log)\n",
    "        \n",
    "        # ===========================================================\n",
    "        # CALCULATE METRICS (On Original Scale)\n",
    "        # ===========================================================\n",
    "        mape = mean_absolute_percentage_error(y_test_raw, pred_real) * 100\n",
    "        rmse = np.sqrt(np.mean((y_test_raw - pred_real)**2))\n",
    "        mae = np.mean(np.abs(y_test_raw - pred_real))\n",
    "        r2 = 1 - (np.sum((y_test_raw - pred_real)**2) / np.sum((y_test_raw - y_test_raw.mean())**2))\n",
    "        \n",
    "        print(f\"Test Results (Real Units):\")\n",
    "        print(f\"  MAPE: {mape:.2f}%\")\n",
    "        print(f\"  RMSE: {rmse:,.0f}\")\n",
    "        print(f\"  MAE:  {mae:,.0f}\")\n",
    "        print(f\"  R¬≤:   {r2:.4f}\")\n",
    "        \n",
    "        self.holdout_results[brand] = {\n",
    "            'test_mape': mape,\n",
    "            'test_rmse': rmse,\n",
    "            'test_mae': mae,\n",
    "            'test_r2': r2,\n",
    "            'predictions': pred_real\n",
    "        }\n",
    "        \n",
    "        return self.holdout_results[brand]\n",
    "    \n",
    "    def _objective_prophet(self, trial):\n",
    "        \"\"\"Optuna objective with log-transformed targets\"\"\"\n",
    "        \n",
    "        params = {\n",
    "            'changepoint_prior_scale': trial.suggest_float('changepoint_prior_scale', 0.001, 0.5, log=True),\n",
    "            'seasonality_prior_scale': trial.suggest_float('seasonality_prior_scale', 0.01, 10.0, log=True),\n",
    "            'holidays_prior_scale': trial.suggest_float('holidays_prior_scale', 0.01, 10.0, log=True),\n",
    "            'seasonality_mode': trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative']),\n",
    "            'changepoint_range': trial.suggest_float('changepoint_range', 0.8, 0.95)\n",
    "        }\n",
    "        \n",
    "        fold_scores = []\n",
    "        \n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                # Split data (already in log-space)\n",
    "                df_train_fold = self.current_df.iloc[split['train']].copy()\n",
    "                df_test_fold = self.current_df.iloc[split['test']].copy()\n",
    "                \n",
    "                # Get raw y for evaluation\n",
    "                y_test_raw = self.current_y_raw[split['test']]\n",
    "                \n",
    "                # Train model on log-transformed y\n",
    "                model = self._create_prophet_model(params, self.current_regressors)\n",
    "                model.fit(df_train_fold)\n",
    "                \n",
    "                # Prepare future dataframe\n",
    "                future = df_test_fold[['ds'] + self.current_regressors].copy()\n",
    "                \n",
    "                # Predict in log-space\n",
    "                forecast = model.predict(future)\n",
    "                pred_log = forecast['yhat'].values\n",
    "                \n",
    "                # Inverse transform to original scale\n",
    "                pred_real = inverse_transform_target(pred_log)\n",
    "                \n",
    "                # Calculate MAPE on original scale\n",
    "                mape = mean_absolute_percentage_error(y_test_raw, pred_real) * 100\n",
    "                fold_scores.append(mape)\n",
    "                \n",
    "            except:\n",
    "                fold_scores.append(999.0)\n",
    "        \n",
    "        return np.mean(fold_scores) if fold_scores else 999.0\n",
    "    \n",
    "    def _create_prophet_model(self, params, regressor_cols):\n",
    "        \"\"\"Create Prophet model with parameters\"\"\"\n",
    "        \n",
    "        model = Prophet(\n",
    "            changepoint_prior_scale=params['changepoint_prior_scale'],\n",
    "            seasonality_prior_scale=params['seasonality_prior_scale'],\n",
    "            holidays_prior_scale=params['holidays_prior_scale'],\n",
    "            seasonality_mode=params['seasonality_mode'],\n",
    "            changepoint_range=params['changepoint_range'],\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "            interval_width=0.80\n",
    "        )\n",
    "        \n",
    "        # Add regressors\n",
    "        for reg in regressor_cols:\n",
    "            model.add_regressor(reg)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _optuna_callback(self, study, trial):\n",
    "        \"\"\"Progress callback (Crash-proof)\"\"\"\n",
    "        if trial.number % 5 == 0:\n",
    "            val = trial.value\n",
    "            best = study.best_value\n",
    "            \n",
    "            # Safe string formatting handling None\n",
    "            val_str = f\"{val:.2f}%\" if val is not None else \"Failed\"\n",
    "            best_str = f\"{best:.2f}%\" if best is not None else \"N/A\"\n",
    "            \n",
    "            print(f\"  Trial {trial.number}: MAPE = {val_str} | Best: {best_str}\")\n",
    "    \n",
    "    def _create_walk_forward_splits(self, n_samples: int):\n",
    "        \"\"\"\n",
    "        Anchored walk-forward CV ending at most recent training data\n",
    "        \n",
    "        Design:\n",
    "        - Last fold ALWAYS tests the most recent 12 months\n",
    "        - Expanding window (training grows chronologically)\n",
    "        - Non-overlapping 12-month test sets\n",
    "        - Auto-adjusts fold count if insufficient data\n",
    "        \n",
    "        Returns:\n",
    "            List of splits, oldest to newest\n",
    "        \"\"\"\n",
    "        test_size = 12  # Full seasonal cycle\n",
    "        n_folds = 5\n",
    "        min_train = 60  # 5 years minimum for Prophet seasonal\n",
    "        \n",
    "        # Anchor: last test set ends at most recent data\n",
    "        last_test_end = n_samples\n",
    "        last_test_start = last_test_end - test_size\n",
    "        \n",
    "        # Calculate where first fold would start\n",
    "        first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        # Safety: ensure minimum training data\n",
    "        if first_train_end < min_train:\n",
    "            # Reduce folds to fit\n",
    "            max_possible_folds = (last_test_start - min_train) // test_size + 1\n",
    "            n_folds = max(2, int(max_possible_folds))\n",
    "            first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "            print(f\"  ‚ö†Ô∏è Reduced to {n_folds} folds (insufficient data for 5)\")\n",
    "        \n",
    "        # Build splits chronologically\n",
    "        splits = []\n",
    "        for i in range(n_folds):\n",
    "            train_end = first_train_end + (i * test_size)\n",
    "            test_start = train_end\n",
    "            test_end = test_start + test_size\n",
    "            \n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "            \n",
    "            # Validate\n",
    "            if train_end < min_train:\n",
    "                print(f\"  ‚ö†Ô∏è Skipping fold {i+1}: insufficient training data ({train_end} < {min_train})\")\n",
    "                continue\n",
    "            \n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(test_start, test_end))\n",
    "            })\n",
    "        \n",
    "        if not splits:\n",
    "            # Emergency fallback: single split\n",
    "            print(f\"  ‚ö†Ô∏è Emergency fallback: using single train/test split\")\n",
    "            train_end = max(min_train, n_samples - test_size)\n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(train_end, n_samples))\n",
    "            })\n",
    "        \n",
    "        return splits\n",
    "    \n",
    "    def optimize_and_evaluate_all(self, n_trials=50):\n",
    "        \"\"\"Optimize all brands and evaluate on holdout\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"PROPHET: OPTIMIZATION + HOLDOUT EVALUATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Architecture: Log-Transform + Regime-Filter\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            self.optimize_brand(brand, n_trials)\n",
    "            self.evaluate_on_holdout(brand)\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PROPHET FINAL RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary = []\n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            cv = self.cv_results[brand]\n",
    "            holdout = self.holdout_results[brand]\n",
    "            params = self.best_params[brand]['hyperparams']\n",
    "            \n",
    "            summary.append({\n",
    "                'Brand': brand,\n",
    "                'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "                'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "                'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "                'Seasonality': params['seasonality_mode']\n",
    "            })\n",
    "        \n",
    "        print(\"\\n\" + pd.DataFrame(summary).to_string(index=False))\n",
    "        \n",
    "        return self.cv_results, self.holdout_results, self.best_params, self.best_models\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE\n",
    "# ================================================================\n",
    "if run_training:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING PROPHET OPTIMIZATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"‚è∞ Expected runtime: 40-60 minutes (10-15 min per brand)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    prophet_optimizer = ProphetOptimizer(df_train, df_test)\n",
    "    prophet_cv_results, prophet_holdout_results, prophet_best_params, prophet_trained_models = \\\n",
    "        prophet_optimizer.optimize_and_evaluate_all(n_trials=50)\n",
    "    \n",
    "    with open(PROPHET_CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'cv_results': prophet_cv_results,\n",
    "            'holdout_results': prophet_holdout_results,\n",
    "            'best_params': prophet_best_params,\n",
    "            'trained_models': prophet_trained_models\n",
    "        }, f)\n",
    "    print(f\"\\nüíæ Results saved to {PROPHET_CACHE_FILE}\")\n",
    "else:\n",
    "    print(\"\\n‚ö° Skipped training (loaded from cache).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db65ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# Display Summary\n",
    "# ===========================================================\n",
    "\n",
    "# Reconstruct the summary dataframe from the Prophet results dictionaries\n",
    "prophet_summary_list = []\n",
    "\n",
    "for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "    cv = prophet_cv_results[brand]\n",
    "    holdout = prophet_holdout_results[brand]\n",
    "    \n",
    "    # ‚úÖ FIX: Access the nested 'hyperparams' dictionary\n",
    "    # The structure saved in Cell 12C is {'hyperparams': {...}, 'regressors': [...]}\n",
    "    all_params = prophet_best_params[brand]\n",
    "    params = all_params['hyperparams']\n",
    "    \n",
    "    prophet_summary_list.append({\n",
    "        'Brand': brand,\n",
    "        'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "        'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "        'Holdout RMSE': f\"{holdout['test_rmse']:,.0f}\",\n",
    "        'Seasonality Mode': params['seasonality_mode'],\n",
    "        'Changepoint Scale': f\"{params['changepoint_prior_scale']:.4f}\",\n",
    "        'Seasonality Scale': f\"{params['seasonality_prior_scale']:.4f}\"\n",
    "    })\n",
    "\n",
    "df_prophet_results = pd.DataFrame(prophet_summary_list)\n",
    "print(\"Prophet Optimization Results:\")\n",
    "display(df_prophet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4735234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ML Training 4: Prophet Univariate + Optuna\n",
    "# ================================================================\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress Prophet's verbose output\n",
    "import logging\n",
    "logging.getLogger('prophet').setLevel(logging.WARNING)\n",
    "logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Check if already trained\n",
    "PROPHET_UNI_CACHE_FILE = 'prophet_uni_results.pkl'\n",
    "run_training = True\n",
    "\n",
    "if os.path.exists(PROPHET_UNI_CACHE_FILE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING CACHED PROPHET UNIVARIATE RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    with open(PROPHET_UNI_CACHE_FILE, 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    prophet_uni_cv_results = cached['cv_results']\n",
    "    prophet_uni_holdout_results = cached['holdout_results']\n",
    "    prophet_uni_best_params = cached['best_params']\n",
    "    prophet_uni_trained_models = cached['trained_models']\n",
    "    run_training = False\n",
    "    print(\"‚úÖ Loaded cached Prophet Univariate results\")\n",
    "    print(\"To retrain, delete:\", PROPHET_UNI_CACHE_FILE)\n",
    "else:\n",
    "    print(\"No cache found - training Prophet Univariate from scratch...\")\n",
    "\n",
    "class ProphetUnivariateOptimizer:\n",
    "    \"\"\"\n",
    "    Prophet with NO external regressors (pure univariate)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_train, df_test):\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "        self.cv_results = {}\n",
    "        self.holdout_results = {}\n",
    "        self.best_params = {}\n",
    "        self.best_models = {}\n",
    "    \n",
    "    def optimize_brand(self, brand: str, n_trials: int = 50):\n",
    "        \"\"\"Optimize Prophet (univariate) with log-transformed targets\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"PROPHET UNIVARIATE OPTIMIZATION: {brand}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Using Optuna TPE Sampler | {n_trials} trials | Walk-Forward CV\")\n",
    "        print(\"‚ö° NO external regressors - pure time series decomposition\")\n",
    "\n",
    "        # ===========================================================\n",
    "        # REGIME FILTERING: Apply brand-specific start dates\n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        print(f\"üìÖ Regime: {start_date} ‚Üí {len(df_brand_train)} train months\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 1: GET RAW TARGET & LOG-TRANSFORM\n",
    "        # ===========================================================\n",
    "        target_col = f'{brand}_units'\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        y_log = transform_target(y_raw)  # Apply np.log1p\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 2: PREPARE PROPHET FORMAT (ONLY ds and y)\n",
    "        # ===========================================================\n",
    "        df_prophet = pd.DataFrame({\n",
    "            'ds': df_brand_train['month'],\n",
    "            'y': y_log  # LOG-TRANSFORMED TARGET\n",
    "        })\n",
    "        \n",
    "        print(f\"Target: {target_col} ‚Üí Log-Transformed (Range: {y_log.min():.2f} - {y_log.max():.2f})\")\n",
    "        print(f\"Regressors: NONE (univariate approach)\")\n",
    "        \n",
    "        # Create walk-forward splits\n",
    "        splits = self._create_walk_forward_splits(len(df_prophet))\n",
    "        print(f\"Walk-forward CV: {len(splits)} folds on training data\")\n",
    "        \n",
    "        # Store for objective function\n",
    "        self.current_brand = brand\n",
    "        self.current_df = df_prophet\n",
    "        self.current_y_raw = y_raw  # Store for evaluation\n",
    "        self.current_splits = splits\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 3: OPTUNA OPTIMIZATION\n",
    "        # ===========================================================\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        \n",
    "        print(f\"üöÄ Starting optimization (Log-Target)...\")\n",
    "        \n",
    "        study.optimize(\n",
    "            self._objective_prophet,\n",
    "            n_trials=n_trials,\n",
    "            show_progress_bar=True,\n",
    "            callbacks=[self._optuna_callback]\n",
    "        )\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        print(f\"‚úÖ Best CV MAPE: {study.best_value:.2f}%\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 4: TRAIN FINAL MODEL ON FULL TRAINING DATA\n",
    "        # =========================================================== \n",
    "        print(f\"üîß Training final model on full training set (log-transformed target)...\")\n",
    "        final_model = self._create_prophet_model(best_params)\n",
    "        final_model.fit(df_prophet)\n",
    "        \n",
    "        self.best_models[brand] = final_model\n",
    "        self.best_params[brand] = best_params\n",
    "\n",
    "        # ===========================================================\n",
    "        # STEP 5: RE-RUN CV TO CAPTURE STANDARD DEVIATION (Risk Metric)\n",
    "        # ===========================================================\n",
    "        fold_scores = []\n",
    "        for split in splits:\n",
    "            try:\n",
    "                # Prepare data splits\n",
    "                df_train_fold = self.current_df.iloc[split['train']].copy()\n",
    "                df_test_fold = self.current_df.iloc[split['test']].copy()\n",
    "                y_test_raw = self.current_y_raw[split['test']]\n",
    "\n",
    "                # Train with BEST params (Univariate - no regressors)\n",
    "                model = self._create_prophet_model(best_params)\n",
    "                model.fit(df_train_fold)\n",
    "\n",
    "                # Predict (Just dates)\n",
    "                future = df_test_fold[['ds']].copy()\n",
    "                forecast = model.predict(future)\n",
    "                pred_real = inverse_transform_target(forecast['yhat'].values)\n",
    "\n",
    "                # Score\n",
    "                fold_scores.append(mean_absolute_percentage_error(y_test_raw, pred_real) * 100)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        cv_std = np.std(fold_scores) if fold_scores else 0.0\n",
    "\n",
    "        # Store metadata with actual standard deviation\n",
    "        self.cv_results[brand] = {\n",
    "            'cv_mape_mean': study.best_value,\n",
    "            'cv_mape_std': cv_std \n",
    "        }\n",
    "        \n",
    "        print(f\"‚úì Final model trained on {len(df_prophet)} training months\")\n",
    "        \n",
    "        return study.best_value, best_params\n",
    "    \n",
    "    def evaluate_on_holdout(self, brand: str):\n",
    "        \"\"\"Evaluate on holdout test set with inverse transform\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"HOLDOUT TEST EVALUATION: {brand}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Apply regime filter \n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_test = self.df_test[self.df_test['month'] >= start_date].copy()\n",
    "        \n",
    "        # ===========================================================\n",
    "        # PREPARE TEST DATA\n",
    "        # ===========================================================\n",
    "        target_col = f'{brand}_units'\n",
    "        y_test_raw = df_brand_test[target_col].values\n",
    "        \n",
    "        # Create future dataframe (just dates, no regressors)\n",
    "        future = pd.DataFrame({'ds': df_brand_test['month']})\n",
    "        \n",
    "        # ===========================================================\n",
    "        # PREDICT & INVERSE TRANSFORM\n",
    "        # ===========================================================\n",
    "        model = self.best_models[brand]\n",
    "        forecast = model.predict(future)\n",
    "        pred_log = forecast['yhat'].values\n",
    "        \n",
    "        # Inverse transform to original scale\n",
    "        pred_real = inverse_transform_target(pred_log)\n",
    "        \n",
    "        # ===========================================================\n",
    "        # CALCULATE METRICS (On Original Scale)\n",
    "        # =========================================================== \n",
    "        mape = mean_absolute_percentage_error(y_test_raw, pred_real) * 100\n",
    "        rmse = np.sqrt(np.mean((y_test_raw - pred_real)**2))\n",
    "        mae = np.mean(np.abs(y_test_raw - pred_real))\n",
    "        r2 = 1 - (np.sum((y_test_raw - pred_real)**2) / np.sum((y_test_raw - y_test_raw.mean())**2))\n",
    "        \n",
    "        print(f\"Test Results (Real Units):\")\n",
    "        print(f\"  MAPE: {mape:.2f}%\")\n",
    "        print(f\"  RMSE: {rmse:,.0f}\")\n",
    "        print(f\"  MAE:  {mae:,.0f}\")\n",
    "        print(f\"  R¬≤:   {r2:.4f}\")\n",
    "        \n",
    "        self.holdout_results[brand] = {\n",
    "            'test_mape': mape,\n",
    "            'test_rmse': rmse,\n",
    "            'test_mae': mae,\n",
    "            'test_r2': r2,\n",
    "            'predictions': pred_real\n",
    "        }\n",
    "        \n",
    "        return self.holdout_results[brand]\n",
    "    \n",
    "    def _objective_prophet(self, trial):\n",
    "        \"\"\"Optuna objective with log-transformed targets\"\"\"\n",
    "        \n",
    "        params = {\n",
    "            'changepoint_prior_scale': trial.suggest_float('changepoint_prior_scale', 0.001, 0.5, log=True),\n",
    "            'seasonality_prior_scale': trial.suggest_float('seasonality_prior_scale', 0.01, 10.0, log=True),\n",
    "            'seasonality_mode': trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative']),\n",
    "            'changepoint_range': trial.suggest_float('changepoint_range', 0.8, 0.95),\n",
    "            'yearly_seasonality': trial.suggest_categorical('yearly_seasonality', [True, 10, 15, 20]),\n",
    "            'monthly_seasonality': trial.suggest_categorical('monthly_seasonality', [False, True])\n",
    "        }\n",
    "        \n",
    "        fold_scores = []\n",
    "        \n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                # Split data (already in log-space)\n",
    "                df_train_fold = self.current_df.iloc[split['train']].copy()\n",
    "                df_test_fold = self.current_df.iloc[split['test']].copy()\n",
    "                \n",
    "                # Get raw y for evaluation\n",
    "                y_test_raw = self.current_y_raw[split['test']]\n",
    "                \n",
    "                # Train model on log-transformed y\n",
    "                model = self._create_prophet_model(params)\n",
    "                model.fit(df_train_fold)\n",
    "                \n",
    "                # Prepare future dataframe (just dates)\n",
    "                future = df_test_fold[['ds']].copy()\n",
    "                \n",
    "                # Predict in log-space\n",
    "                forecast = model.predict(future)\n",
    "                pred_log = forecast['yhat'].values\n",
    "                \n",
    "                # Inverse transform to original scale\n",
    "                pred_real = inverse_transform_target(pred_log)\n",
    "                \n",
    "                # Calculate MAPE on original scale\n",
    "                mape = mean_absolute_percentage_error(y_test_raw, pred_real) * 100\n",
    "                fold_scores.append(mape)\n",
    "                \n",
    "            except:\n",
    "                fold_scores.append(999.0)\n",
    "        \n",
    "        return np.mean(fold_scores) if fold_scores else 999.0\n",
    "    \n",
    "    def _create_prophet_model(self, params):\n",
    "        \"\"\"Create Prophet model (NO regressors)\"\"\"\n",
    "        \n",
    "        # Handle yearly_seasonality parameter\n",
    "        yearly_seasonality = params['yearly_seasonality']\n",
    "        if yearly_seasonality == True:\n",
    "            yearly_seasonality = 'auto'\n",
    "        \n",
    "        model = Prophet(\n",
    "            changepoint_prior_scale=params['changepoint_prior_scale'],\n",
    "            seasonality_prior_scale=params['seasonality_prior_scale'],\n",
    "            seasonality_mode=params['seasonality_mode'],\n",
    "            changepoint_range=params['changepoint_range'],\n",
    "            yearly_seasonality=yearly_seasonality,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "            interval_width=0.80\n",
    "        )\n",
    "        \n",
    "        # Add monthly seasonality if suggested\n",
    "        if params['monthly_seasonality']:\n",
    "            model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _optuna_callback(self, study, trial):\n",
    "        \"\"\"Progress callback (Crash-proof)\"\"\"\n",
    "        if trial.number % 5 == 0:\n",
    "            val = trial.value\n",
    "            best = study.best_value\n",
    "            \n",
    "            # Safe string formatting handling None\n",
    "            val_str = f\"{val:.2f}%\" if val is not None else \"Failed\"\n",
    "            best_str = f\"{best:.2f}%\" if best is not None else \"N/A\"\n",
    "            \n",
    "            print(f\"  Trial {trial.number}: MAPE = {val_str} | Best: {best_str}\")\n",
    "    \n",
    "    def _create_walk_forward_splits(self, n_samples: int):\n",
    "        \"\"\"\n",
    "        Anchored walk-forward CV ending at most recent training data\n",
    "        \n",
    "        Design:\n",
    "        - Last fold ALWAYS tests the most recent 12 months\n",
    "        - Expanding window (training grows chronologically)\n",
    "        - Non-overlapping 12-month test sets\n",
    "        - Auto-adjusts fold count if insufficient data\n",
    "        \"\"\"\n",
    "        test_size = 12  # Full seasonal cycle\n",
    "        n_folds = 5\n",
    "        min_train = 60  # 5 years minimum \n",
    "        \n",
    "        # Anchor: last test set ends at most recent data\n",
    "        last_test_end = n_samples\n",
    "        last_test_start = last_test_end - test_size\n",
    "        \n",
    "        # Calculate where first fold would start\n",
    "        first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        # Safety: ensure minimum training data\n",
    "        if first_train_end < min_train:\n",
    "            # Reduce folds to fit\n",
    "            max_possible_folds = (last_test_start - min_train) // test_size + 1\n",
    "            n_folds = max(2, int(max_possible_folds))\n",
    "            first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "            print(f\"  ‚ö†Ô∏è Reduced to {n_folds} folds (insufficient data for 5)\")\n",
    "        \n",
    "        # Build splits chronologically\n",
    "        splits = []\n",
    "        for i in range(n_folds):\n",
    "            train_end = first_train_end + (i * test_size)\n",
    "            test_start = train_end\n",
    "            test_end = test_start + test_size\n",
    "            \n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "            \n",
    "            # Validate\n",
    "            if train_end < min_train:\n",
    "                print(f\"  ‚ö†Ô∏è Skipping fold {i+1}: insufficient training data ({train_end} < {min_train})\")\n",
    "                continue\n",
    "            \n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(test_start, test_end))\n",
    "            })\n",
    "        \n",
    "        if not splits:\n",
    "            # Emergency fallback: single split\n",
    "            print(f\"  ‚ö†Ô∏è Emergency fallback: using single train/test split\")\n",
    "            train_end = max(min_train, n_samples - test_size)\n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(train_end, n_samples))\n",
    "            })\n",
    "        \n",
    "        return splits\n",
    "    \n",
    "    def optimize_and_evaluate_all(self, n_trials=50):\n",
    "        \"\"\"Optimize all brands and evaluate on holdout\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"PROPHET UNIVARIATE: OPTIMIZATION + HOLDOUT EVALUATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Architecture: Log-Transform + Regime-Filter + Pure Time Series\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            self.optimize_brand(brand, n_trials)\n",
    "            self.evaluate_on_holdout(brand)\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PROPHET UNIVARIATE FINAL RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary = []\n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            cv = self.cv_results[brand]\n",
    "            holdout = self.holdout_results[brand]\n",
    "            params = self.best_params[brand]\n",
    "            \n",
    "            summary.append({\n",
    "                'Brand': brand,\n",
    "                'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "                'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "                'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "                'Seasonality': params['seasonality_mode']\n",
    "            })\n",
    "        \n",
    "        print(\"\\n\" + pd.DataFrame(summary).to_string(index=False))\n",
    "        \n",
    "        return self.cv_results, self.holdout_results, self.best_params, self.best_models\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE\n",
    "# ================================================================\n",
    "if run_training:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING PROPHET UNIVARIATE OPTIMIZATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"‚è∞ Expected runtime: 40-60 minutes (10-15 min per brand)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    prophet_univariate_optimizer = ProphetUnivariateOptimizer(df_train, df_test)\n",
    "    prophet_uni_cv_results, prophet_uni_holdout_results, prophet_uni_best_params, prophet_uni_trained_models = \\\n",
    "        prophet_univariate_optimizer.optimize_and_evaluate_all(n_trials=50)\n",
    "    \n",
    "    with open(PROPHET_UNI_CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'cv_results': prophet_uni_cv_results,\n",
    "            'holdout_results': prophet_uni_holdout_results,\n",
    "            'best_params': prophet_uni_best_params,\n",
    "            'trained_models': prophet_uni_trained_models\n",
    "        }, f)\n",
    "    print(f\"\\nüíæ Results Saved to {PROPHET_UNI_CACHE_FILE}\")\n",
    "else:\n",
    "    print(\"\\n‚ö° Skipped training (loaded from cache).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# Display Summary\n",
    "# ===========================================================\n",
    "\n",
    "# --- 1. Summary Table ---\n",
    "prophet_uni_summary_list = []\n",
    "\n",
    "for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "    cv = prophet_uni_cv_results[brand]\n",
    "    holdout = prophet_uni_holdout_results[brand]\n",
    "    params = prophet_uni_best_params[brand]\n",
    "    \n",
    "    prophet_uni_summary_list.append({\n",
    "        'Brand': brand,\n",
    "        'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "        'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "        'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "        'Seasonality': params['seasonality_mode'],\n",
    "        'Changepoint': f\"{params['changepoint_prior_scale']:.4f}\",\n",
    "        'Yearly Fourier': str(params['yearly_seasonality'])\n",
    "    })\n",
    "\n",
    "df_prophet_uni_results = pd.DataFrame(prophet_uni_summary_list)\n",
    "print(\"Prophet Univariate Optimization Results:\")\n",
    "display(df_prophet_uni_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafd3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ML Training 5: LightGBM with Optuna + LOG-SCALING (ROBUST)\n",
    "# ================================================================\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Check if already trained\n",
    "LIGHTGBM_CACHE_FILE = 'lightgbm_results.pkl'\n",
    "run_training = True\n",
    "\n",
    "if os.path.exists(LIGHTGBM_CACHE_FILE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING CACHED LIGHTGBM RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    with open(LIGHTGBM_CACHE_FILE, 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    lightgbm_cv_results = cached['cv_results']\n",
    "    lightgbm_holdout_results = cached['holdout_results']\n",
    "    lightgbm_best_params = cached['best_params']\n",
    "    lightgbm_trained_models = cached['trained_models']\n",
    "    lightgbm_scalers = cached.get('scalers', {})\n",
    "    run_training = False\n",
    "    print(\"‚úÖ Loaded cached LightGBM results\")\n",
    "    print(\"To retrain, delete:\", LIGHTGBM_CACHE_FILE)\n",
    "else:\n",
    "    print(\"No cache found - training LightGBM from scratch...\")\n",
    "\n",
    "class LightGBMOptimizer:\n",
    "    \"\"\"\n",
    "    LightGBM with Optuna-based hyperparameter optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_train, df_test):\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "        self.cv_results = {}\n",
    "        self.holdout_results = {}\n",
    "        self.best_params = {}\n",
    "        self.best_models = {}\n",
    "        self.scalers = {}  # Store fitted scalers for holdout/production\n",
    "        self.feature_importance = {}\n",
    "    \n",
    "    def optimize_brand(self, brand: str, n_trials: int = 50):\n",
    "        \"\"\"Optimize LightGBM using robust transformation pipeline\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"LIGHTGBM OPTIMIZATION: {brand}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Using Optuna TPE Sampler | {n_trials} trials | Walk-Forward CV\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 1: REGIME FILTERING\n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        print(f\"üìÖ Regime: {start_date} ‚Üí {len(df_brand_train)} train months\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 2: FEATURE PREPARATION\n",
    "        # ===========================================================\n",
    "        feature_cols = [\n",
    "            f'{brand}_lag1', f'{brand}_lag12', \n",
    "            f'{brand}_ma3', f'{brand}_ma12',\n",
    "            f'launch_{brand.lower()}', 'is_holiday_season', \n",
    "            'is_back_to_school', 'is_black_friday', \n",
    "            'month_num', 'quarter', 'time_index', 'cpi_index'\n",
    "        ]\n",
    "        feature_cols = [c for c in feature_cols if c in df_brand_train.columns]\n",
    "        \n",
    "        # Get RAW Target\n",
    "        target_col = f'{brand}_units'\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 3: LOG-TRANSFORM TARGET\n",
    "        # ===========================================================\n",
    "        y_log = transform_target(y_raw)\n",
    "        print(f\"Target: {target_col} ‚Üí Log-Transformed (Range: {y_log.min():.2f} - {y_log.max():.2f})\")\n",
    "        \n",
    "        # Get Raw Features\n",
    "        X_raw = df_brand_train[feature_cols].values\n",
    "        \n",
    "        # Store for objective\n",
    "        self.current_X = X_raw\n",
    "        self.current_y_log = y_log\n",
    "        self.current_y_raw = y_raw  # For fold evaluation\n",
    "        self.current_feature_cols = feature_cols  # Store for holdout\n",
    "        self.current_splits = self._create_walk_forward_splits(len(y_raw))\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 4: OPTUNA OPTIMIZATION\n",
    "        # ===========================================================\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        \n",
    "        print(f\"üöÄ Starting optimization (Log-Target + Scaled-Features)...\")\n",
    "        study.optimize(\n",
    "            self._objective_lightgbm, \n",
    "            n_trials=n_trials, \n",
    "            show_progress_bar=True,\n",
    "            callbacks=[self._optuna_callback]\n",
    "        )\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        print(f\"‚úÖ Best CV MAPE: {study.best_value:.2f}%\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 5: TRAIN FINAL MODEL (On Full Training Set)\n",
    "        # ===========================================================\n",
    "        \n",
    "        # 1. Fit Scaler on Full Training Data\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_raw)\n",
    "        self.scalers[brand] = scaler  # Store for holdout/production\n",
    "        \n",
    "        # 2. Train Model on Scaled X, Log y\n",
    "        print(f\"üîß Training final model on full training set...\")\n",
    "        final_model = lgb.LGBMRegressor(**best_params, random_state=42, verbose=-1, n_jobs=-1)\n",
    "        final_model.fit(X_scaled, y_log)\n",
    "        \n",
    "        self.best_models[brand] = final_model\n",
    "        self.best_params[brand] = best_params\n",
    "\n",
    "        # ===========================================================\n",
    "        # STEP 6: RE-RUN CV TO CAPTURE STANDARD DEVIATION (Risk Metric)\n",
    "        # ===========================================================\n",
    "        fold_scores = []\n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                # Reconstruct fold data (Leakage Proof)\n",
    "                X_tr = self.current_X[split['train']]\n",
    "                X_te = self.current_X[split['test']]\n",
    "                y_tr_log = self.current_y_log[split['train']]\n",
    "                y_te_raw = self.current_y_raw[split['test']]\n",
    "                \n",
    "                # Scale\n",
    "                sc = StandardScaler()\n",
    "                X_tr_sc = sc.fit_transform(X_tr)\n",
    "                X_te_sc = sc.transform(X_te)\n",
    "                \n",
    "                # Train & Predict\n",
    "                m = lgb.LGBMRegressor(**best_params, random_state=42, verbose=-1, n_jobs=-1)\n",
    "                m.fit(X_tr_sc, y_tr_log)\n",
    "                \n",
    "                # Inverse Transform\n",
    "                pred_real = inverse_transform_target(m.predict(X_te_sc))\n",
    "                fold_scores.append(mean_absolute_percentage_error(y_te_raw, pred_real) * 100)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        cv_std = np.std(fold_scores) if fold_scores else 0.0\n",
    "\n",
    "        # Store metadata with actual standard deviation\n",
    "        self.cv_results[brand] = {\n",
    "            'cv_mape_mean': study.best_value,\n",
    "            'cv_mape_std': cv_std \n",
    "        }\n",
    "        \n",
    "        # Feature Importance\n",
    "        imp = final_model.feature_importances_\n",
    "        self.feature_importance[brand] = dict(zip(feature_cols, imp))\n",
    "        \n",
    "        print(f\"‚úì Final model trained on {len(y_raw)} training months\")\n",
    "        \n",
    "        return study.best_value, best_params\n",
    "    \n",
    "    def evaluate_on_holdout(self, brand: str):\n",
    "        \"\"\"Evaluate on Holdout Test Set using Fitted Scaler\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"HOLDOUT TEST EVALUATION: {brand}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Test set \n",
    "        # ===========================================================\n",
    "        feature_cols = list(self.feature_importance[brand].keys())\n",
    "        target_col = f'{brand}_units'\n",
    "        \n",
    "        X_test_raw = self.df_test[feature_cols].values\n",
    "        y_test_raw = self.df_test[target_col].values\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Use saved scaler\n",
    "        # ===========================================================\n",
    "        scaler = self.scalers[brand]\n",
    "        X_test_scaled = scaler.transform(X_test_raw)\n",
    "        \n",
    "        # Predict (Log Space)\n",
    "        model = self.best_models[brand]\n",
    "        pred_log = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Inverse Transform\n",
    "        pred_real = inverse_transform_target(pred_log)\n",
    "        \n",
    "        # Metrics\n",
    "        mape = mean_absolute_percentage_error(y_test_raw, pred_real) * 100\n",
    "        rmse = np.sqrt(np.mean((y_test_raw - pred_real)**2))\n",
    "        r2 = 1 - (np.sum((y_test_raw - pred_real)**2) / np.sum((y_test_raw - y_test_raw.mean())**2))\n",
    "        \n",
    "        print(f\"Test Results (Real Units):\")\n",
    "        print(f\"  MAPE: {mape:.2f}%\")\n",
    "        print(f\"  RMSE: {rmse:,.0f}\")\n",
    "        print(f\"  R¬≤:   {r2:.4f}\")\n",
    "        \n",
    "        self.holdout_results[brand] = {\n",
    "            'test_mape': mape,\n",
    "            'test_rmse': rmse,\n",
    "            'test_r2': r2,\n",
    "            'predictions': pred_real\n",
    "        }\n",
    "        return self.holdout_results[brand]\n",
    "\n",
    "    def _objective_lightgbm(self, trial):\n",
    "        \"\"\"Objective with Internal Scaling\"\"\"\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "            'random_state': 42,\n",
    "            'verbose': -1,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        fold_scores = []\n",
    "        \n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                # Raw Split\n",
    "                X_train_raw = self.current_X[split['train']]\n",
    "                X_test_raw = self.current_X[split['test']]\n",
    "                y_train_log = self.current_y_log[split['train']]\n",
    "                y_test_raw = self.current_y_raw[split['test']]  # For Eval\n",
    "                \n",
    "                # ===========================================================\n",
    "                # INTERNAL SPLIT-THEN-SCALE (Leakage Proof)\n",
    "                # ===========================================================\n",
    "                scaler = StandardScaler()\n",
    "                X_train_sc = scaler.fit_transform(X_train_raw)\n",
    "                X_test_sc = scaler.transform(X_test_raw)\n",
    "                \n",
    "                # Train\n",
    "                model = lgb.LGBMRegressor(**params)\n",
    "                model.fit(X_train_sc, y_train_log)\n",
    "                \n",
    "                # Predict\n",
    "                pred_log = model.predict(X_test_sc)\n",
    "                pred_real = inverse_transform_target(pred_log)\n",
    "                \n",
    "                # Score\n",
    "                mape = mean_absolute_percentage_error(y_test_raw, pred_real) * 100\n",
    "                fold_scores.append(mape)\n",
    "            except:\n",
    "                fold_scores.append(999)\n",
    "        \n",
    "        return np.mean(fold_scores) if fold_scores else 999\n",
    "\n",
    "    def _create_walk_forward_splits(self, n_samples: int):\n",
    "        \"\"\"\n",
    "        Anchored walk-forward CV ending at most recent training data\n",
    "        \n",
    "        Design:\n",
    "        - Last fold ALWAYS tests the most recent 12 months\n",
    "        - Expanding window (training grows chronologically)\n",
    "        - Non-overlapping 12-month test sets\n",
    "        - Auto-adjusts fold count if insufficient data\n",
    "        \"\"\"\n",
    "        test_size = 12  # Full seasonal cycle\n",
    "        n_folds = 5\n",
    "        min_train = 60  # 5 years minimum for seasonal patterns\n",
    "        \n",
    "        # Anchor: last test set ends at most recent data\n",
    "        last_test_end = n_samples\n",
    "        last_test_start = last_test_end - test_size\n",
    "        \n",
    "        # Calculate where first fold would start\n",
    "        first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        # Safety: ensure minimum training data\n",
    "        if first_train_end < min_train:\n",
    "            # Reduce folds to fit\n",
    "            max_possible_folds = (last_test_start - min_train) // test_size + 1\n",
    "            n_folds = max(2, int(max_possible_folds))\n",
    "            first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "            print(f\"  ‚ö†Ô∏è Reduced to {n_folds} folds (insufficient data for 5)\")\n",
    "        \n",
    "        # Build splits chronologically\n",
    "        splits = []\n",
    "        for i in range(n_folds):\n",
    "            train_end = first_train_end + (i * test_size)\n",
    "            test_start = train_end\n",
    "            test_end = test_start + test_size\n",
    "            \n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "            \n",
    "            # Validate\n",
    "            if train_end < min_train:\n",
    "                print(f\"  ‚ö†Ô∏è Skipping fold {i+1}: insufficient training data ({train_end} < {min_train})\")\n",
    "                continue\n",
    "            \n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(test_start, test_end))\n",
    "            })\n",
    "        \n",
    "        if not splits:\n",
    "            # Emergency fallback: single split\n",
    "            print(f\"  ‚ö†Ô∏è Emergency fallback: using single train/test split\")\n",
    "            train_end = max(min_train, n_samples - test_size)\n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(train_end, n_samples))\n",
    "            })\n",
    "        \n",
    "        return splits\n",
    "\n",
    "    def _optuna_callback(self, study, trial):\n",
    "        \"\"\"Progress callback (Crash-proof)\"\"\"\n",
    "        if trial.number % 10 == 0:\n",
    "            val = trial.value\n",
    "            best = study.best_value\n",
    "            \n",
    "            # Safe string formatting handling None\n",
    "            val_str = f\"{val:.2f}%\" if val is not None else \"Failed\"\n",
    "            best_str = f\"{best:.2f}%\" if best is not None else \"N/A\"\n",
    "            \n",
    "            print(f\"  Trial {trial.number}: MAPE = {val_str} | Best: {best_str}\")\n",
    "\n",
    "    def optimize_and_evaluate_all(self, n_trials=50):\n",
    "        \"\"\"Optimize all brands and evaluate on holdout\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"LIGHTGBM: OPTIMIZATION + HOLDOUT EVALUATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Architecture: Log-Transform + Scaled-Features + Regime-Filter\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            self.optimize_brand(brand, n_trials)\n",
    "            self.evaluate_on_holdout(brand)\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"LIGHTGBM FINAL RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary = []\n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            cv = self.cv_results[brand]\n",
    "            holdout = self.holdout_results[brand]\n",
    "            \n",
    "            summary.append({\n",
    "                'Brand': brand,\n",
    "                'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "                'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "                'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "                'n_estimators': self.best_params[brand]['n_estimators']\n",
    "            })\n",
    "        \n",
    "        print(\"\\n\" + pd.DataFrame(summary).to_string(index=False))\n",
    "        \n",
    "        return self.cv_results, self.holdout_results, self.best_params, self.best_models\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE\n",
    "# ================================================================\n",
    "if run_training:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING LIGHTGBM OPTIMIZATION (LOG-SCALING)\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"‚è∞ Expected runtime: 10-15 minutes (2-4 min per brand)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    lightgbm_optimizer = LightGBMOptimizer(df_train, df_test)\n",
    "    lightgbm_cv_results, lightgbm_holdout_results, lightgbm_best_params, lightgbm_trained_models = \\\n",
    "        lightgbm_optimizer.optimize_and_evaluate_all(n_trials=100)\n",
    "    \n",
    "    with open(LIGHTGBM_CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'cv_results': lightgbm_cv_results,\n",
    "            'holdout_results': lightgbm_holdout_results,\n",
    "            'best_params': lightgbm_best_params,\n",
    "            'trained_models': lightgbm_trained_models,\n",
    "            'scalers': lightgbm_optimizer.scalers  # Save scalers!\n",
    "        }, f)\n",
    "    print(f\"\\nüíæ Results Saved to {LIGHTGBM_CACHE_FILE}\")\n",
    "else:\n",
    "    print(\"\\n‚ö° Skipped training (loaded from cache).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# Display Summary\n",
    "# ===========================================================\n",
    "\n",
    "# --- 1. Summary Table ---\n",
    "lgb_summary_list = []\n",
    "\n",
    "for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "    cv = lightgbm_cv_results[brand]\n",
    "    holdout = lightgbm_holdout_results[brand]\n",
    "    params = lightgbm_best_params[brand]\n",
    "    \n",
    "    lgb_summary_list.append({\n",
    "        'Brand': brand,\n",
    "        'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "        'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "        'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "        'N Estimators': params['n_estimators'],\n",
    "        'Num Leaves': params['num_leaves'],\n",
    "        'Learning Rate': f\"{params['learning_rate']:.4f}\"\n",
    "    })\n",
    "\n",
    "df_lgb_results = pd.DataFrame(lgb_summary_list)\n",
    "print(\"LightGBM Optimization Results:\")\n",
    "display(df_lgb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698dc8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ML Training 6: Gaussian Process with Optuna\n",
    "# ================================================================\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    RBF, Matern, RationalQuadratic, ExpSineSquared, \n",
    "    WhiteKernel, ConstantKernel as C\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if already trained\n",
    "GP_CACHE_FILE = 'gp_results.pkl'\n",
    "run_training = True\n",
    "\n",
    "if os.path.exists(GP_CACHE_FILE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING CACHED GAUSSIAN PROCESS RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    with open(GP_CACHE_FILE, 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    gp_cv_results = cached['cv_results']\n",
    "    gp_holdout_results = cached['holdout_results']\n",
    "    gp_best_params = cached['best_params']\n",
    "    gp_trained_models = cached['trained_models']\n",
    "    gp_scalers = cached['scalers']\n",
    "    run_training = False\n",
    "    print(\"‚úÖ Loaded cached Gaussian Process results\")\n",
    "    print(\"To retrain, delete:\", GP_CACHE_FILE)\n",
    "else:\n",
    "    print(\"No cache found - training Gaussian Process from scratch...\")\n",
    "\n",
    "class GaussianProcessOptimizer:\n",
    "    \"\"\"\n",
    "    Gaussian Process with Optuna-based hyperparameter optimization\n",
    "    CRITICAL: GP needs BOTH X and y scaling (Euclidean distance sensitivity)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_train, df_test):\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "        self.cv_results = {}\n",
    "        self.holdout_results = {}\n",
    "        self.best_params = {}\n",
    "        self.best_models = {}\n",
    "        self.scalers = {}\n",
    "        self.feature_importance = {}\n",
    "    \n",
    "    def optimize_brand(self, brand: str, n_trials: int = 75):\n",
    "        \"\"\"Optimize Gaussian Process using robust transformation pipeline\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"GAUSSIAN PROCESS OPTIMIZATION: {brand}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Using Optuna TPE Sampler | {n_trials} trials | Walk-Forward CV\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 1: REGIME FILTERING\n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        print(f\"üìÖ Regime: {start_date} ‚Üí {len(df_brand_train)} train months\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 2: FEATURE PREPARATION\n",
    "        # ===========================================================\n",
    "        # Auto-Detect Column Name Case\n",
    "        target_col = f'{brand}_units'\n",
    "        if target_col not in df_brand_train.columns:\n",
    "            target_col = f'{brand.lower()}_units'\n",
    "            brand_prefix = brand.lower()\n",
    "        else:\n",
    "            brand_prefix = brand\n",
    "        \n",
    "        # Define Features\n",
    "        feature_cols = [\n",
    "            f'{brand_prefix}_lag1', f'{brand_prefix}_lag12', \n",
    "            f'{brand_prefix}_ma3', f'{brand_prefix}_ma12',\n",
    "            f'launch_{brand.lower()}',\n",
    "            'is_holiday_season', 'is_back_to_school', 'is_black_friday',\n",
    "            'month_num', 'quarter', 'time_index', 'cpi_index'\n",
    "        ]\n",
    "        feature_cols = [c for c in feature_cols if c in df_brand_train.columns]\n",
    "        \n",
    "        print(f\"Target: {target_col}\")\n",
    "        print(f\"Features: {len(feature_cols)} columns\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 3: GET RAW DATA & LOG-TRANSFORM TARGET\n",
    "        # ===========================================================\n",
    "        X_raw = df_brand_train[feature_cols].values\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        \n",
    "        # Log-Transform Target\n",
    "        y_log = transform_target(y_raw)\n",
    "        print(f\"Target Log-Transformed: {y_log.min():.2f} - {y_log.max():.2f}\")\n",
    "        \n",
    "        # Store for objective\n",
    "        self.current_X_raw = X_raw\n",
    "        self.current_y_log = y_log\n",
    "        self.current_y_raw = y_raw\n",
    "        self.current_splits = self._create_walk_forward_splits(len(y_raw))\n",
    "        self.current_feature_cols = feature_cols\n",
    "        self.current_target_col = target_col\n",
    "        \n",
    "        print(f\"Walk-forward CV: {len(self.current_splits)} folds\")\n",
    "        print(f\"‚ö†Ô∏è  GP is O(n¬≥) - expect longer runtime\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 4: OPTUNA OPTIMIZATION\n",
    "        # ===========================================================\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        \n",
    "        print(f\"üöÄ Starting optimization (Log-Target + Double-Scaled)...\")\n",
    "        study.optimize(\n",
    "            self._objective_gp, \n",
    "            n_trials=n_trials, \n",
    "            show_progress_bar=True,\n",
    "            callbacks=[self._optuna_callback]\n",
    "        )\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        print(f\"‚úÖ Best CV MAPE: {study.best_value:.2f}%\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 5: TRAIN FINAL MODEL (On Full Training Set)\n",
    "        # ===========================================================\n",
    "        print(f\"üîß Training final model on full training set...\")\n",
    "        \n",
    "        # Fit scalers on FULL training data\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "        \n",
    "        X_scaled = scaler_X.fit_transform(X_raw)\n",
    "        y_scaled = scaler_y.fit_transform(y_log.reshape(-1, 1)).ravel()\n",
    "        \n",
    "        # Save scalers\n",
    "        self.scalers[brand] = {'X_scaler': scaler_X, 'y_scaler': scaler_y}\n",
    "        \n",
    "        # Train final model \n",
    "        kernel = self._build_kernel(best_params)\n",
    "        final_model = GaussianProcessRegressor(\n",
    "            kernel=kernel, \n",
    "            alpha=best_params['alpha'], \n",
    "            n_restarts_optimizer=10, \n",
    "            normalize_y=False, \n",
    "            random_state=42\n",
    "        )\n",
    "        final_model.fit(X_scaled, y_scaled)\n",
    "        \n",
    "        self.best_models[brand] = final_model\n",
    "        self.best_params[brand] = {\n",
    "            'params': best_params, \n",
    "            'feature_cols': feature_cols, \n",
    "            'target_col': target_col\n",
    "        }\n",
    "\n",
    "        # ===========================================================\n",
    "        # STEP 6: RE-RUN CV TO CAPTURE STANDARD DEVIATION \n",
    "        # ===========================================================\n",
    "        fold_scores = []\n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                # Raw data splits\n",
    "                X_tr = self.current_X_raw[split['train']]\n",
    "                X_te = self.current_X_raw[split['test']]\n",
    "                y_tr_log = self.current_y_log[split['train']]\n",
    "                y_te_raw = self.current_y_raw[split['test']]\n",
    "\n",
    "                # Subsample if large \n",
    "                if len(X_tr) > 1000:\n",
    "                    idx = np.random.choice(len(X_tr), 1000, replace=False)\n",
    "                    X_tr = X_tr[idx]\n",
    "                    y_tr_log = y_tr_log[idx]\n",
    "\n",
    "                # Internal Split-then-Scale (Double Scaling for GP)\n",
    "                sc_X = StandardScaler()\n",
    "                sc_y = StandardScaler()\n",
    "                \n",
    "                X_tr_sc = sc_X.fit_transform(X_tr)\n",
    "                X_te_sc = sc_X.transform(X_te)\n",
    "                y_tr_sc = sc_y.fit_transform(y_tr_log.reshape(-1, 1)).ravel()\n",
    "\n",
    "                # Train GP\n",
    "                k = self._build_kernel(best_params)\n",
    "                m = GaussianProcessRegressor(\n",
    "                    kernel=k, alpha=best_params['alpha'], \n",
    "                    n_restarts_optimizer=0, normalize_y=False, random_state=42\n",
    "                )\n",
    "                m.fit(X_tr_sc, y_tr_sc)\n",
    "\n",
    "                # Predict & Inverse Transform\n",
    "                pred_sc = m.predict(X_te_sc)\n",
    "                pred_log = sc_y.inverse_transform(pred_sc.reshape(-1, 1)).ravel()\n",
    "                pred_real = inverse_transform_target(pred_log)\n",
    "\n",
    "                fold_scores.append(mean_absolute_percentage_error(y_te_raw, pred_real) * 100)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        cv_std = np.std(fold_scores) if fold_scores else 0.0\n",
    "\n",
    "        # Store metadata with actual standard deviation\n",
    "        self.cv_results[brand] = {\n",
    "            'cv_mape_mean': study.best_value,\n",
    "            'cv_mape_std': cv_std \n",
    "        }\n",
    "        \n",
    "        print(f\"‚úì Final model trained on {len(X_scaled)} training months\")\n",
    "        \n",
    "        return study.best_value, best_params\n",
    "    \n",
    "    def evaluate_on_holdout(self, brand: str):\n",
    "        \"\"\"Evaluate on Holdout Test Set using Fitted Scalers\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"HOLDOUT TEST EVALUATION: {brand}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Apply regime filter \n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_test = self.df_test[self.df_test['month'] >= start_date].copy()\n",
    "        \n",
    "        # Retrieve context\n",
    "        params = self.best_params[brand]\n",
    "        feature_cols = params['feature_cols']\n",
    "        target_col = params['target_col']\n",
    "        model = self.best_models[brand]\n",
    "        \n",
    "        # Get RAW test data\n",
    "        X_test_raw = df_brand_test[feature_cols].values\n",
    "        y_test_raw = df_brand_test[target_col].values\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Use SAVED scalers (both X and y)\n",
    "        # ===========================================================\n",
    "        scaler_X = self.scalers[brand]['X_scaler']\n",
    "        scaler_y = self.scalers[brand]['y_scaler']\n",
    "        X_test_scaled = scaler_X.transform(X_test_raw)\n",
    "        \n",
    "        # Predict (returns SCALED y in LOG-space)\n",
    "        y_pred_scaled, y_std_scaled = model.predict(X_test_scaled, return_std=True)\n",
    "        \n",
    "        # Inverse scale (log-space)\n",
    "        y_pred_log = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "        y_std_log = y_std_scaled * scaler_y.scale_[0]\n",
    "        \n",
    "        # Inverse log-transform (original scale)\n",
    "        y_pred_real = inverse_transform_target(y_pred_log)\n",
    "        \n",
    "        # For uncertainty, transform bounds\n",
    "        lower_log = y_pred_log - (1.28 * y_std_log)  # 80% CI\n",
    "        upper_log = y_pred_log + (1.28 * y_std_log)\n",
    "        lower_real = inverse_transform_target(lower_log)\n",
    "        upper_real = inverse_transform_target(upper_log)\n",
    "        y_std_real = (upper_real - lower_real) / 2.56\n",
    "        \n",
    "        # Metrics\n",
    "        mape = mean_absolute_percentage_error(y_test_raw, y_pred_real) * 100\n",
    "        rmse = np.sqrt(np.mean((y_test_raw - y_pred_real)**2))\n",
    "        mae = np.mean(np.abs(y_test_raw - y_pred_real))\n",
    "        r2 = 1 - (np.sum((y_test_raw - y_pred_real)**2) / np.sum((y_test_raw - y_test_raw.mean())**2))\n",
    "        avg_unc = np.mean(y_std_real)\n",
    "        unc_pct = (avg_unc / y_test_raw.mean()) * 100\n",
    "        \n",
    "        print(f\"Test Results (Real Units):\")\n",
    "        print(f\"  MAPE: {mape:.2f}%\")\n",
    "        print(f\"  RMSE: {rmse:,.0f}\")\n",
    "        print(f\"  MAE:  {mae:,.0f}\")\n",
    "        print(f\"  R¬≤:   {r2:.4f}\")\n",
    "        print(f\"  Avg Uncertainty: ¬±{avg_unc:,.0f} ({unc_pct:.1f}%)\")\n",
    "        \n",
    "        self.holdout_results[brand] = {\n",
    "            'test_mape': mape, \n",
    "            'test_rmse': rmse,\n",
    "            'test_mae': mae,\n",
    "            'test_r2': r2, \n",
    "            'avg_uncertainty': avg_unc,\n",
    "            'uncertainty_pct': unc_pct,\n",
    "            'predictions': y_pred_real\n",
    "        }\n",
    "        \n",
    "        return self.holdout_results[brand]\n",
    "    \n",
    "    def _objective_gp(self, trial):\n",
    "        \"\"\"Optuna objective with internal scaling\"\"\"\n",
    "        \n",
    "        kernel_type = trial.suggest_categorical(\n",
    "            'kernel_type', \n",
    "            ['RBF', 'Matern', 'RationalQuadratic', 'RBF+Periodic']\n",
    "        )\n",
    "        length_scale = trial.suggest_float('length_scale', 0.1, 10.0, log=True)\n",
    "        alpha = trial.suggest_float('alpha', 1e-6, 1e-1, log=True)\n",
    "        \n",
    "        k_params = {\n",
    "            'kernel_type': kernel_type, \n",
    "            'length_scale': length_scale, \n",
    "            'alpha': alpha\n",
    "        }\n",
    "        \n",
    "        if kernel_type == 'Matern': \n",
    "            k_params['nu'] = trial.suggest_categorical('nu', [0.5, 1.5, 2.5])\n",
    "        if kernel_type == 'RationalQuadratic': \n",
    "            k_params['rq_alpha'] = trial.suggest_float('rq_alpha', 0.1, 10.0)\n",
    "        if kernel_type == 'RBF+Periodic': \n",
    "            k_params['period'] = trial.suggest_float('period', 10.0, 14.0)\n",
    "        \n",
    "        kernel = self._build_kernel(k_params)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                # Get RAW data for fold\n",
    "                X_train_raw = self.current_X_raw[split['train']]\n",
    "                X_test_raw = self.current_X_raw[split['test']]\n",
    "                y_train_log = self.current_y_log[split['train']]\n",
    "                y_test_raw = self.current_y_raw[split['test']]\n",
    "                \n",
    "                # Subsample if too large (GP is O(n¬≥))\n",
    "                if len(X_train_raw) > 1000:\n",
    "                    idx = np.random.choice(len(X_train_raw), 1000, replace=False)\n",
    "                    X_train_raw = X_train_raw[idx]\n",
    "                    y_train_log = y_train_log[idx]\n",
    "                \n",
    "                # Internal Split-then-Scale (BOTH X and y for GP)\n",
    "                scaler_X = StandardScaler()\n",
    "                scaler_y = StandardScaler()\n",
    "                \n",
    "                X_train_sc = scaler_X.fit_transform(X_train_raw)\n",
    "                X_test_sc = scaler_X.transform(X_test_raw)\n",
    "                y_train_sc = scaler_y.fit_transform(y_train_log.reshape(-1, 1)).ravel()\n",
    "                \n",
    "                # Train GP\n",
    "                model = GaussianProcessRegressor(\n",
    "                    kernel=kernel, \n",
    "                    alpha=alpha, \n",
    "                    n_restarts_optimizer=0,\n",
    "                    normalize_y=False,\n",
    "                    random_state=42\n",
    "                )\n",
    "                model.fit(X_train_sc, y_train_sc)\n",
    "                \n",
    "                # Predict (scaled log-space)\n",
    "                y_pred_sc = model.predict(X_test_sc)\n",
    "                \n",
    "                # Inverse scale (log-space)\n",
    "                y_pred_log = scaler_y.inverse_transform(y_pred_sc.reshape(-1, 1)).ravel()\n",
    "                \n",
    "                # Inverse log-transform (original scale)\n",
    "                y_pred_real = inverse_transform_target(y_pred_log)\n",
    "                \n",
    "                # Calculate MAPE on original scale\n",
    "                mape = mean_absolute_percentage_error(y_test_raw, y_pred_real) * 100\n",
    "                fold_scores.append(mape)\n",
    "                \n",
    "            except:\n",
    "                fold_scores.append(999.0)\n",
    "        \n",
    "        return np.mean(fold_scores) if fold_scores else 999.0\n",
    "    \n",
    "    def _optuna_callback(self, study, trial):\n",
    "        \"\"\"Progress callback (Crash-proof)\"\"\"\n",
    "        if trial.number % 10 == 0:\n",
    "            val = trial.value\n",
    "            best = study.best_value\n",
    "            \n",
    "            # Safe string formatting handling None\n",
    "            val_str = f\"{val:.2f}%\" if val is not None else \"Failed\"\n",
    "            best_str = f\"{best:.2f}%\" if best is not None else \"N/A\"\n",
    "            \n",
    "            print(f\"  Trial {trial.number}: MAPE = {val_str} | Best: {best_str}\")\n",
    "    \n",
    "    def _build_kernel(self, p):\n",
    "        \"\"\"Build kernel from parameters\"\"\"\n",
    "        \n",
    "        base = C(1.0, (1e-3, 1e3))\n",
    "        \n",
    "        if p['kernel_type'] == 'RBF':\n",
    "            k = base * RBF(\n",
    "                length_scale=p['length_scale'],\n",
    "                length_scale_bounds=(1e-2, 1e2)\n",
    "            )\n",
    "        \n",
    "        elif p['kernel_type'] == 'Matern':\n",
    "            k = base * Matern(\n",
    "                length_scale=p['length_scale'], \n",
    "                nu=p['nu'],\n",
    "                length_scale_bounds=(1e-2, 1e2)\n",
    "            )\n",
    "        \n",
    "        elif p['kernel_type'] == 'RationalQuadratic':\n",
    "            k = base * RationalQuadratic(\n",
    "                length_scale=p['length_scale'], \n",
    "                alpha=p['rq_alpha'],\n",
    "                length_scale_bounds=(1e-2, 1e2)\n",
    "            )\n",
    "        \n",
    "        else:  # RBF+Periodic\n",
    "            k = (\n",
    "                base * RBF(\n",
    "                    length_scale=p['length_scale'],\n",
    "                    length_scale_bounds=(1e-2, 1e2)\n",
    "                ) + \n",
    "                base * ExpSineSquared(\n",
    "                    length_scale=1.0, \n",
    "                    periodicity=p['period'],\n",
    "                    length_scale_bounds=(1e-2, 1e2),\n",
    "                    periodicity_bounds=(10.0, 14.0)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        return k + WhiteKernel(\n",
    "            noise_level=p['alpha'],\n",
    "            noise_level_bounds=(1e-8, 1e0)\n",
    "        )\n",
    "    \n",
    "    def _create_walk_forward_splits(self, n_samples: int):\n",
    "        \"\"\"\n",
    "        Anchored walk-forward CV ending at most recent training data\n",
    "        \n",
    "        Design:\n",
    "        - Last fold ALWAYS tests the most recent 12 months\n",
    "        - Expanding window (training grows chronologically)\n",
    "        - Non-overlapping 12-month test sets\n",
    "        - Auto-adjusts fold count if insufficient data\n",
    "        \"\"\"\n",
    "        test_size = 12  # Full seasonal cycle\n",
    "        n_folds = 5\n",
    "        min_train = 60  # 5 years minimum for seasonal patterns\n",
    "        \n",
    "        # Anchor: last test set ends at most recent data\n",
    "        last_test_end = n_samples\n",
    "        last_test_start = last_test_end - test_size\n",
    "        \n",
    "        # Calculate where first fold would start\n",
    "        first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        # Safety: ensure minimum training data\n",
    "        if first_train_end < min_train:\n",
    "            # Reduce folds to fit\n",
    "            max_possible_folds = (last_test_start - min_train) // test_size + 1\n",
    "            n_folds = max(2, int(max_possible_folds))\n",
    "            first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "            print(f\"  ‚ö†Ô∏è Reduced to {n_folds} folds (insufficient data for 5)\")\n",
    "        \n",
    "        # Build splits chronologically\n",
    "        splits = []\n",
    "        for i in range(n_folds):\n",
    "            train_end = first_train_end + (i * test_size)\n",
    "            test_start = train_end\n",
    "            test_end = test_start + test_size\n",
    "            \n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "            \n",
    "            # Validate\n",
    "            if train_end < min_train:\n",
    "                print(f\"  ‚ö†Ô∏è Skipping fold {i+1}: insufficient training data ({train_end} < {min_train})\")\n",
    "                continue\n",
    "            \n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(test_start, test_end))\n",
    "            })\n",
    "        \n",
    "        if not splits:\n",
    "            # Emergency fallback: single split\n",
    "            print(f\"  ‚ö†Ô∏è Emergency fallback: using single train/test split\")\n",
    "            train_end = max(min_train, n_samples - test_size)\n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(train_end, n_samples))\n",
    "            })\n",
    "        \n",
    "        return splits\n",
    "    \n",
    "    def optimize_and_evaluate_all(self, n_trials=75):\n",
    "        \"\"\"Optimize all brands and evaluate on holdout\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"GAUSSIAN PROCESS: OPTIMIZATION + HOLDOUT EVALUATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Architecture: Log-Transform + Double-Scaled + Regime-Filter\")\n",
    "        print(f\"Bayesian Optimization | {n_trials} trials per brand\")\n",
    "        print(\"‚è∞ GP is O(n¬≥) - slower than tree models\")\n",
    "        print(\"üí° Provides native uncertainty quantification\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            self.optimize_brand(brand, n_trials)\n",
    "            self.evaluate_on_holdout(brand)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"GAUSSIAN PROCESS FINAL RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary = []\n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            cv = self.cv_results[brand]\n",
    "            holdout = self.holdout_results[brand]\n",
    "            \n",
    "            summary.append({\n",
    "                'Brand': brand,\n",
    "                'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",  # ‚Üê FIX: Added std\n",
    "                'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "                'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "                'Uncertainty': f\"¬±{holdout['uncertainty_pct']:.1f}%\"\n",
    "            })\n",
    "        \n",
    "        print(\"\\n\" + pd.DataFrame(summary).to_string(index=False))\n",
    "        \n",
    "        return self.cv_results, self.holdout_results, self.best_params, self.best_models\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE\n",
    "# ================================================================\n",
    "if run_training:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING GAUSSIAN PROCESS OPTIMIZATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"‚è∞ Expected runtime: 25-45 minutes (6-11 min per brand)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    gp_optimizer = GaussianProcessOptimizer(df_train, df_test)\n",
    "    gp_cv_results, gp_holdout_results, gp_best_params, gp_trained_models = \\\n",
    "        gp_optimizer.optimize_and_evaluate_all(n_trials=75)\n",
    "    \n",
    "    with open(GP_CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'cv_results': gp_cv_results,\n",
    "            'holdout_results': gp_holdout_results,\n",
    "            'best_params': gp_best_params,\n",
    "            'trained_models': gp_trained_models,\n",
    "            'scalers': gp_optimizer.scalers  \n",
    "        }, f)\n",
    "    print(f\"\\nüíæ Results Saved to {GP_CACHE_FILE}\")\n",
    "else:\n",
    "    print(\"\\n‚ö° Skipped training (loaded from cache).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# Display Summary\n",
    "# ===========================================================\n",
    "\n",
    "# --- Gaussian Process Summary Table ---\n",
    "gp_summary_list = []\n",
    "\n",
    "for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "    cv = gp_cv_results[brand]\n",
    "    holdout = gp_holdout_results[brand]\n",
    "    # Note: gp_best_params stores the actual dict in 'params' key\n",
    "    params = gp_best_params[brand]['params'] \n",
    "    \n",
    "    gp_summary_list.append({\n",
    "        'Brand': brand,\n",
    "        'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "        'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "        'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "        'Avg Uncertainty': f\"¬±{holdout['avg_uncertainty']:.0f} ({holdout['uncertainty_pct']:.1f}%)\",\n",
    "        'Kernel': params['kernel_type'],\n",
    "        'Length Scale': f\"{params['length_scale']:.2f}\",\n",
    "        'Noise (Alpha)': f\"{params['alpha']:.1e}\"\n",
    "    })\n",
    "\n",
    "df_gp_results = pd.DataFrame(gp_summary_list)\n",
    "print(\"Gaussian Process Optimization Results:\")\n",
    "display(df_gp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81372f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ML Training 7: CatBoost with Optuna \n",
    "# ================================================================\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if already trained\n",
    "CATBOOST_CACHE_FILE = 'catboost_results.pkl'\n",
    "run_training = True\n",
    "\n",
    "if os.path.exists(CATBOOST_CACHE_FILE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING CACHED CATBOOST RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    with open(CATBOOST_CACHE_FILE, 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    catboost_cv_results = cached['cv_results']\n",
    "    catboost_holdout_results = cached['holdout_results']\n",
    "    catboost_best_params = cached['best_params']\n",
    "    catboost_trained_models = cached['trained_models']\n",
    "    catboost_scalers = cached.get('scalers', {})\n",
    "    run_training = False\n",
    "    print(\"‚úÖ Loaded cached CatBoost results\")\n",
    "    print(\"To retrain, delete:\", CATBOOST_CACHE_FILE)\n",
    "else:\n",
    "    print(\"No cache found - training CatBoost from scratch...\")\n",
    "\n",
    "class CatBoostOptimizer:\n",
    "    \"\"\"\n",
    "    CatBoost with Optuna-based hyperparameter optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_train, df_test):\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "        self.cv_results = {}\n",
    "        self.holdout_results = {}\n",
    "        self.best_params = {}\n",
    "        self.best_models = {}\n",
    "        self.scalers = {}\n",
    "        self.feature_importance = {}\n",
    "    \n",
    "    def optimize_brand(self, brand: str, n_trials: int = 50):\n",
    "        \"\"\"Optimize CatBoost using robust transformation pipeline\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"CATBOOST OPTIMIZATION: {brand}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Using Optuna TPE Sampler | {n_trials} trials | Walk-Forward CV\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 1: REGIME FILTERING\n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        print(f\"üìÖ Regime: {start_date} ‚Üí {len(df_brand_train)} train months\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 2: FEATURE PREPARATION\n",
    "        # ===========================================================\n",
    "        # Auto-Detect Column Name Case\n",
    "        target_col = f'{brand}_units'\n",
    "        if target_col not in df_brand_train.columns:\n",
    "            target_col = f'{brand.lower()}_units'\n",
    "            brand_prefix = brand.lower()\n",
    "        else:\n",
    "            brand_prefix = brand\n",
    "        \n",
    "        # Prepare features\n",
    "        feature_cols = [\n",
    "            f'{brand_prefix}_lag1', f'{brand_prefix}_lag12',\n",
    "            f'{brand_prefix}_ma3', f'{brand_prefix}_ma12',\n",
    "            f'launch_{brand.lower()}', \n",
    "            'is_holiday_season', 'is_back_to_school', 'is_black_friday',\n",
    "            'month_num', 'quarter', 'time_index', 'cpi_index'\n",
    "        ]\n",
    "        feature_cols = [c for c in feature_cols if c in df_brand_train.columns]\n",
    "        \n",
    "        # Identify categorical features \n",
    "        categorical_features = [col for col in feature_cols if col in ['month_num', 'quarter']]\n",
    "        \n",
    "        print(f\"Target: {target_col}\")\n",
    "        print(f\"Features: {len(feature_cols)} columns\")\n",
    "        print(f\"Categorical: {categorical_features}\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 3: GET RAW DATA & LOG-TRANSFORM TARGET\n",
    "        # ===========================================================\n",
    "        X_raw = df_brand_train[feature_cols].copy()  # Keep as DataFrame for CatBoost\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        \n",
    "        # Log-Transform Target\n",
    "        y_log = transform_target(y_raw)\n",
    "        print(f\"Target Log-Transformed: {y_log.min():.2f} - {y_log.max():.2f}\")\n",
    "        \n",
    "        # Store for objective\n",
    "        self.current_X_raw = X_raw\n",
    "        self.current_y_log = y_log\n",
    "        self.current_y_raw = y_raw\n",
    "        self.current_splits = self._create_walk_forward_splits(len(y_raw))\n",
    "        self.current_feature_cols = feature_cols\n",
    "        self.current_cat_features = categorical_features\n",
    "        self.current_target_col = target_col\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 4: OPTUNA OPTIMIZATION\n",
    "        # ===========================================================\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        \n",
    "        print(f\"üöÄ Starting optimization (Log-Target + Scaled-Features)...\")\n",
    "        study.optimize(\n",
    "            self._objective_catboost, \n",
    "            n_trials=n_trials, \n",
    "            show_progress_bar=True,\n",
    "            callbacks=[self._optuna_callback]\n",
    "        )\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        print(f\"‚úÖ Best CV MAPE: {study.best_value:.2f}%\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # STEP 5: TRAIN FINAL MODEL (On Full Training Set)\n",
    "        # ===========================================================\n",
    "        # Fit scaler on FULL training data\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = X_raw.copy()\n",
    "        \n",
    "        # Scale only numeric columns (preserve categorical)\n",
    "        numeric_cols = [c for c in feature_cols if c not in categorical_features]\n",
    "        X_scaled[numeric_cols] = scaler.fit_transform(X_raw[numeric_cols])\n",
    "        \n",
    "        self.scalers[brand] = scaler\n",
    "        \n",
    "        print(f\"üîß Training final model on full training set...\")\n",
    "        final_model = CatBoostRegressor(\n",
    "            **best_params, \n",
    "            random_state=42, \n",
    "            verbose=False,\n",
    "            cat_features=categorical_features\n",
    "        )\n",
    "        final_model.fit(X_scaled, y_log)\n",
    "        \n",
    "        self.best_models[brand] = final_model\n",
    "        self.best_params[brand] = {\n",
    "            'params': best_params,\n",
    "            'feature_cols': feature_cols,\n",
    "            'cat_features': categorical_features,\n",
    "            'target_col': target_col,\n",
    "            'numeric_cols': numeric_cols\n",
    "        }\n",
    "\n",
    "        # ===========================================================\n",
    "        # STEP 6: RE-RUN CV TO CAPTURE STANDARD DEVIATION (Risk Metric)\n",
    "        # ===========================================================\n",
    "        fold_scores = []\n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                # Reconstruct fold data (Leakage Proof)\n",
    "                X_tr = self.current_X_raw.iloc[split['train']].copy()\n",
    "                X_te = self.current_X_raw.iloc[split['test']].copy()\n",
    "                y_tr_log = self.current_y_log[split['train']]\n",
    "                y_te_raw = self.current_y_raw[split['test']]\n",
    "                \n",
    "                # Scale numeric columns only\n",
    "                sc = StandardScaler()\n",
    "                X_tr[numeric_cols] = sc.fit_transform(X_tr[numeric_cols])\n",
    "                X_te[numeric_cols] = sc.transform(X_te[numeric_cols])\n",
    "                \n",
    "                # Train\n",
    "                m = CatBoostRegressor(**best_params, verbose=False, random_state=42, cat_features=categorical_features)\n",
    "                m.fit(X_tr, y_tr_log)\n",
    "                \n",
    "                # Predict & Inverse\n",
    "                pred_log = m.predict(X_te)\n",
    "                pred_real = inverse_transform_target(pred_log)\n",
    "                \n",
    "                fold_scores.append(mean_absolute_percentage_error(y_te_raw, pred_real) * 100)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        cv_std = np.std(fold_scores) if fold_scores else 0.0\n",
    "\n",
    "        # Store metadata with actual standard deviation\n",
    "        self.cv_results[brand] = {\n",
    "            'cv_mape_mean': study.best_value,\n",
    "            'cv_mape_std': cv_std \n",
    "        }\n",
    "        \n",
    "        # Feature Importance\n",
    "        imp = final_model.get_feature_importance()\n",
    "        self.feature_importance[brand] = dict(zip(feature_cols, imp))\n",
    "        \n",
    "        print(f\"‚úì Final model trained on {len(y_raw)} training months\")\n",
    "        \n",
    "        return study.best_value, best_params\n",
    "    \n",
    "    def evaluate_on_holdout(self, brand: str):\n",
    "        \"\"\"Evaluate on Holdout Test Set using Fitted Scaler\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"HOLDOUT TEST EVALUATION: {brand}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        params = self.best_params[brand]\n",
    "        feature_cols = params['feature_cols']\n",
    "        numeric_cols = params['numeric_cols']\n",
    "        target_col = params['target_col']\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Apply regime filter \n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_test = self.df_test[self.df_test['month'] >= start_date].copy()\n",
    "        \n",
    "        # Get RAW test data (keep as DataFrame)\n",
    "        X_test_raw = df_brand_test[feature_cols].copy()\n",
    "        y_test_raw = df_brand_test[target_col].values\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Use saved scaler\n",
    "        # ===========================================================\n",
    "        scaler = self.scalers[brand]\n",
    "        X_test_scaled = X_test_raw.copy()\n",
    "        X_test_scaled[numeric_cols] = scaler.transform(X_test_raw[numeric_cols])\n",
    "        \n",
    "        # Predict (Log Space)\n",
    "        model = self.best_models[brand]\n",
    "        pred_log = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Inverse Transform\n",
    "        pred_real = inverse_transform_target(pred_log)\n",
    "        \n",
    "        # Metrics\n",
    "        mape = mean_absolute_percentage_error(y_test_raw, pred_real) * 100\n",
    "        rmse = np.sqrt(np.mean((y_test_raw - pred_real)**2))\n",
    "        r2 = 1 - (np.sum((y_test_raw - pred_real)**2) / np.sum((y_test_raw - y_test_raw.mean())**2))\n",
    "        \n",
    "        print(f\"Test Results (Real Units):\")\n",
    "        print(f\"  MAPE: {mape:.2f}%\")\n",
    "        print(f\"  RMSE: {rmse:,.0f}\")\n",
    "        print(f\"  R¬≤:   {r2:.4f}\")\n",
    "        \n",
    "        self.holdout_results[brand] = {\n",
    "            'test_mape': mape,\n",
    "            'test_rmse': rmse,\n",
    "            'test_r2': r2,\n",
    "            'predictions': pred_real\n",
    "        }\n",
    "        return self.holdout_results[brand]\n",
    "\n",
    "    def _objective_catboost(self, trial):\n",
    "        \"\"\"Objective with Internal Scaling\"\"\"\n",
    "        \n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('iterations', 100, 500),\n",
    "            'depth': trial.suggest_int('depth', 4, 8),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "            'random_strength': trial.suggest_float('random_strength', 0, 10),\n",
    "            'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "            'verbose': False, \n",
    "            'random_state': 42,\n",
    "            'cat_features': self.current_cat_features\n",
    "        }\n",
    "        \n",
    "        fold_scores = []\n",
    "        numeric_cols = [c for c in self.current_feature_cols if c not in self.current_cat_features]\n",
    "        \n",
    "        for split in self.current_splits:\n",
    "            try:\n",
    "                # Get RAW data for fold (DataFrame)\n",
    "                X_train_raw = self.current_X_raw.iloc[split['train']].copy()\n",
    "                X_test_raw = self.current_X_raw.iloc[split['test']].copy()\n",
    "                y_train_log = self.current_y_log[split['train']]\n",
    "                y_test_raw = self.current_y_raw[split['test']]\n",
    "                \n",
    "                # Internal Split-then-Scale (numeric columns only)\n",
    "                scaler = StandardScaler()\n",
    "                X_train_sc = X_train_raw.copy()\n",
    "                X_test_sc = X_test_raw.copy()\n",
    "                \n",
    "                X_train_sc[numeric_cols] = scaler.fit_transform(X_train_raw[numeric_cols])\n",
    "                X_test_sc[numeric_cols] = scaler.transform(X_test_raw[numeric_cols])\n",
    "                \n",
    "                # Train\n",
    "                model = CatBoostRegressor(**params)\n",
    "                model.fit(X_train_sc, y_train_log)\n",
    "                \n",
    "                # Predict\n",
    "                pred_log = model.predict(X_test_sc)\n",
    "                pred_real = inverse_transform_target(pred_log)\n",
    "                \n",
    "                # Score\n",
    "                mape = mean_absolute_percentage_error(y_test_raw, pred_real) * 100\n",
    "                fold_scores.append(mape)\n",
    "            except:\n",
    "                fold_scores.append(999)\n",
    "        \n",
    "        return np.mean(fold_scores) if fold_scores else 999\n",
    "\n",
    "    def _optuna_callback(self, study, trial):\n",
    "        \"\"\"Progress callback (Crash-proof)\"\"\"\n",
    "        if trial.number % 10 == 0:\n",
    "            val = trial.value\n",
    "            best = study.best_value\n",
    "            \n",
    "            # Safe string formatting handling None\n",
    "            val_str = f\"{val:.2f}%\" if val is not None else \"Failed\"\n",
    "            best_str = f\"{best:.2f}%\" if best is not None else \"N/A\"\n",
    "            \n",
    "            print(f\"  Trial {trial.number}: MAPE = {val_str} | Best: {best_str}\")\n",
    "\n",
    "    def _create_walk_forward_splits(self, n_samples: int):\n",
    "        \"\"\"\n",
    "        Anchored walk-forward CV ending at most recent training data\n",
    "        \n",
    "        Design:\n",
    "        - Last fold ALWAYS tests the most recent 12 months\n",
    "        - Expanding window (training grows chronologically)\n",
    "        - Non-overlapping 12-month test sets\n",
    "        - Auto-adjusts fold count if insufficient data\n",
    "        \"\"\"\n",
    "        test_size = 12  # Full seasonal cycle\n",
    "        n_folds = 5\n",
    "        min_train = 60  # 5 years minimum \n",
    "        \n",
    "        # Anchor: last test set ends at most recent data\n",
    "        last_test_end = n_samples\n",
    "        last_test_start = last_test_end - test_size\n",
    "        \n",
    "        # Calculate where first fold would start\n",
    "        first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        # Safety: ensure minimum training data\n",
    "        if first_train_end < min_train:\n",
    "            # Reduce folds to fit\n",
    "            max_possible_folds = (last_test_start - min_train) // test_size + 1\n",
    "            n_folds = max(2, int(max_possible_folds))\n",
    "            first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "            print(f\"  ‚ö†Ô∏è Reduced to {n_folds} folds (insufficient data for 5)\")\n",
    "        \n",
    "        # Build splits chronologically\n",
    "        splits = []\n",
    "        for i in range(n_folds):\n",
    "            train_end = first_train_end + (i * test_size)\n",
    "            test_start = train_end\n",
    "            test_end = test_start + test_size\n",
    "            \n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "            \n",
    "            # Validate\n",
    "            if train_end < min_train:\n",
    "                print(f\"  ‚ö†Ô∏è Skipping fold {i+1}: insufficient training data ({train_end} < {min_train})\")\n",
    "                continue\n",
    "            \n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(test_start, test_end))\n",
    "            })\n",
    "        \n",
    "        if not splits:\n",
    "            # Emergency fallback: single split\n",
    "            print(f\"  ‚ö†Ô∏è Emergency fallback: using single train/test split\")\n",
    "            train_end = max(min_train, n_samples - test_size)\n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(train_end, n_samples))\n",
    "            })\n",
    "        \n",
    "        return splits\n",
    "\n",
    "    def optimize_and_evaluate_all(self, n_trials=50):\n",
    "        \"\"\"Optimize all brands and evaluate on holdout\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"CATBOOST: OPTIMIZATION + HOLDOUT EVALUATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Architecture: Log-Transform + Scaled-Features + Regime-Filter\")\n",
    "        print(f\"Bayesian Optimization | {n_trials} trials per brand\")\n",
    "        print(\"üí° CatBoost: Ordered boosting + Native categorical support\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            self.optimize_brand(brand, n_trials)\n",
    "            self.evaluate_on_holdout(brand)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"CATBOOST FINAL RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary = []\n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            cv = self.cv_results[brand]\n",
    "            holdout = self.holdout_results[brand]\n",
    "            params = self.best_params[brand]['params']\n",
    "            \n",
    "            summary.append({\n",
    "                'Brand': brand,\n",
    "                'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",  # ‚Üê FIX: Added std\n",
    "                'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "                'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "                'iterations': params['iterations']\n",
    "            })\n",
    "        \n",
    "        print(\"\\n\" + pd.DataFrame(summary).to_string(index=False))\n",
    "        \n",
    "        return self.cv_results, self.holdout_results, self.best_params, self.best_models\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE\n",
    "# ================================================================\n",
    "if run_training:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING CATBOOST OPTIMIZATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"‚è∞ Expected runtime: 15-25 minutes (4-6 min per brand)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    catboost_optimizer = CatBoostOptimizer(df_train, df_test)\n",
    "    catboost_cv_results, catboost_holdout_results, catboost_best_params, catboost_trained_models = \\\n",
    "        catboost_optimizer.optimize_and_evaluate_all(n_trials=50)\n",
    "    \n",
    "    with open(CATBOOST_CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'cv_results': catboost_cv_results,\n",
    "            'holdout_results': catboost_holdout_results,\n",
    "            'best_params': catboost_best_params,\n",
    "            'trained_models': catboost_trained_models,\n",
    "            'scalers': catboost_optimizer.scalers\n",
    "        }, f)\n",
    "    print(f\"\\nüíæ Results Saved to {CATBOOST_CACHE_FILE}\")\n",
    "else:\n",
    "    print(\"\\n‚ö° Skipped training (loaded from cache).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa73364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# Display Summary\n",
    "# ===========================================================\n",
    "\n",
    "# --- CatBoost Summary Table ---\n",
    "catboost_summary_list = []\n",
    "\n",
    "for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "    # Retrieve results for the brand\n",
    "    cv = catboost_cv_results[brand]\n",
    "    holdout = catboost_holdout_results[brand]\n",
    "    \n",
    "    # Access the specific parameters dictionary\n",
    "    # Note: 'best_params' structure is {'params': {...}, 'feature_cols': [...]}\n",
    "    params = catboost_best_params[brand]['params']\n",
    "    \n",
    "    catboost_summary_list.append({\n",
    "        'Brand': brand,\n",
    "        'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",\n",
    "        'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "        'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "        'Iterations': params['iterations'],\n",
    "        'Depth': params['depth'],\n",
    "        'Learning Rate': f\"{params['learning_rate']:.4f}\",\n",
    "        'L2 Regularization': f\"{params['l2_leaf_reg']:.2f}\"\n",
    "    })\n",
    "\n",
    "df_catboost_results = pd.DataFrame(catboost_summary_list)\n",
    "print(\"CatBoost Optimization Results:\")\n",
    "display(df_catboost_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e237ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ML Training 8: Caruana Ensemble + LOG-SCALING \n",
    "# ================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Check if already trained\n",
    "ENSEMBLE_CACHE_FILE = 'ensemble_results.pkl'\n",
    "run_training = True\n",
    "\n",
    "if os.path.exists(ENSEMBLE_CACHE_FILE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING CACHED ENSEMBLE RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    with open(ENSEMBLE_CACHE_FILE, 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    ensemble_cv_results = cached['cv_results']\n",
    "    ensemble_holdout_results = cached['holdout_results']\n",
    "    ensemble_weights = cached['ensemble_weights']\n",
    "    run_training = False\n",
    "    print(\"‚úÖ Loaded cached Ensemble results\")\n",
    "    print(\"To retrain, delete:\", ENSEMBLE_CACHE_FILE)\n",
    "else:\n",
    "    print(\"No cache found - training Ensemble from scratch...\")\n",
    "\n",
    "class CaruanaEnsembleOptimizer:\n",
    "    \"\"\"\n",
    "    Caruana Ensemble with LOG-SCALING\n",
    "    \n",
    "    CRITICAL ARCHITECTURE:\n",
    "    - All base models trained on log-scale (from Cells 12A-12F)\n",
    "    - Ensemble averages predictions in LOG-SPACE\n",
    "    - Single inverse transform converts to original scale\n",
    "    - Maintains variance stabilization across entire pipeline\n",
    "    - Brand-specific regime filtering (Google starts 2016, others 2011)\n",
    "    \n",
    "    Base models (7):\n",
    "    1. SARIMAX, 2. XGBoost, 3. LightGBM, 4. Prophet-Multi,\n",
    "    5. Prophet-Uni, 6. CatBoost, 7. Gaussian Process\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_train, df_test):\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "        self.ensemble_weights = {}\n",
    "        self.cv_results = {}\n",
    "        self.holdout_results = {}\n",
    "        self.all_cv_predictions = {}  # In LOG-SPACE\n",
    "        self.all_holdout_predictions = {}  # In LOG-SPACE\n",
    "        self.individual_cv_scores = {}\n",
    "        self.individual_holdout_scores = {}\n",
    "    \n",
    "    def generate_all_predictions(\n",
    "        self,\n",
    "        sarimax_params, sarimax_models, sarimax_scalers,  # Added scalers\n",
    "        xgboost_params, xgboost_models, xgboost_scalers,\n",
    "        lightgbm_params, lightgbm_models, lightgbm_scalers,\n",
    "        prophet_params, prophet_models,\n",
    "        prophet_uni_params, prophet_uni_models,\n",
    "        catboost_params, catboost_models, catboost_scalers,\n",
    "        gp_params, gp_models, gp_scalers\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate out-of-fold predictions IN LOG-SPACE for all base models\n",
    "        \n",
    "        All predictions stay in log-space for ensemble averaging\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"GENERATING LOG-SPACE PREDICTIONS FOR ENSEMBLE\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"‚öôÔ∏è  All base models trained on log-scale\")\n",
    "        print(\"üìä Predictions will be averaged in log-space\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        brands = ['Apple', 'Samsung', 'Google', 'Motorola']\n",
    "        \n",
    "        for idx, brand in enumerate(brands):\n",
    "            print(f\"\\n[{idx+1}/4] Processing: {brand}\")\n",
    "            print(\"‚îÄ\" * 50)\n",
    "            \n",
    "            self.all_cv_predictions[brand] = {}\n",
    "            self.all_holdout_predictions[brand] = {}\n",
    "            \n",
    "            # [1] SARIMAX\n",
    "            print(\"  [1/7] SARIMAX...\", end='', flush=True)\n",
    "            cv, holdout = self._generate_sarimax_predictions(\n",
    "                brand, sarimax_params[brand], sarimax_models.get(brand), \n",
    "                sarimax_scalers.get(brand)  # ‚Üê FIX: Pass scaler\n",
    "            )\n",
    "            self.all_cv_predictions[brand]['SARIMAX'] = cv\n",
    "            self.all_holdout_predictions[brand]['SARIMAX'] = holdout\n",
    "            print(\" ‚úì\")\n",
    "            \n",
    "            # [2] XGBoost\n",
    "            print(\"  [2/7] XGBoost...\", end='', flush=True)\n",
    "            cv, holdout = self._generate_xgboost_predictions(\n",
    "                brand, xgboost_params[brand], xgboost_models[brand], xgboost_scalers[brand]\n",
    "            )\n",
    "            self.all_cv_predictions[brand]['XGBoost'] = cv\n",
    "            self.all_holdout_predictions[brand]['XGBoost'] = holdout\n",
    "            print(\" ‚úì\")\n",
    "            \n",
    "            # [3] LightGBM\n",
    "            print(\"  [3/7] LightGBM...\", end='', flush=True)\n",
    "            cv, holdout = self._generate_lightgbm_predictions(\n",
    "                brand, lightgbm_params[brand], lightgbm_models[brand], lightgbm_scalers[brand]\n",
    "            )\n",
    "            self.all_cv_predictions[brand]['LightGBM'] = cv\n",
    "            self.all_holdout_predictions[brand]['LightGBM'] = holdout\n",
    "            print(\" ‚úì\")\n",
    "            \n",
    "            # [4] Prophet-Multi\n",
    "            print(\"  [4/7] Prophet-Multi...\", end='', flush=True)\n",
    "            cv, holdout = self._generate_prophet_predictions(\n",
    "                brand, prophet_params[brand], prophet_models[brand], multivariate=True\n",
    "            )\n",
    "            self.all_cv_predictions[brand]['Prophet-Multi'] = cv\n",
    "            self.all_holdout_predictions[brand]['Prophet-Multi'] = holdout\n",
    "            print(\" ‚úì\")\n",
    "            \n",
    "            # [5] Prophet-Uni\n",
    "            print(\"  [5/7] Prophet-Uni...\", end='', flush=True)\n",
    "            cv, holdout = self._generate_prophet_uni_predictions(\n",
    "                brand, prophet_uni_params[brand], prophet_uni_models[brand]\n",
    "            )\n",
    "            self.all_cv_predictions[brand]['Prophet-Uni'] = cv\n",
    "            self.all_holdout_predictions[brand]['Prophet-Uni'] = holdout\n",
    "            print(\" ‚úì\")\n",
    "\n",
    "            # [6] CatBoost\n",
    "            print(\"  [6/7] CatBoost...\", end='', flush=True)\n",
    "            cv, holdout = self._generate_catboost_predictions(\n",
    "                brand, catboost_params[brand], catboost_models[brand], catboost_scalers[brand]\n",
    "            )\n",
    "            self.all_cv_predictions[brand]['CatBoost'] = cv\n",
    "            self.all_holdout_predictions[brand]['CatBoost'] = holdout\n",
    "            print(\" ‚úì\")\n",
    "\n",
    "            # [7] Gaussian Process\n",
    "            print(\"  [7/7] Gaussian Process...\", end='', flush=True)\n",
    "            cv, holdout = self._generate_gp_predictions(\n",
    "                brand, gp_params[brand], gp_models[brand], gp_scalers[brand]\n",
    "            )\n",
    "            self.all_cv_predictions[brand]['GP'] = cv\n",
    "            self.all_holdout_predictions[brand]['GP'] = holdout\n",
    "            print(\" ‚úì\")\n",
    "        \n",
    "        print(\"\\n‚úÖ All LOG-SPACE predictions generated successfully\")\n",
    "\n",
    "    def _generate_sarimax_predictions(self, brand, params, trained_model, scaler):  # Added scaler param\n",
    "        \"\"\"Generate SARIMAX predictions\"\"\"\n",
    "        from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Apply regime filter (consistency with training)\n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        df_brand_test = self.df_test[self.df_test['month'] >= start_date].copy()\n",
    "\n",
    "        target_col = f'{brand}_units'\n",
    "        if target_col not in df_brand_train.columns:\n",
    "            target_col = f'{brand.lower()}_units'\n",
    "        \n",
    "        # Get RAW target and log-transform\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        y_log = transform_target(y_raw)\n",
    "        \n",
    "        exog_cols = params.get('exog_cols', [])\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Apply scaler to exogenous variables\n",
    "        # ===========================================================\n",
    "        if exog_cols and scaler is not None:\n",
    "            X_raw = df_brand_train[exog_cols].values\n",
    "            X = scaler.transform(X_raw)  # ‚Üê Use fitted scaler\n",
    "            \n",
    "            X_test_raw = df_brand_test[exog_cols].values\n",
    "            X_test = scaler.transform(X_test_raw)  # ‚Üê Use fitted scaler\n",
    "        else:\n",
    "            X = df_brand_train[exog_cols].values if exog_cols else None\n",
    "            X_test = df_brand_test[exog_cols].values if exog_cols else None\n",
    "        \n",
    "        # CV predictions (in log-space)\n",
    "        cv_preds_log = []\n",
    "        splits = self._create_walk_forward_splits(len(y_log))\n",
    "        \n",
    "        for split in splits:\n",
    "            y_train_log = y_log[split['train']]\n",
    "            X_train = X[split['train']] if X is not None else None\n",
    "            X_val = X[split['test']] if X is not None else None\n",
    "            \n",
    "            model = SARIMAX(\n",
    "                y_train_log, exog=X_train, \n",
    "                order=params.get('order', (1,1,1)), \n",
    "                seasonal_order=params.get('seasonal_order', (1,1,1,12)),\n",
    "                enforce_stationarity=False, \n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            fit = model.fit(disp=False, maxiter=200, method='lbfgs')\n",
    "            cv_preds_log.extend(fit.forecast(steps=len(split['test']), exog=X_val))\n",
    "        \n",
    "        # Holdout predictions (use trained model if available, else retrain)\n",
    "        if trained_model is not None:\n",
    "            holdout_pred_log = trained_model.forecast(steps=len(df_brand_test), exog=X_test)\n",
    "        else:\n",
    "            model_full = SARIMAX(\n",
    "                y_log, exog=X, \n",
    "                order=params.get('order', (1,1,1)), \n",
    "                seasonal_order=params.get('seasonal_order', (1,1,1,12)),\n",
    "                enforce_stationarity=False, \n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            fit_full = model_full.fit(disp=False, maxiter=200, method='lbfgs')\n",
    "            holdout_pred_log = fit_full.forecast(steps=len(df_brand_test), exog=X_test)\n",
    "        \n",
    "        return np.array(cv_preds_log), np.array(holdout_pred_log)\n",
    "\n",
    "    def _generate_xgboost_predictions(self, brand, params, trained_model, scaler):\n",
    "        \"\"\"Generate XGBoost predictions (in log-space)\"\"\"\n",
    "        import xgboost as xgb\n",
    "\n",
    "        # ===========================================================\n",
    "        # Apply regime filter \n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        df_brand_test = self.df_test[self.df_test['month'] >= start_date].copy()\n",
    "        \n",
    "        target_col = f'{brand}_units'\n",
    "        if target_col not in df_brand_train.columns:\n",
    "            target_col = f'{brand.lower()}_units'\n",
    "            brand_prefix = brand.lower()\n",
    "        else:\n",
    "            brand_prefix = brand\n",
    "        \n",
    "        feature_cols = [\n",
    "            f'{brand_prefix}_lag1', f'{brand_prefix}_lag12',\n",
    "            f'{brand_prefix}_ma3', f'{brand_prefix}_ma12',\n",
    "            f'launch_{brand.lower()}', \n",
    "            'is_holiday_season', 'is_back_to_school', 'is_black_friday',\n",
    "            'month_num', 'quarter', 'time_index', 'cpi_index'\n",
    "        ]\n",
    "        feature_cols = [c for c in feature_cols if c in df_brand_train.columns]\n",
    "        \n",
    "        X_raw = df_brand_train[feature_cols].values\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        y_log = transform_target(y_raw)\n",
    "        \n",
    "        X_test_raw = df_brand_test[feature_cols].values\n",
    "        \n",
    "        # CV predictions (in log-space)\n",
    "        cv_preds_log = []\n",
    "        splits = self._create_walk_forward_splits(len(X_raw))\n",
    "        \n",
    "        for split in splits:\n",
    "            scaler_fold = StandardScaler()\n",
    "            X_train_sc = scaler_fold.fit_transform(X_raw[split['train']])\n",
    "            X_val_sc = scaler_fold.transform(X_raw[split['test']])\n",
    "            y_train_log = y_log[split['train']]\n",
    "            \n",
    "            model = xgb.XGBRegressor(**params, random_state=42, n_jobs=-1)\n",
    "            model.fit(X_train_sc, y_train_log, verbose=False)\n",
    "            cv_preds_log.extend(model.predict(X_val_sc))\n",
    "        \n",
    "        # Holdout predictions (use trained model + scaler)\n",
    "        X_test_sc = scaler.transform(X_test_raw)\n",
    "        holdout_pred_log = trained_model.predict(X_test_sc)\n",
    "        \n",
    "        return np.array(cv_preds_log), holdout_pred_log\n",
    "\n",
    "    def _generate_lightgbm_predictions(self, brand, params, trained_model, scaler):\n",
    "        \"\"\"Generate LightGBM predictions (in log-space)\"\"\"\n",
    "        import lightgbm as lgb\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Apply regime filter \n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        df_brand_test = self.df_test[self.df_test['month'] >= start_date].copy()\n",
    "\n",
    "        # Same logic as XGBoost\n",
    "        target_col = f'{brand}_units'\n",
    "        if target_col not in df_brand_train.columns:\n",
    "            target_col = f'{brand.lower()}_units'\n",
    "            brand_prefix = brand.lower()\n",
    "        else:\n",
    "            brand_prefix = brand\n",
    "        \n",
    "        feature_cols = [\n",
    "            f'{brand_prefix}_lag1', f'{brand_prefix}_lag12',\n",
    "            f'{brand_prefix}_ma3', f'{brand_prefix}_ma12',\n",
    "            f'launch_{brand.lower()}', \n",
    "            'is_holiday_season', 'is_back_to_school', 'is_black_friday',\n",
    "            'month_num', 'quarter', 'time_index', 'cpi_index'\n",
    "        ]\n",
    "        feature_cols = [c for c in feature_cols if c in df_brand_train.columns]\n",
    "        \n",
    "        X_raw = df_brand_train[feature_cols].values\n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        y_log = transform_target(y_raw)\n",
    "        X_test_raw = df_brand_test[feature_cols].values\n",
    "        \n",
    "        cv_preds_log = []\n",
    "        splits = self._create_walk_forward_splits(len(X_raw))\n",
    "        \n",
    "        for split in splits:\n",
    "            scaler_fold = StandardScaler()\n",
    "            X_train_sc = scaler_fold.fit_transform(X_raw[split['train']])\n",
    "            X_val_sc = scaler_fold.transform(X_raw[split['test']])\n",
    "            y_train_log = y_log[split['train']]\n",
    "            \n",
    "            model = lgb.LGBMRegressor(**params, random_state=42, verbose=-1, n_jobs=-1)\n",
    "            model.fit(X_train_sc, y_train_log)\n",
    "            cv_preds_log.extend(model.predict(X_val_sc))\n",
    "        \n",
    "        X_test_sc = scaler.transform(X_test_raw)\n",
    "        holdout_pred_log = trained_model.predict(X_test_sc)\n",
    "        \n",
    "        return np.array(cv_preds_log), holdout_pred_log\n",
    "\n",
    "    def _generate_prophet_predictions(self, brand, params, trained_model, multivariate):\n",
    "        \"\"\"Generate Prophet-Multi predictions (in log-space)\"\"\"\n",
    "        from prophet import Prophet\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Apply regime filter \n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        df_brand_test = self.df_test[self.df_test['month'] >= start_date].copy()\n",
    "\n",
    "        target_col = f'{brand}_units'\n",
    "        if target_col not in df_brand_train.columns:\n",
    "            target_col = f'{brand.lower()}_units'\n",
    "        \n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        y_log = transform_target(y_raw)\n",
    "        \n",
    "        df_prophet = pd.DataFrame({\n",
    "            'ds': df_brand_train['month'],\n",
    "            'y': y_log  # LOG-TRANSFORMED\n",
    "        })\n",
    "        \n",
    "        regressors = []\n",
    "        if multivariate:\n",
    "            regressors = [\n",
    "                f'launch_{brand.lower()}', \n",
    "                'is_holiday_season', 'is_back_to_school', \n",
    "                'is_black_friday', 'cpi_index'\n",
    "            ]\n",
    "            for reg in regressors:\n",
    "                if reg in df_brand_train.columns:\n",
    "                    df_prophet[reg] = df_brand_train[reg].values\n",
    "            regressors = [r for r in regressors if r in df_prophet.columns]\n",
    "        \n",
    "        cv_preds_log = []\n",
    "        splits = self._create_walk_forward_splits(len(df_prophet))\n",
    "        \n",
    "        for split in splits:\n",
    "            model = self._create_prophet_model(params, regressors)\n",
    "            model.fit(df_prophet.iloc[split['train']])\n",
    "            \n",
    "            future_df = df_prophet.iloc[split['test']][['ds'] + regressors].copy()\n",
    "            forecast = model.predict(future_df)\n",
    "            cv_preds_log.extend(forecast['yhat'].values)\n",
    "        \n",
    "        # Holdout (use trained model)\n",
    "        future_holdout = pd.DataFrame({'ds': df_brand_test['month']})\n",
    "        for reg in regressors:\n",
    "            if reg in df_brand_test.columns:\n",
    "                future_holdout[reg] = df_brand_test[reg].values\n",
    "        \n",
    "        holdout_forecast = trained_model.predict(future_holdout)\n",
    "        holdout_pred_log = holdout_forecast['yhat'].values\n",
    "        \n",
    "        return np.array(cv_preds_log), holdout_pred_log\n",
    "\n",
    "    def _generate_prophet_uni_predictions(self, brand, params, trained_model):\n",
    "        \"\"\"Generate Prophet-Uni predictions (in log-space)\"\"\"\n",
    "        # Same as Prophet-Multi but multivariate=False\n",
    "        return self._generate_prophet_predictions(brand, params, trained_model, multivariate=False)\n",
    "\n",
    "    def _create_prophet_model(self, params, regressors):\n",
    "        \"\"\"Helper to create Prophet model\"\"\"\n",
    "        from prophet import Prophet\n",
    "        \n",
    "        # Handle nested params (Multi) vs Flat params (Uni)\n",
    "        p = params['hyperparams'] if 'hyperparams' in params else params\n",
    "        \n",
    "        yearly_seasonality = 'auto' if p.get('yearly_seasonality') == True else p.get('yearly_seasonality', True)\n",
    "        \n",
    "        model = Prophet(\n",
    "            changepoint_prior_scale=p['changepoint_prior_scale'],\n",
    "            seasonality_prior_scale=p['seasonality_prior_scale'],\n",
    "            seasonality_mode=p['seasonality_mode'],\n",
    "            changepoint_range=p.get('changepoint_range', 0.8),\n",
    "            yearly_seasonality=yearly_seasonality,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False\n",
    "        )\n",
    "        \n",
    "        for reg in regressors:\n",
    "            model.add_regressor(reg)\n",
    "        \n",
    "        if p.get('monthly_seasonality', False):\n",
    "            model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def _generate_catboost_predictions(self, brand, catboost_data, trained_model, scaler):\n",
    "        \"\"\"Generate CatBoost predictions (in log-space)\"\"\"\n",
    "        from catboost import CatBoostRegressor\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Apply regime filter \n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        df_brand_test = self.df_test[self.df_test['month'] >= start_date].copy()\n",
    "\n",
    "        params = catboost_data['params']\n",
    "        feature_cols = catboost_data['feature_cols']\n",
    "        cat_features = catboost_data['cat_features']\n",
    "        target_col = catboost_data['target_col']\n",
    "        numeric_cols = catboost_data['numeric_cols']\n",
    "        \n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        y_log = transform_target(y_raw)\n",
    "        \n",
    "        X_raw = df_brand_train[feature_cols].copy()\n",
    "        X_test_raw = df_brand_test[feature_cols].copy()\n",
    "        \n",
    "        cv_preds_log = []\n",
    "        splits = self._create_walk_forward_splits(len(X_raw))\n",
    "        \n",
    "        for split in splits:\n",
    "            scaler_fold = StandardScaler()\n",
    "            \n",
    "            X_train = X_raw.iloc[split['train']].copy()\n",
    "            X_val = X_raw.iloc[split['test']].copy()\n",
    "            X_train[numeric_cols] = scaler_fold.fit_transform(X_train[numeric_cols])\n",
    "            X_val[numeric_cols] = scaler_fold.transform(X_val[numeric_cols])\n",
    "            y_train_log = y_log[split['train']]\n",
    "            \n",
    "            model = CatBoostRegressor(**params, verbose=False, random_state=42, cat_features=cat_features)\n",
    "            model.fit(X_train, y_train_log)\n",
    "            cv_preds_log.extend(model.predict(X_val))\n",
    "        \n",
    "        X_test_sc = X_test_raw.copy()\n",
    "        X_test_sc[numeric_cols] = scaler.transform(X_test_raw[numeric_cols])\n",
    "        holdout_pred_log = trained_model.predict(X_test_sc)\n",
    "        \n",
    "        return np.array(cv_preds_log), holdout_pred_log\n",
    "\n",
    "    def _generate_gp_predictions(self, brand, gp_data, trained_model, scalers):\n",
    "        \"\"\"Generate GP predictions (in log-space)\"\"\"\n",
    "        from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "        # ===========================================================\n",
    "        # Apply regime filter \n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        df_brand_test = self.df_test[self.df_test['month'] >= start_date].copy()\n",
    "        \n",
    "        feature_cols = gp_data['feature_cols']\n",
    "        target_col = gp_data['target_col']\n",
    "        \n",
    "        y_raw = df_brand_train[target_col].values\n",
    "        y_log = transform_target(y_raw)\n",
    "        \n",
    "        X_raw = df_brand_train[feature_cols].values\n",
    "        X_test_raw = df_brand_test[feature_cols].values\n",
    "        \n",
    "        scaler_X_full = scalers['X_scaler']\n",
    "        scaler_y_full = scalers['y_scaler']\n",
    "        \n",
    "        cv_preds_log = []\n",
    "        splits = self._create_walk_forward_splits(len(X_raw))\n",
    "        \n",
    "        for split in splits:\n",
    "            # Subsample for speed\n",
    "            train_idx = split['train']\n",
    "            if len(train_idx) > 1000:\n",
    "                train_idx = train_idx[-1000:]\n",
    "            \n",
    "            scaler_X = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "            \n",
    "            X_train_sc = scaler_X.fit_transform(X_raw[train_idx])\n",
    "            X_val_sc = scaler_X.transform(X_raw[split['test']])\n",
    "            y_train_log_fold = y_log[train_idx]\n",
    "            y_train_sc = scaler_y.fit_transform(y_train_log_fold.reshape(-1, 1)).ravel()\n",
    "            \n",
    "            # Recreate kernel (simplified - use RBF)\n",
    "            from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel as C\n",
    "            kernel = C(1.0) * RBF(1.0) + WhiteKernel(1e-3)\n",
    "            \n",
    "            model = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, n_restarts_optimizer=0, normalize_y=False)\n",
    "            model.fit(X_train_sc, y_train_sc)\n",
    "            \n",
    "            pred_sc = model.predict(X_val_sc)\n",
    "            pred_log = scaler_y.inverse_transform(pred_sc.reshape(-1, 1)).ravel()\n",
    "            cv_preds_log.extend(pred_log)\n",
    "        \n",
    "        # Holdout (use trained model + scalers)\n",
    "        X_test_sc = scaler_X_full.transform(X_test_raw)\n",
    "        pred_sc = trained_model.predict(X_test_sc)\n",
    "        holdout_pred_log = scaler_y_full.inverse_transform(pred_sc.reshape(-1, 1)).ravel()\n",
    "        \n",
    "        return np.array(cv_preds_log), holdout_pred_log\n",
    "\n",
    "    def build_ensemble_for_brand(self, brand, max_iterations=100, early_stop_rounds=10):\n",
    "        \"\"\"Build Caruana ensemble - averages in LOG-SPACE, inverse transforms once\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"CARUANA ENSEMBLE OPTIMIZATION: {brand}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Get actuals (RAW scale for evaluation)\n",
    "        y_cv_raw = self._get_cv_actuals(brand)\n",
    "\n",
    "        # ===========================================================\n",
    "        # Apply regime filter for holdout (consistency with training)\n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_test = self.df_test[self.df_test['month'] >= start_date].copy()\n",
    "        \n",
    "        target_col = f'{brand}_units'\n",
    "        if target_col not in df_brand_test.columns:\n",
    "            target_col = f'{brand.lower()}_units'\n",
    "        y_holdout_raw = df_brand_test[target_col].values\n",
    "        \n",
    "        model_names = list(self.all_cv_predictions[brand].keys())\n",
    "        print(f\"Base models ({len(model_names)}): {', '.join(model_names)}\")\n",
    "        \n",
    "        # Align lengths\n",
    "        min_len = min(len(y_cv_raw), min([len(p) for p in self.all_cv_predictions[brand].values()]))\n",
    "        y_cv_raw = y_cv_raw[-min_len:]\n",
    "        for model in model_names:\n",
    "            self.all_cv_predictions[brand][model] = self.all_cv_predictions[brand][model][-min_len:]\n",
    "        \n",
    "        # Evaluate individual models\n",
    "        print(f\"\\nIndividual Model CV Performance (on original scale):\")\n",
    "        print(f\"{'Model':<18} {'CV MAPE':<12} {'Holdout MAPE':<15}\")\n",
    "        print(\"‚îÄ\" * 50)\n",
    "        \n",
    "        self.individual_cv_scores[brand] = {}\n",
    "        self.individual_holdout_scores[brand] = {}\n",
    "        \n",
    "        for model in model_names:\n",
    "            # Inverse transform predictions for evaluation\n",
    "            cv_pred_real = inverse_transform_target(self.all_cv_predictions[brand][model])\n",
    "            holdout_pred_real = inverse_transform_target(self.all_holdout_predictions[brand][model])\n",
    "            \n",
    "            cv_mape = mean_absolute_percentage_error(y_cv_raw, cv_pred_real) * 100\n",
    "            holdout_mape = mean_absolute_percentage_error(y_holdout_raw, holdout_pred_real) * 100\n",
    "            \n",
    "            print(f\"{model:<18} {cv_mape:>11.2f}% {holdout_mape:>14.2f}%\")\n",
    "            \n",
    "            self.individual_cv_scores[brand][model] = cv_mape\n",
    "            self.individual_holdout_scores[brand][model] = holdout_mape\n",
    "        \n",
    "        # Greedy forward selection (in log-space)\n",
    "        ensemble = []\n",
    "        best_cv_score = float('inf')\n",
    "        no_improvement_count = 0\n",
    "        \n",
    "        print(f\"\\nGreedy forward selection (averaging in log-space)...\")\n",
    "        print(f\"{'Iter':<6} {'Added Model':<18} {'Size':<6} {'CV MAPE':<12} {'Improvement':<12}\")\n",
    "        print(\"‚îÄ\" * 70)\n",
    "        \n",
    "        for i in range(max_iterations):\n",
    "            best_add = None\n",
    "            best_score = float('inf')\n",
    "            \n",
    "            for model in model_names:\n",
    "                candidate_ensemble = ensemble + [model]\n",
    "                \n",
    "                # Average in LOG-SPACE\n",
    "                ensemble_pred_log = self._get_ensemble_prediction_log(candidate_ensemble, brand, 'cv')\n",
    "                # Inverse transform for evaluation\n",
    "                ensemble_pred_real = inverse_transform_target(ensemble_pred_log)\n",
    "                \n",
    "                score = mean_absolute_percentage_error(y_cv_raw, ensemble_pred_real) * 100\n",
    "                \n",
    "                if score < best_score:\n",
    "                    best_add = model\n",
    "                    best_score = score\n",
    "            \n",
    "            ensemble.append(best_add)\n",
    "            improvement = best_cv_score - best_score\n",
    "            \n",
    "            if improvement > 0.01:\n",
    "                best_cv_score = best_score\n",
    "                no_improvement_count = 0\n",
    "                print(f\"{i+1:<6} {best_add:<18} {len(ensemble):<6} {best_cv_score:<11.2f}% {improvement:>+11.2f}%\")\n",
    "            else:\n",
    "                no_improvement_count += 1\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"{i+1:<6} {best_add:<18} {len(ensemble):<6} {best_cv_score:<11.2f}% {'no change':>11}\")\n",
    "            \n",
    "            if no_improvement_count >= early_stop_rounds:\n",
    "                print(f\"\\nEarly stopping: No improvement for {early_stop_rounds} iterations\")\n",
    "                break\n",
    "        \n",
    "        # Calculate weights\n",
    "        weights = {model: ensemble.count(model) / len(ensemble) for model in set(ensemble)}\n",
    "        self.ensemble_weights[brand] = weights\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"ENSEMBLE COMPOSITION\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        print(f\"{'Model':<18} {'Weight':<10} {'Selections':<12}\")\n",
    "        print(\"‚îÄ\" * 50)\n",
    "        \n",
    "        for model, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"{model:<18} {weight:<9.4f} {ensemble.count(model):<12}\")\n",
    "        \n",
    "        # ===========================================================\n",
    "        # Calculate True Ensemble Variance (Re-Fold)\n",
    "        # ===========================================================\n",
    "        final_cv_preds_log = self._get_ensemble_prediction_log(ensemble, brand, 'cv')\n",
    "        final_cv_preds_real = inverse_transform_target(final_cv_preds_log)\n",
    "        \n",
    "        # Re-create splits to match the base models\n",
    "        splits = self._create_walk_forward_splits(len(y_cv_raw))\n",
    "        \n",
    "        fold_scores = []\n",
    "        current_idx = 0\n",
    "        \n",
    "        for split in splits:\n",
    "            fold_len = len(split['test'])\n",
    "            # Extract the segment corresponding to this fold\n",
    "            y_pred_fold = final_cv_preds_real[current_idx : current_idx + fold_len]\n",
    "            y_true_fold = y_cv_raw[current_idx : current_idx + fold_len]\n",
    "            \n",
    "            # Calculate MAPE for this specific fold\n",
    "            if len(y_true_fold) > 0:\n",
    "                fold_mape = mean_absolute_percentage_error(y_true_fold, y_pred_fold) * 100\n",
    "                fold_scores.append(fold_mape)\n",
    "            \n",
    "            current_idx += fold_len\n",
    "            \n",
    "        # Calculate standard deviation across folds\n",
    "        ensemble_std = np.std(fold_scores) if fold_scores else 0.0\n",
    "\n",
    "        # Evaluate ensemble on holdout\n",
    "        holdout_pred_log = self._get_ensemble_prediction_log(ensemble, brand, 'holdout')\n",
    "        holdout_pred_real = inverse_transform_target(holdout_pred_log)\n",
    "        \n",
    "        holdout_mape = mean_absolute_percentage_error(y_holdout_raw, holdout_pred_real) * 100\n",
    "        holdout_rmse = np.sqrt(np.mean((y_holdout_raw - holdout_pred_real)**2))\n",
    "        holdout_r2 = 1 - (np.sum((y_holdout_raw - holdout_pred_real)**2) / np.sum((y_holdout_raw - y_holdout_raw.mean())**2))\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"FINAL PERFORMANCE (original scale)\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        print(f\"CV MAPE:       {best_cv_score:.2f}% (¬±{ensemble_std:.2f}%)\")  # ‚Üê FIX: Show std\n",
    "        print(f\"Holdout MAPE:  {holdout_mape:.2f}%\")\n",
    "        print(f\"Holdout RMSE:  {holdout_rmse:,.0f}\")\n",
    "        print(f\"Holdout R¬≤:    {holdout_r2:.4f}\")\n",
    "        \n",
    "        self.cv_results[brand] = {'cv_mape_mean': best_cv_score, 'cv_mape_std': ensemble_std, 'ensemble_size': len(ensemble)}\n",
    "        self.holdout_results[brand] = {\n",
    "            'test_mape': holdout_mape,\n",
    "            'test_rmse': holdout_rmse,\n",
    "            'test_r2': holdout_r2\n",
    "        }\n",
    "        \n",
    "        return weights, best_cv_score, holdout_mape\n",
    "\n",
    "    def _get_cv_actuals(self, brand):\n",
    "        \"\"\"Get actual values (RAW scale) aligned with CV predictions\"\"\"\n",
    "        # ===========================================================\n",
    "        # Apply regime filter \n",
    "        # ===========================================================\n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_train = self.df_train[self.df_train['month'] >= start_date].copy()\n",
    "        \n",
    "        target_col = f'{brand}_units'\n",
    "        if target_col not in df_brand_train.columns:\n",
    "            target_col = f'{brand.lower()}_units'\n",
    "        \n",
    "        y = df_brand_train[target_col].values\n",
    "        splits = self._create_walk_forward_splits(len(y))\n",
    "        \n",
    "        cv_actuals = []\n",
    "        for split in splits:\n",
    "            cv_actuals.extend(y[split['test']])\n",
    "        \n",
    "        return np.array(cv_actuals)\n",
    "\n",
    "    def _get_ensemble_prediction_log(self, ensemble, brand, split_type):\n",
    "        \"\"\"Average predictions in LOG-SPACE\"\"\"\n",
    "        preds = self.all_cv_predictions[brand] if split_type == 'cv' else self.all_holdout_predictions[brand]\n",
    "        \n",
    "        # Average in log-space\n",
    "        final_pred_log = np.zeros_like(list(preds.values())[0])\n",
    "        for model in ensemble:\n",
    "            final_pred_log += preds[model]\n",
    "        \n",
    "        return final_pred_log / len(ensemble)\n",
    "\n",
    "    def _create_walk_forward_splits(self, n_samples: int):\n",
    "        \"\"\"\n",
    "        Anchored walk-forward CV ending at most recent training data\n",
    "        \n",
    "        Design:\n",
    "        - Last fold ALWAYS tests the most recent 12 months\n",
    "        - Expanding window (training grows chronologically)\n",
    "        - Non-overlapping 12-month test sets\n",
    "        - Auto-adjusts fold count if insufficient data\n",
    "        \"\"\"\n",
    "        test_size = 12  # Full seasonal cycle\n",
    "        n_folds = 5\n",
    "        min_train = 60  # 5 years minimum \n",
    "        \n",
    "        # Anchor: last test set ends at most recent data\n",
    "        last_test_end = n_samples\n",
    "        last_test_start = last_test_end - test_size\n",
    "        \n",
    "        # Calculate where first fold would start\n",
    "        first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        # Safety: ensure minimum training data\n",
    "        if first_train_end < min_train:\n",
    "            # Reduce folds to fit\n",
    "            max_possible_folds = (last_test_start - min_train) // test_size + 1\n",
    "            n_folds = max(2, int(max_possible_folds))\n",
    "            first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        # Build splits chronologically\n",
    "        splits = []\n",
    "        for i in range(n_folds):\n",
    "            train_end = first_train_end + (i * test_size)\n",
    "            test_start = train_end\n",
    "            test_end = test_start + test_size\n",
    "            \n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "            \n",
    "            # Validate\n",
    "            if train_end < min_train:\n",
    "                continue\n",
    "            \n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(test_start, test_end))\n",
    "            })\n",
    "        \n",
    "        if not splits:\n",
    "            # Emergency fallback: single split\n",
    "            train_end = max(min_train, n_samples - test_size)\n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(train_end, n_samples))\n",
    "            })\n",
    "        \n",
    "        return splits\n",
    "\n",
    "    def optimize_all_brands(self):\n",
    "        \"\"\"Build ensembles for all brands\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"BUILDING ENSEMBLES FOR ALL BRANDS\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Architecture: Log-Space Averaging + Regime-Filter\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            self.build_ensemble_for_brand(brand)\n",
    "        \n",
    "        # ===========================================================\n",
    "        # FINAL SUMMARY TABLE \n",
    "        # ===========================================================\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ENSEMBLE FINAL RESULTS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary = []\n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            cv = self.cv_results[brand]\n",
    "            holdout = self.holdout_results[brand]\n",
    "            best_individual = min(self.individual_holdout_scores[brand].items(), key=lambda x: x[1])\n",
    "            improvement = best_individual[1] - holdout['test_mape']\n",
    "            \n",
    "            summary.append({\n",
    "                'Brand': brand,\n",
    "                'CV MAPE': f\"{cv['cv_mape_mean']:.2f}% (¬±{cv['cv_mape_std']:.2f}%)\",  # ‚Üê FIX: Added std\n",
    "                'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "                'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "                'Best Individual': f\"{best_individual[0]} ({best_individual[1]:.2f}%)\",\n",
    "                'Improvement': f\"{improvement:+.2f}%\"\n",
    "            })\n",
    "        \n",
    "        print(\"\\n\" + pd.DataFrame(summary).to_string(index=False))\n",
    "        \n",
    "        return self.cv_results, self.holdout_results, self.ensemble_weights\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE\n",
    "# ================================================================\n",
    "if run_training:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CARUANA ENSEMBLE OPTIMIZATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Models: SARIMAX, XGBoost, LightGBM, Prophet√ó2, CatBoost, GP\")\n",
    "    print(\"‚öôÔ∏è  Averaging in LOG-SPACE for variance stabilization\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    ensemble_optimizer = CaruanaEnsembleOptimizer(df_train, df_test)\n",
    "    \n",
    "    ensemble_optimizer.generate_all_predictions(\n",
    "        sarimax_best_params, sarimax_trained_models, sarimax_optimizer.scalers,  # ‚Üê FIX: Added scalers\n",
    "        xgboost_best_params, xgboost_trained_models, xgboost_optimizer.scalers,\n",
    "        lightgbm_best_params, lightgbm_trained_models, lightgbm_optimizer.scalers,\n",
    "        prophet_best_params, prophet_trained_models,\n",
    "        prophet_uni_best_params, prophet_uni_trained_models,\n",
    "        catboost_best_params, catboost_trained_models, catboost_optimizer.scalers,\n",
    "        gp_best_params, gp_trained_models, gp_optimizer.scalers\n",
    "    )\n",
    "    \n",
    "    ensemble_optimizer.optimize_all_brands()\n",
    "    \n",
    "    with open(ENSEMBLE_CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'cv_results': ensemble_optimizer.cv_results,\n",
    "            'holdout_results': ensemble_optimizer.holdout_results,\n",
    "            'ensemble_weights': ensemble_optimizer.ensemble_weights\n",
    "        }, f)\n",
    "    print(f\"\\nüíæ Results Saved to {ENSEMBLE_CACHE_FILE}\")\n",
    "    \n",
    "    ensemble_cv_results = ensemble_optimizer.cv_results\n",
    "    ensemble_holdout_results = ensemble_optimizer.holdout_results\n",
    "    ensemble_weights = ensemble_optimizer.ensemble_weights\n",
    "    \n",
    "    print(\"\\n‚úÖ Ensemble optimization complete\")\n",
    "else:\n",
    "    print(\"\\n‚ö° Skipped training (loaded from cache).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae28262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# FINAL ENSEMBLE SUMMARY TABLE\n",
    "# ================================================================\n",
    "\n",
    "ensemble_summary_list = []\n",
    "\n",
    "for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "    # Retrieve results\n",
    "    # Check if keys exist (safe access)\n",
    "    if brand in ensemble_cv_results:\n",
    "        cv_score = ensemble_cv_results[brand]['cv_mape_mean']\n",
    "        holdout = ensemble_holdout_results[brand]\n",
    "        weights = ensemble_weights[brand]\n",
    "        \n",
    "        # Sort weights to find the top contributing models\n",
    "        sorted_weights = sorted(weights.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Format the \"Model Composition\" string (e.g., \"CatBoost (40%), SARIMAX (30%)\")\n",
    "        composition_str = \", \".join([f\"{model} ({weight:.0%})\" for model, weight in sorted_weights[:3]])\n",
    "        \n",
    "        ensemble_summary_list.append({\n",
    "            'Brand': brand,\n",
    "            'Ensemble CV MAPE': f\"{cv_score:.2f}%\",\n",
    "            'Holdout MAPE': f\"{holdout['test_mape']:.2f}%\",\n",
    "            'Holdout R¬≤': f\"{holdout['test_r2']:.4f}\",\n",
    "            'Top 3 Models (by Weight)': composition_str\n",
    "        })\n",
    "\n",
    "df_ensemble_summary = pd.DataFrame(ensemble_summary_list)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL ENSEMBLE PERFORMANCE & COMPOSITION\")\n",
    "print(\"=\"*70)\n",
    "display(df_ensemble_summary)\n",
    "\n",
    "# Optional: Print full weight breakdown if needed\n",
    "print(\"\\nDetailed Model Weights:\")\n",
    "for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "    print(f\"\\n{brand}:\")\n",
    "    weights = ensemble_weights.get(brand, {})\n",
    "    for m, w in sorted(weights.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  - {m}: {w:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Load all cached results if kernel was restarted\n",
    "# ================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING MODEL RESULTS FROM CACHE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cache_files = {\n",
    "    'sarimax': 'sarimax_results.pkl',\n",
    "    'xgboost': 'xgboost_results.pkl',\n",
    "    'prophet': 'prophet_results.pkl',\n",
    "    'prophet_uni': 'prophet_uni_results.pkl',\n",
    "    'lightgbm': 'lightgbm_results.pkl',\n",
    "    'catboost': 'catboost_results.pkl',       \n",
    "    'gaussian_process': 'gp_results.pkl',      \n",
    "    'ensemble': 'ensemble_results.pkl'\n",
    "}\n",
    "\n",
    "# 1. Load SARIMAX\n",
    "if os.path.exists(cache_files['sarimax']):\n",
    "    with open(cache_files['sarimax'], 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    sarimax_cv_results = cached['cv_results']\n",
    "    sarimax_holdout_results = cached['holdout_results']\n",
    "    sarimax_best_params = cached['best_params']\n",
    "    print(\"‚úì SARIMAX loaded\")\n",
    "else:\n",
    "    print(\"‚úó SARIMAX not found - run Cell 12A first\")\n",
    "\n",
    "# 2. Load XGBoost\n",
    "if os.path.exists(cache_files['xgboost']):\n",
    "    with open(cache_files['xgboost'], 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    xgboost_cv_results = cached['cv_results']\n",
    "    xgboost_holdout_results = cached['holdout_results']\n",
    "    xgboost_best_params = cached['best_params']\n",
    "    print(\"‚úì XGBoost loaded\")\n",
    "else:\n",
    "    print(\"‚úó XGBoost not found - run Cell 12B first\")\n",
    "\n",
    "# 3. Load Prophet (Multivariate)\n",
    "if os.path.exists(cache_files['prophet']):\n",
    "    with open(cache_files['prophet'], 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    prophet_cv_results = cached['cv_results']\n",
    "    prophet_holdout_results = cached['holdout_results']\n",
    "    prophet_best_params = cached['best_params']\n",
    "    print(\"‚úì Prophet-Multi loaded\")\n",
    "else:\n",
    "    print(\"‚úó Prophet-Multi not found - run Cell 12C first\")\n",
    "\n",
    "# 4. Load Prophet (Univariate)\n",
    "if os.path.exists(cache_files['prophet_uni']):\n",
    "    with open(cache_files['prophet_uni'], 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    prophet_uni_cv_results = cached['cv_results']\n",
    "    prophet_uni_holdout_results = cached['holdout_results']\n",
    "    prophet_uni_best_params = cached['best_params']\n",
    "    print(\"‚úì Prophet-Uni loaded\")\n",
    "else:\n",
    "    print(\"‚úó Prophet-Uni not found - run Cell 12C2 first\")\n",
    "\n",
    "# 5. Load LightGBM\n",
    "if os.path.exists(cache_files['lightgbm']):\n",
    "    with open(cache_files['lightgbm'], 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    lightgbm_cv_results = cached['cv_results']\n",
    "    lightgbm_holdout_results = cached['holdout_results']\n",
    "    lightgbm_best_params = cached['best_params']\n",
    "    print(\"‚úì LightGBM loaded\")\n",
    "else:\n",
    "    print(\"‚úó LightGBM not found - run Cell 12D first\")\n",
    "\n",
    "# 6. Load CatBoost \n",
    "if os.path.exists(cache_files['catboost']):\n",
    "    with open(cache_files['catboost'], 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    catboost_cv_results = cached['cv_results']\n",
    "    catboost_holdout_results = cached['holdout_results']\n",
    "    catboost_best_params = cached['best_params']\n",
    "    print(\"‚úì CatBoost loaded\")\n",
    "else:\n",
    "    print(\"‚úó CatBoost not found - run Cell 12F first\")\n",
    "\n",
    "# 7. Load Gaussian Process \n",
    "if os.path.exists(cache_files['gaussian_process']):\n",
    "    with open(cache_files['gaussian_process'], 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    gp_cv_results = cached['cv_results']\n",
    "    gp_holdout_results = cached['holdout_results']\n",
    "    gp_best_params = cached['best_params']\n",
    "    # Note: Trained models and scalers are also in the pickle if needed\n",
    "    print(\"‚úì Gaussian Process loaded\")\n",
    "else:\n",
    "    print(\"‚úó Gaussian Process not found - run Cell 12E first\")\n",
    "\n",
    "# 8. Load Ensemble\n",
    "if os.path.exists(cache_files['ensemble']):\n",
    "    with open(cache_files['ensemble'], 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    ensemble_cv_results = cached['cv_results']\n",
    "    ensemble_holdout_results = cached['holdout_results']\n",
    "    ensemble_weights = cached['ensemble_weights']\n",
    "    print(\"‚úì Ensemble loaded\")\n",
    "else:\n",
    "    print(\"‚úó Ensemble not found - run Cell 12G first\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfe8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Robust Model Selection + Business Metrics\n",
    "# ================================================================\n",
    "\n",
    "class RobustModelSelector:\n",
    "    \"\"\"\n",
    "    Pure data-driven model selection \n",
    "    Compares 8 models: SARIMAX, XGBoost, LightGBM, Prophet-Multi, Prophet-Uni, CatBoost, GP, Ensemble\n",
    "    \n",
    "    LOG-SCALING AWARENESS:\n",
    "    - All models trained on log-transformed targets\n",
    "    - All metrics already calculated on original scale (after inverse transform)\n",
    "    - This selector just compares the metrics (no additional transforms)\n",
    "    \n",
    "    Selection criteria weighted by importance:\n",
    "    1. Holdout MAPE (60% weight) - What matters in production\n",
    "    2. CV MAPE (25% weight) - Generalization ability  \n",
    "    3. R¬≤ score (15% weight) - Variance explained\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_test=None):\n",
    "        self.selected_models = {}\n",
    "        self.all_scores = {}\n",
    "        self.model_rankings = {}\n",
    "        self.df_test = df_test  # For business metrics calculation\n",
    "        self.enhanced_metrics = {}  # Store business metrics\n",
    "        self.baseline_comparison = {}  # Store baseline comparison\n",
    "    \n",
    "    def select_best_models(\n",
    "        self,\n",
    "        sarimax_cv, xgboost_cv, lightgbm_cv,\n",
    "        prophet_cv, prophet_uni_cv,\n",
    "        catboost_cv, gp_cv,\n",
    "        ensemble_cv,\n",
    "        sarimax_holdout, xgboost_holdout, lightgbm_holdout,\n",
    "        prophet_holdout, prophet_uni_holdout,\n",
    "        catboost_holdout, gp_holdout,\n",
    "        ensemble_holdout\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Select best model for each brand using weighted scoring\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"ROBUST MODEL SELECTION (8 MODELS + LOG-SCALING)\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Models: SARIMAX, XGBoost, LightGBM, Prophet√ó2, CatBoost, GP, Ensemble\")\n",
    "        print(\"\\n‚öôÔ∏è  All models trained on log-scale\")\n",
    "        print(\"üìä Metrics evaluated on original scale (inverse-transformed)\")\n",
    "        print(\"\\nWeighted Criteria:\")\n",
    "        print(\"  ‚Ä¢ Holdout MAPE: 60% (production performance)\")\n",
    "        print(\"  ‚Ä¢ CV MAPE: 25% (generalization)\")\n",
    "        print(\"  ‚Ä¢ R¬≤ Score: 15% (explained variance)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        brands = ['Apple', 'Samsung', 'Google', 'Motorola']\n",
    "        \n",
    "        # Store holdout results for business metrics extraction\n",
    "        self.holdout_results = {\n",
    "            'SARIMAX': sarimax_holdout,\n",
    "            'XGBoost': xgboost_holdout,\n",
    "            'LightGBM': lightgbm_holdout,\n",
    "            'Prophet-Multi': prophet_holdout,\n",
    "            'Prophet-Uni': prophet_uni_holdout,\n",
    "            'CatBoost': catboost_holdout,\n",
    "            'GP': gp_holdout,\n",
    "            'Ensemble': ensemble_holdout\n",
    "        }\n",
    "        \n",
    "        for brand in brands:\n",
    "            print(f\"\\n{'‚îÄ'*70}\")\n",
    "            print(f\"SELECTING BEST MODEL: {brand}\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "            \n",
    "            # Gather all results (8 models)\n",
    "            candidates = {\n",
    "                'SARIMAX': {\n",
    "                    'cv_mape': sarimax_cv[brand].get('cv_mape_mean', 999.0),\n",
    "                    'cv_std': sarimax_cv[brand].get('cv_mape_std', 0.0),\n",
    "                    'holdout_mape': sarimax_holdout[brand]['test_mape'],\n",
    "                    'holdout_rmse': sarimax_holdout[brand]['test_rmse'],\n",
    "                    'r2': sarimax_holdout[brand].get('test_r2', 0.0)\n",
    "                },\n",
    "                'XGBoost': {\n",
    "                    'cv_mape': xgboost_cv[brand].get('cv_mape_mean', 999.0),\n",
    "                    'cv_std': xgboost_cv[brand].get('cv_mape_std', 0.0),\n",
    "                    'holdout_mape': xgboost_holdout[brand]['test_mape'],\n",
    "                    'holdout_rmse': xgboost_holdout[brand]['test_rmse'],\n",
    "                    'r2': xgboost_holdout[brand]['test_r2']\n",
    "                },\n",
    "                'LightGBM': {\n",
    "                    'cv_mape': lightgbm_cv[brand].get('cv_mape_mean', 999.0),\n",
    "                    'cv_std': lightgbm_cv[brand].get('cv_mape_std', 0.0),\n",
    "                    'holdout_mape': lightgbm_holdout[brand]['test_mape'],\n",
    "                    'holdout_rmse': lightgbm_holdout[brand]['test_rmse'],\n",
    "                    'r2': lightgbm_holdout[brand]['test_r2']\n",
    "                },\n",
    "                'Prophet-Multi': {\n",
    "                    'cv_mape': prophet_cv[brand].get('cv_mape_mean', 999.0),\n",
    "                    'cv_std': prophet_cv[brand].get('cv_mape_std', 0.0),\n",
    "                    'holdout_mape': prophet_holdout[brand]['test_mape'],\n",
    "                    'holdout_rmse': prophet_holdout[brand]['test_rmse'],\n",
    "                    'r2': prophet_holdout[brand]['test_r2']\n",
    "                },\n",
    "                'Prophet-Uni': {\n",
    "                    'cv_mape': prophet_uni_cv[brand].get('cv_mape_mean', 999.0),\n",
    "                    'cv_std': prophet_uni_cv[brand].get('cv_mape_std', 0.0),\n",
    "                    'holdout_mape': prophet_uni_holdout[brand]['test_mape'],\n",
    "                    'holdout_rmse': prophet_uni_holdout[brand]['test_rmse'],\n",
    "                    'r2': prophet_uni_holdout[brand]['test_r2']\n",
    "                },\n",
    "                'CatBoost': {\n",
    "                    'cv_mape': catboost_cv[brand].get('cv_mape_mean', 999.0),\n",
    "                    'cv_std': catboost_cv[brand].get('cv_mape_std', 0.0),\n",
    "                    'holdout_mape': catboost_holdout[brand]['test_mape'],\n",
    "                    'holdout_rmse': catboost_holdout[brand]['test_rmse'],\n",
    "                    'r2': catboost_holdout[brand]['test_r2']\n",
    "                },\n",
    "                'GP': {\n",
    "                    'cv_mape': gp_cv[brand].get('cv_mape_mean', 999.0),\n",
    "                    'cv_std': gp_cv[brand].get('cv_mape_std', 0.0),\n",
    "                    'holdout_mape': gp_holdout[brand]['test_mape'],\n",
    "                    'holdout_rmse': gp_holdout[brand]['test_rmse'],\n",
    "                    'r2': gp_holdout[brand]['test_r2']\n",
    "                },\n",
    "                'Ensemble': {\n",
    "                    'cv_mape': ensemble_cv[brand].get('cv_mape_mean', 999.0),\n",
    "                    'cv_std': ensemble_cv[brand].get('cv_mape_std', 0.0),\n",
    "                    'holdout_mape': ensemble_holdout[brand]['test_mape'],\n",
    "                    'holdout_rmse': ensemble_holdout[brand]['test_rmse'],\n",
    "                    'r2': ensemble_holdout[brand]['test_r2']\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Display all candidates\n",
    "            print(\"\\nCandidate Models (all metrics on original scale):\")\n",
    "            print(f\"{'Model':<15} {'Holdout MAPE':>14} {'CV MAPE':>12} {'CV Std':>10} {'R¬≤':>10}\")\n",
    "            print(\"‚îÄ\" * 70)\n",
    "            \n",
    "            for model_name, metrics in sorted(candidates.items(), key=lambda x: x[1]['holdout_mape']):\n",
    "                r2_str = f\"{metrics['r2']:.4f}\"\n",
    "                print(f\"{model_name:<15} {metrics['holdout_mape']:>13.2f}% \"\n",
    "                      f\"{metrics['cv_mape']:>11.2f}% {metrics['cv_std']:>9.2f}% {r2_str:>10}\")\n",
    "            \n",
    "            # Calculate scores and select\n",
    "            scores = self._calculate_weighted_scores(brand, candidates)\n",
    "            best_model_name = max(scores.keys(), key=lambda m: scores[m]['total_score'])\n",
    "            \n",
    "            # Store selection\n",
    "            self.selected_models[brand] = {\n",
    "                'model': best_model_name,\n",
    "                'holdout_mape': candidates[best_model_name]['holdout_mape'],\n",
    "                'cv_mape': candidates[best_model_name]['cv_mape'],\n",
    "                'cv_std': candidates[best_model_name]['cv_std'],\n",
    "                'r2': candidates[best_model_name]['r2'],\n",
    "                'holdout_rmse': candidates[best_model_name]['holdout_rmse'],\n",
    "                'score': scores[best_model_name]['total_score'],\n",
    "                'score_breakdown': scores[best_model_name]\n",
    "            }\n",
    "            \n",
    "            self.all_scores[brand] = scores\n",
    "            \n",
    "            # Store rankings\n",
    "            self.model_rankings[brand] = sorted(\n",
    "                scores.items(),\n",
    "                key=lambda x: x[1]['total_score'],\n",
    "                reverse=True\n",
    "            )\n",
    "            \n",
    "            # Display scores\n",
    "            print(f\"\\nWeighted Scores (higher = better):\")\n",
    "            print(f\"{'Rank':<6} {'Model':<15} {'Total Score':>12} {'Detail':<45}\")\n",
    "            print(\"‚îÄ\" * 80)\n",
    "            \n",
    "            for rank, (model, s) in enumerate(self.model_rankings[brand], 1):\n",
    "                detail = f\"H:{s['holdout_score']:.1f} + CV:{s['cv_score']:.1f} + R¬≤:{s['r2_score']:.1f}\"\n",
    "                marker = \"üèÜ\" if rank == 1 else f\"{rank}.\"\n",
    "                print(f\"{marker:<6} {model:<15} {s['total_score']:>11.1f}  {detail:<45}\")\n",
    "            \n",
    "            print(f\"\\nüèÜ SELECTED: {best_model_name}\")\n",
    "            print(f\"   Holdout MAPE: {candidates[best_model_name]['holdout_mape']:.2f}%\")\n",
    "            print(f\"   Holdout RMSE: {candidates[best_model_name]['holdout_rmse']:,.0f}\")\n",
    "            print(f\"   Total Score: {scores[best_model_name]['total_score']:.1f}\")\n",
    "            \n",
    "            # Show why it won\n",
    "            self._explain_selection(brand, best_model_name, scores, candidates)\n",
    "        \n",
    "        # Calculate business metrics\n",
    "        if self.df_test is not None:\n",
    "            self._calculate_business_metrics()\n",
    "        \n",
    "        # Compare against baselines\n",
    "        if 'BASELINE_TARGETS' in CONF:\n",
    "            self._compare_against_baselines()\n",
    "        \n",
    "        # Summary\n",
    "        self._print_summary()\n",
    "        \n",
    "        return self.selected_models\n",
    "    \n",
    "    def _calculate_weighted_scores(self, brand, candidates):\n",
    "        \"\"\"\n",
    "        Calculate weighted scores for all models\n",
    "        Lower MAPE = higher score, Higher R¬≤ = higher score\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        \n",
    "        # Get min/max for normalization\n",
    "        holdout_mapes = [c['holdout_mape'] for c in candidates.values()]\n",
    "        cv_mapes = [c['cv_mape'] for c in candidates.values()]\n",
    "        r2_values = [c['r2'] for c in candidates.values()]\n",
    "        \n",
    "        min_holdout = min(holdout_mapes)\n",
    "        max_holdout = max(holdout_mapes)\n",
    "        min_cv = min(cv_mapes)\n",
    "        max_cv = max(cv_mapes)\n",
    "        min_r2 = min(r2_values)\n",
    "        max_r2 = max(r2_values)\n",
    "        \n",
    "        for model_name, metrics in candidates.items():\n",
    "            # Normalize holdout MAPE (lower is better, so invert)\n",
    "            if max_holdout > min_holdout:\n",
    "                holdout_score = 100 * (1 - (metrics['holdout_mape'] - min_holdout) / (max_holdout - min_holdout))\n",
    "            else:\n",
    "                holdout_score = 100\n",
    "            \n",
    "            # Normalize CV MAPE (lower is better, so invert)\n",
    "            if max_cv > min_cv:\n",
    "                cv_score = 100 * (1 - (metrics['cv_mape'] - min_cv) / (max_cv - min_cv))\n",
    "            else:\n",
    "                cv_score = 100\n",
    "            \n",
    "            # Normalize R¬≤ (higher is better)\n",
    "            if max_r2 > min_r2:\n",
    "                r2_score = 100 * (metrics['r2'] - min_r2) / (max_r2 - min_r2)\n",
    "            else:\n",
    "                r2_score = 100 if metrics['r2'] >= 0 else 0\n",
    "            \n",
    "            # Handle negative R¬≤ (model failure)\n",
    "            if metrics['r2'] < -0.5:\n",
    "                r2_score = 0\n",
    "                holdout_score *= 0.5  # Penalize catastrophic failures\n",
    "            \n",
    "            # Weighted total (60% holdout, 25% CV, 15% R¬≤)\n",
    "            total_score = (\n",
    "                0.60 * holdout_score +\n",
    "                0.25 * cv_score +\n",
    "                0.15 * r2_score\n",
    "            )\n",
    "\n",
    "            if model_name == 'Ensemble':\n",
    "                total_score *= 0.85 # Slight penalty for complexity\n",
    "            \n",
    "            scores[model_name] = {\n",
    "                'holdout_score': holdout_score,\n",
    "                'cv_score': cv_score,\n",
    "                'r2_score': r2_score,\n",
    "                'total_score': total_score\n",
    "            }\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def _calculate_business_metrics(self):\n",
    "        \"\"\"\n",
    "        Calculate business-relevant metrics beyond MAPE\n",
    "        \"\"\"\n",
    "    \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"BUSINESS METRICS ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "    \n",
    "        for brand in self.selected_models.keys():\n",
    "            selected_model = self.selected_models[brand]['model']\n",
    "        \n",
    "            # Get holdout data for the selected model\n",
    "            holdout_data = self.holdout_results[selected_model][brand]\n",
    "        \n",
    "            # CHECK ALL POSSIBLE PREDICTION KEY NAMES\n",
    "            y_pred = None\n",
    "            for key in ['test_predictions', 'predictions', 'pred']:\n",
    "                if key in holdout_data:\n",
    "                    y_pred = holdout_data[key]\n",
    "                    break\n",
    "        \n",
    "            if y_pred is None:\n",
    "                print(f\"\\n‚ö†Ô∏è  {brand} ({selected_model}): No predictions found in keys {list(holdout_data.keys())}\")\n",
    "                continue\n",
    "        \n",
    "            # Get actuals\n",
    "            target_col = f'{brand}_units'\n",
    "            if target_col not in self.df_test.columns:\n",
    "                print(f\"\\n‚ö†Ô∏è  {brand}: {target_col} not in df_test\")\n",
    "                continue\n",
    "        \n",
    "            y_true = self.df_test[target_col].values\n",
    "        \n",
    "            # Validate length match\n",
    "            if len(y_pred) != len(y_true):\n",
    "                print(f\"\\n‚ö†Ô∏è  {brand}: Length mismatch (pred={len(y_pred)}, true={len(y_true)})\")\n",
    "                continue\n",
    "        \n",
    "            # Calculate metrics\n",
    "            metrics = {}\n",
    "        \n",
    "            # 1. MAPE (use stored value for consistency)\n",
    "            metrics['mape'] = self.selected_models[brand]['holdout_mape']\n",
    "        \n",
    "            # 2. BIAS (Mean Percentage Error)\n",
    "            mask = y_true > 0\n",
    "            if mask.sum() > 0:\n",
    "                metrics['bias'] = np.mean((y_pred[mask] - y_true[mask]) / y_true[mask]) * 100\n",
    "            else:\n",
    "                metrics['bias'] = 0.0\n",
    "        \n",
    "            # 3. DIRECTIONAL ACCURACY\n",
    "            if len(y_true) >= 2:\n",
    "                actual_direction = np.sign(np.diff(y_true))\n",
    "                pred_direction = np.sign(np.diff(y_pred))\n",
    "                metrics['directional_accuracy'] = np.mean(actual_direction == pred_direction)\n",
    "            else:\n",
    "                metrics['directional_accuracy'] = 0.0\n",
    "        \n",
    "            # 4. Q4 ERROR \n",
    "            q4_mask = self.df_test['month'].dt.quarter == 4\n",
    "            if q4_mask.sum() > 0:\n",
    "                y_true_q4 = y_true[q4_mask]\n",
    "                y_pred_q4 = y_pred[q4_mask]\n",
    "                mask_q4 = y_true_q4 > 0\n",
    "                if mask_q4.sum() > 0:\n",
    "                    metrics['q4_mape'] = mean_absolute_percentage_error(\n",
    "                        y_true_q4[mask_q4], y_pred_q4[mask_q4]\n",
    "                    ) * 100\n",
    "                else:\n",
    "                    metrics['q4_mape'] = None\n",
    "            else:\n",
    "                metrics['q4_mape'] = None\n",
    "        \n",
    "            # 5. LAUNCH MONTH ERROR \n",
    "            launch_col = f'launch_{brand.lower()}'\n",
    "            if launch_col in self.df_test.columns:\n",
    "                launch_mask = self.df_test[launch_col] == 1\n",
    "                if launch_mask.sum() > 0:\n",
    "                    y_true_launch = y_true[launch_mask]\n",
    "                    y_pred_launch = y_pred[launch_mask]\n",
    "                    mask_launch = y_true_launch > 0\n",
    "                    if mask_launch.sum() > 0:\n",
    "                        metrics['launch_mape'] = mean_absolute_percentage_error(\n",
    "                            y_true_launch[mask_launch], y_pred_launch[mask_launch]\n",
    "                        ) * 100\n",
    "                    else:\n",
    "                        metrics['launch_mape'] = None\n",
    "                else:\n",
    "                    metrics['launch_mape'] = None\n",
    "            else:\n",
    "                metrics['launch_mape'] = None\n",
    "        \n",
    "            # Store\n",
    "            self.enhanced_metrics[brand] = metrics\n",
    "        \n",
    "            # Display\n",
    "            print(f\"\\n{brand} ({selected_model}):\")\n",
    "            print(f\"  MAPE: {metrics['mape']:.2f}%\")\n",
    "        \n",
    "            bias_label = \"Overforecast\" if metrics['bias'] > 0 else \"Underforecast\"\n",
    "            bias_severity = \"‚ö†Ô∏è HIGH\" if abs(metrics['bias']) > 10 else \"‚úì Low\"\n",
    "            print(f\"  Bias: {metrics['bias']:+.2f}% ({bias_label}) [{bias_severity}]\")\n",
    "        \n",
    "            dir_pct = metrics['directional_accuracy'] * 100\n",
    "            dir_status = \"‚úÖ Excellent\" if dir_pct >= 80 else \"‚úì Good\" if dir_pct >= 70 else \"‚ö†Ô∏è Poor\"\n",
    "            print(f\"  Directional Accuracy: {dir_pct:.1f}% [{dir_status}]\")\n",
    "        \n",
    "            if metrics['q4_mape'] is not None:\n",
    "                q4_diff = metrics['q4_mape'] - metrics['mape']\n",
    "                q4_status = \"‚ö†Ô∏è Worse\" if q4_diff > 5 else \"‚úì Similar\" if abs(q4_diff) <= 5 else \"‚úÖ Better\"\n",
    "                print(f\"  Q4 MAPE: {metrics['q4_mape']:.2f}% ({q4_diff:+.1f}pp vs overall) [{q4_status}]\")\n",
    "        \n",
    "            if metrics['launch_mape'] is not None:\n",
    "                launch_diff = metrics['launch_mape'] - metrics['mape']\n",
    "                launch_status = \"‚ö†Ô∏è Worse\" if launch_diff > 10 else \"‚úì Similar\"\n",
    "                print(f\"  Launch MAPE: {metrics['launch_mape']:.2f}% ({launch_diff:+.1f}pp vs overall) [{launch_status}]\")\n",
    "    \n",
    "    def _compare_against_baselines(self):\n",
    "        \"\"\"\n",
    "        Compare ML models against simple baselines\n",
    "        Proves that ML complexity is justified\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"BEATING THE BASELINE?\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Comparing ML models vs simple forecasts (SPLY, Moving Average, etc.)\")\n",
    "        print(f\"\\n{'Brand':<12} {'ML MAPE':>8} {'Best Baseline':>14} {'Improvement':>12} {'Verdict':<15}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "        \n",
    "        for brand in self.selected_models.keys():\n",
    "            if brand not in CONF['BASELINE_TARGETS']:\n",
    "                continue\n",
    "            \n",
    "            # ML performance\n",
    "            ml_mape = self.selected_models[brand]['holdout_mape']\n",
    "            \n",
    "            # Best baseline performance\n",
    "            baseline_mape = CONF['BASELINE_TARGETS'][brand]['mape']\n",
    "            baseline_method = CONF['BASELINE_TARGETS'][brand]['method']\n",
    "            \n",
    "            # Calculate improvement\n",
    "            improvement = ((baseline_mape - ml_mape) / baseline_mape) * 100\n",
    "            \n",
    "            # Verdict Logic \n",
    "            # - Strong: Clearly beats baseline (>5%)\n",
    "            # - Competitive: Statistical tie (-10% to 5%). ML wins on robustness/risk-adjustment.\n",
    "            # - Failed: Significantly worse (<-10%). SPLY is just better.\n",
    "            \n",
    "            if improvement >= 5:\n",
    "                verdict = \"‚úÖ STRONG\"\n",
    "                verdict_full = \"Clear win over baseline\"\n",
    "            elif improvement >= 0:\n",
    "                verdict = \"‚úì WIN\"\n",
    "                verdict_full = \"Beats baseline\"\n",
    "            elif improvement >= -10:\n",
    "                verdict = \"‚ö†Ô∏è COMPETITIVE\"\n",
    "                verdict_full = \"Statistical tie (Robustness adds value)\"\n",
    "            else:\n",
    "                verdict = \"‚ùå FAILED\"\n",
    "                verdict_full = \"Significantly worse than baseline\"\n",
    "            \n",
    "            # Baseline method display name\n",
    "            method_display = {\n",
    "                'naive': 'Naive',\n",
    "                'seasonal_naive': 'SPLY',\n",
    "                'moving_avg_3': 'MA-3',\n",
    "                'moving_avg_6': 'MA-6'\n",
    "            }.get(baseline_method, baseline_method)\n",
    "            \n",
    "            print(f\"{brand:<12} {ml_mape:>7.2f}% {baseline_mape:>7.2f}% ({method_display:>4}) \"\n",
    "                  f\"{improvement:>+10.1f}% {verdict:<15}\")\n",
    "            \n",
    "            # Store for Streamlit\n",
    "            self.baseline_comparison[brand] = {\n",
    "                'ml_mape': ml_mape,\n",
    "                'baseline_mape': baseline_mape,\n",
    "                'baseline_method': baseline_method,\n",
    "                'improvement_pct': improvement,\n",
    "                'verdict': verdict_full\n",
    "            }\n",
    "        \n",
    "        # Calculate overall improvement\n",
    "        if len(self.selected_models) > 0:\n",
    "            avg_ml_mape = np.mean([s['holdout_mape'] for s in self.selected_models.values()])\n",
    "            avg_baseline_mape = CONF.get('BASELINE_TARGET_AVG', 0)\n",
    "            \n",
    "            if avg_baseline_mape > 0:\n",
    "                overall_improvement = ((avg_baseline_mape - avg_ml_mape) / avg_baseline_mape) * 100\n",
    "                \n",
    "                print(f\"{'-'*70}\")\n",
    "                print(f\"{'AVERAGE':<12} {avg_ml_mape:>7.2f}% {avg_baseline_mape:>14.2f}% \"\n",
    "                      f\"{overall_improvement:>+10.1f}%\")\n",
    "                \n",
    "                self.baseline_comparison['overall'] = {\n",
    "                    'ml_mape': avg_ml_mape,\n",
    "                    'baseline_mape': avg_baseline_mape,\n",
    "                    'improvement_pct': overall_improvement\n",
    "                }\n",
    "    \n",
    "    def _explain_selection(self, brand, winner, scores, candidates):\n",
    "        \"\"\"Explain why this model was selected\"\"\"\n",
    "        \n",
    "        sorted_models = sorted(scores.keys(), key=lambda m: scores[m]['total_score'], reverse=True)\n",
    "        \n",
    "        if len(sorted_models) < 2:\n",
    "            return\n",
    "        \n",
    "        runner_up = sorted_models[1]\n",
    "        \n",
    "        winner_mape = candidates[winner]['holdout_mape']\n",
    "        runner_up_mape = candidates[runner_up]['holdout_mape']\n",
    "        mape_diff = runner_up_mape - winner_mape\n",
    "        \n",
    "        score_diff = scores[winner]['total_score'] - scores[runner_up]['total_score']\n",
    "        \n",
    "        print(f\"\\n   Why {winner} beat {runner_up}:\")\n",
    "        \n",
    "        if mape_diff > 0.5:\n",
    "            print(f\"     ‚Ä¢ {mape_diff:.2f}% better holdout MAPE ({winner_mape:.2f}% vs {runner_up_mape:.2f}%)\")\n",
    "        elif mape_diff < -0.5:\n",
    "            print(f\"     ‚Ä¢ Holdout MAPE is {abs(mape_diff):.2f}% worse, but compensated by:\")\n",
    "        else:\n",
    "            print(f\"     ‚Ä¢ Very close holdout MAPE (Œî={mape_diff:.2f}%)\")\n",
    "        \n",
    "        cv_diff = candidates[runner_up]['cv_mape'] - candidates[winner]['cv_mape']\n",
    "        if abs(cv_diff) > 1.0:\n",
    "            if cv_diff > 0:\n",
    "                print(f\"     ‚Ä¢ {cv_diff:.2f}% better CV MAPE (better generalization)\")\n",
    "            else:\n",
    "                print(f\"     ‚Ä¢ Runner-up has {abs(cv_diff):.2f}% better CV, but worse holdout\")\n",
    "        \n",
    "        r2_diff = candidates[winner]['r2'] - candidates[runner_up]['r2']\n",
    "        if abs(r2_diff) > 0.1:\n",
    "            if r2_diff > 0:\n",
    "                print(f\"     ‚Ä¢ {r2_diff:.4f} higher R¬≤ (explains more variance)\")\n",
    "            else:\n",
    "                print(f\"     ‚Ä¢ Runner-up has {abs(r2_diff):.4f} higher R¬≤, but worse MAPE\")\n",
    "        \n",
    "        print(f\"     ‚Ä¢ Overall score advantage: {score_diff:.1f} points\")\n",
    "    \n",
    "    def _print_summary(self):\n",
    "        \"\"\"Print comprehensive final summary\"\"\"\n",
    "        \n",
    "        print(\"\\n\\n\" + \"=\"*70)\n",
    "        print(\"FINAL MODEL SELECTION SUMMARY (LOG-SCALING)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary_data = []\n",
    "        for brand, selection in self.selected_models.items():\n",
    "            summary_data.append({\n",
    "                'Brand': brand,\n",
    "                'Model': selection['model'],\n",
    "                'Holdout MAPE': f\"{selection['holdout_mape']:.2f}%\",\n",
    "                'CV MAPE': f\"{selection['cv_mape']:.2f}%\",\n",
    "                'R¬≤': f\"{selection['r2']:.4f}\",\n",
    "                'Score': f\"{selection['score']:.1f}\"\n",
    "            })\n",
    "        \n",
    "        df_summary = pd.DataFrame(summary_data)\n",
    "        print(\"\\n\" + df_summary.to_string(index=False))\n",
    "        \n",
    "        # Model distribution\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"MODEL DISTRIBUTION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        model_counts = {}\n",
    "        for selection in self.selected_models.values():\n",
    "            model_name = selection['model']\n",
    "            model_counts[model_name] = model_counts.get(model_name, 0) + 1\n",
    "        \n",
    "        for model, count in sorted(model_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            brands_with_model = [b for b, s in self.selected_models.items() if s['model'] == model]\n",
    "            print(f\"  {model}: {count} brand(s) - {', '.join(brands_with_model)}\")\n",
    "        \n",
    "        # Tree models comparison\n",
    "        tree_models = ['XGBoost', 'LightGBM', 'CatBoost']\n",
    "        tree_count = sum(model_counts.get(m, 0) for m in tree_models)\n",
    "        \n",
    "        if tree_count > 0:\n",
    "            print(\"\\n\" + \"‚îÄ\"*70)\n",
    "            print(\"GRADIENT BOOSTING COMPARISON\")\n",
    "            print(\"‚îÄ\"*70)\n",
    "            for model in tree_models:\n",
    "                count = model_counts.get(model, 0)\n",
    "                if count > 0:\n",
    "                    brands = [b for b, s in self.selected_models.items() if s['model'] == model]\n",
    "                    print(f\"  {model}: {count} brand(s) - {', '.join(brands)}\")\n",
    "            \n",
    "            if model_counts.get('CatBoost', 0) > 0:\n",
    "                print(\"  ‚Üí CatBoost selected: Ordered boosting + categorical handling proved valuable\")\n",
    "            if model_counts.get('XGBoost', 0) > model_counts.get('LightGBM', 0):\n",
    "                print(\"  ‚Üí XGBoost dominated over LightGBM\")\n",
    "            elif model_counts.get('LightGBM', 0) > model_counts.get('XGBoost', 0):\n",
    "                print(\"  ‚Üí LightGBM dominated over XGBoost\")\n",
    "        \n",
    "        # GP analysis\n",
    "        gp_count = model_counts.get('GP', 0)\n",
    "        if gp_count > 0:\n",
    "            print(\"\\n\" + \"‚îÄ\"*70)\n",
    "            print(\"GAUSSIAN PROCESS ANALYSIS\")\n",
    "            print(\"‚îÄ\"*70)\n",
    "            brands_with_gp = [b for b, s in self.selected_models.items() if s['model'] == 'GP']\n",
    "            print(f\"  GP selected for {gp_count} brand(s): {', '.join(brands_with_gp)}\")\n",
    "            print(\"  ‚Üí Uncertainty quantification + small-data performance proved optimal\")\n",
    "            print(\"  ‚Üí Log-scaling fixed GP flatline issue (variance stabilization)\")\n",
    "        else:\n",
    "            print(\"\\n\" + \"‚îÄ\"*70)\n",
    "            print(\"GAUSSIAN PROCESS ANALYSIS\")\n",
    "            print(\"‚îÄ\"*70)\n",
    "            print(\"  GP NOT selected for any brand\")\n",
    "            print(\"  ‚Üí Other models achieved better accuracy-speed tradeoff\")\n",
    "        \n",
    "        # Ensemble analysis\n",
    "        ensemble_count = model_counts.get('Ensemble', 0)\n",
    "        if ensemble_count > 0:\n",
    "            print(\"\\n\" + \"‚îÄ\"*70)\n",
    "            print(\"ENSEMBLE SELECTION ANALYSIS\")\n",
    "            print(\"‚îÄ\"*70)\n",
    "            brands_with_ensemble = [b for b, s in self.selected_models.items() if s['model'] == 'Ensemble']\n",
    "            print(f\"  Ensemble selected for {ensemble_count} brand(s): {', '.join(brands_with_ensemble)}\")\n",
    "            print(\"  ‚Üí Caruana stacking successfully improved over single models\")\n",
    "            print(\"  ‚Üí Averaging in log-space maintained variance stabilization\")\n",
    "        else:\n",
    "            print(\"\\n\" + \"‚îÄ\"*70)\n",
    "            print(\"ENSEMBLE SELECTION ANALYSIS\")\n",
    "            print(\"‚îÄ\"*70)\n",
    "            print(\"  Ensemble NOT selected for any brand\")\n",
    "            print(\"  ‚Üí Single models already optimal (ensemble couldn't improve)\")\n",
    "        \n",
    "        # Prophet comparison\n",
    "        prophet_multi_count = model_counts.get('Prophet-Multi', 0)\n",
    "        prophet_uni_count = model_counts.get('Prophet-Uni', 0)\n",
    "        \n",
    "        if prophet_multi_count > 0 or prophet_uni_count > 0:\n",
    "            print(\"\\n\" + \"‚îÄ\"*70)\n",
    "            print(\"PROPHET VARIANT COMPARISON\")\n",
    "            print(\"‚îÄ\"*70)\n",
    "            if prophet_multi_count > 0:\n",
    "                brands = [b for b, s in self.selected_models.items() if s['model'] == 'Prophet-Multi']\n",
    "                print(f\"  Prophet with regressors: {prophet_multi_count} brand(s) - {', '.join(brands)}\")\n",
    "            if prophet_uni_count > 0:\n",
    "                brands = [b for b, s in self.selected_models.items() if s['model'] == 'Prophet-Uni']\n",
    "                print(f\"  Prophet univariate: {prophet_uni_count} brand(s) - {', '.join(brands)}\")\n",
    "            \n",
    "            if prophet_uni_count > prophet_multi_count:\n",
    "                print(\"  ‚Üí Univariate approach performed better overall\")\n",
    "            elif prophet_multi_count > prophet_uni_count:\n",
    "                print(\"  ‚Üí External regressors provided value\")\n",
    "        \n",
    "        # SARIMAX analysis\n",
    "        sarimax_count = model_counts.get('SARIMAX', 0)\n",
    "        if sarimax_count > 0:\n",
    "            print(\"\\n\" + \"‚îÄ\"*70)\n",
    "            print(\"SARIMAX ANALYSIS\")\n",
    "            print(\"‚îÄ\"*70)\n",
    "            brands = [b for b, s in self.selected_models.items() if s['model'] == 'SARIMAX']\n",
    "            print(f\"  SARIMAX selected for {sarimax_count} brand(s): {', '.join(brands)}\")\n",
    "            print(\"  ‚Üí Statistical time series methods competitive with ML\")\n",
    "        \n",
    "        # Performance summary\n",
    "        avg_mape = np.mean([s['holdout_mape'] for s in self.selected_models.values()])\n",
    "        avg_r2 = np.mean([s['r2'] for s in self.selected_models.values()])\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"OVERALL PERFORMANCE (LOG-SCALING BENEFITS)\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"  Average Holdout MAPE: {avg_mape:.2f}%\")\n",
    "        print(f\"  Average R¬≤: {avg_r2:.4f}\")\n",
    "        \n",
    "        if avg_mape < 10:\n",
    "            print(\"\\n  üéâ EXCELLENT - Outstanding production-ready performance!\")\n",
    "            print(\"     ‚Üí Log-scaling + feature engineering highly effective\")\n",
    "        elif avg_mape < 15:\n",
    "            print(\"\\n  ‚úÖ VERY GOOD - High-quality production forecasts\")\n",
    "            print(\"     ‚Üí Log-scaling stabilized variance effectively\")\n",
    "        elif avg_mape < 20:\n",
    "            print(\"\\n  ‚úì GOOD - Acceptable for production use\")\n",
    "        else:\n",
    "            print(\"\\n  ‚ö†Ô∏è ACCEPTABLE - Review individual brand performance\")\n",
    "        \n",
    "        # Business metrics summary\n",
    "        if self.enhanced_metrics:\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(\"BUSINESS METRICS SUMMARY\")\n",
    "            print(\"=\"*70)\n",
    "            \n",
    "            avg_bias = np.mean([m['bias'] for m in self.enhanced_metrics.values()])\n",
    "            avg_dir_acc = np.mean([m['directional_accuracy'] for m in self.enhanced_metrics.values()])\n",
    "            \n",
    "            print(f\"  Average Bias: {avg_bias:+.2f}% ({'Overforecast' if avg_bias > 0 else 'Underforecast'})\")\n",
    "            print(f\"  Average Directional Accuracy: {avg_dir_acc*100:.1f}%\")\n",
    "            \n",
    "            if abs(avg_bias) < 5 and avg_dir_acc > 0.75:\n",
    "                print(\"  ‚úÖ Models are well-calibrated and directionally accurate\")\n",
    "            elif abs(avg_bias) > 10:\n",
    "                print(\"  ‚ö†Ô∏è  High bias detected - consider recalibration\")\n",
    "            elif avg_dir_acc < 0.65:\n",
    "                print(\"  ‚ö†Ô∏è  Low directional accuracy - trend prediction needs improvement\")\n",
    "        \n",
    "        # Baseline comparison summary\n",
    "        if self.baseline_comparison and len(self.baseline_comparison) > 1:  # More than just 'overall'\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(\"BASELINE COMPARISON SUMMARY\")\n",
    "            print(\"=\"*70)\n",
    "            \n",
    "            if 'overall' in self.baseline_comparison:\n",
    "                overall = self.baseline_comparison['overall']\n",
    "                print(f\"  ML Average: {overall['ml_mape']:.2f}% MAPE\")\n",
    "                print(f\"  Baseline Average: {overall['baseline_mape']:.2f}% MAPE\")\n",
    "                print(f\"  Improvement: {overall['improvement_pct']:+.1f}%\")\n",
    "                \n",
    "                if overall['improvement_pct'] >= 15:\n",
    "                    print(\"  ‚úÖ ML models show strong improvement over baselines\")\n",
    "                    print(\"     ‚Üí Complexity is justified\")\n",
    "                elif overall['improvement_pct'] >= 5:\n",
    "                    print(\"  ‚úì ML models show marginal improvement over baselines\")\n",
    "                elif overall['improvement_pct'] < 0:\n",
    "                    print(\"  ‚ùå ML models WORSE than baselines - review feature engineering\")\n",
    "        \n",
    "        # Detailed breakdown\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PERFORMANCE BREAKDOWN BY BRAND\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            if brand not in self.selected_models:\n",
    "                continue\n",
    "            \n",
    "            sel = self.selected_models[brand]\n",
    "            print(f\"\\n{brand} ‚Üí {sel['model']}\")\n",
    "            print(f\"  Production Error: {sel['holdout_mape']:.2f}% MAPE\")\n",
    "            print(f\"  Generalization: {sel['cv_mape']:.2f}% ¬±{sel['cv_std']:.2f}% (CV)\")\n",
    "            print(f\"  Variance Explained: {sel['r2']:.2%} (R¬≤)\")\n",
    "            print(f\"  RMSE: {sel['holdout_rmse']:,.0f} units\")\n",
    "            \n",
    "            # Add business metrics if available\n",
    "            if brand in self.enhanced_metrics:\n",
    "                em = self.enhanced_metrics[brand]\n",
    "                print(f\"  Bias: {em['bias']:+.2f}%\")\n",
    "                print(f\"  Directional Accuracy: {em['directional_accuracy']*100:.1f}%\")\n",
    "            \n",
    "            # Add baseline comparison if available\n",
    "            if brand in self.baseline_comparison:\n",
    "                bc = self.baseline_comparison[brand]\n",
    "                print(f\"  vs Baseline: {bc['improvement_pct']:+.1f}% improvement ({bc['verdict']})\")\n",
    "            \n",
    "            print(f\"  Top 3 Models:\")\n",
    "            for rank, (model, score_data) in enumerate(self.model_rankings[brand][:3], 1):\n",
    "                print(f\"    {rank}. {model} (Score: {score_data['total_score']:.1f})\")\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING ROBUST MODEL SELECTION (8 MODELS + LOG-SCALING)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize with df_test for business metrics\n",
    "selector = RobustModelSelector(df_test=df_test if 'df_test' in globals() else None)\n",
    "\n",
    "final_model_selection = selector.select_best_models(\n",
    "    sarimax_cv_results,\n",
    "    xgboost_cv_results,\n",
    "    lightgbm_cv_results,\n",
    "    prophet_cv_results,\n",
    "    prophet_uni_cv_results,\n",
    "    catboost_cv_results,\n",
    "    gp_cv_results,\n",
    "    ensemble_cv_results,\n",
    "    sarimax_holdout_results,\n",
    "    xgboost_holdout_results,\n",
    "    lightgbm_holdout_results,\n",
    "    prophet_holdout_results,\n",
    "    prophet_uni_holdout_results,\n",
    "    catboost_holdout_results,\n",
    "    gp_holdout_results,\n",
    "    ensemble_holdout_results\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Model selection complete (log-scaling aware)\")\n",
    "print(\"Selected models stored in: final_model_selection\")\n",
    "\n",
    "# Store enhanced metrics in CONF for state freezing\n",
    "if selector.enhanced_metrics:\n",
    "    CONF['ENHANCED_METRICS'] = selector.enhanced_metrics\n",
    "    print(\"‚úÖ Enhanced metrics stored in CONF['ENHANCED_METRICS']\")\n",
    "\n",
    "if selector.baseline_comparison:\n",
    "    CONF['BASELINE_COMPARISON'] = selector.baseline_comparison\n",
    "    print(\"‚úÖ Baseline comparison stored in CONF['BASELINE_COMPARISON']\")\n",
    "\n",
    "# Save model selection results\n",
    "SELECTION_CACHE_FILE = 'model_selection.pkl'\n",
    "\n",
    "with open(SELECTION_CACHE_FILE, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'selected_models': final_model_selection,\n",
    "        'all_scores': selector.all_scores,\n",
    "        'model_rankings': selector.model_rankings,\n",
    "        'enhanced_metrics': selector.enhanced_metrics,  # NEW\n",
    "        'baseline_comparison': selector.baseline_comparison  # NEW\n",
    "    }, f)\n",
    "\n",
    "print(f\"\\nüíæ Saved model selection to {SELECTION_CACHE_FILE}\")\n",
    "\n",
    "# Display final selections\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SELECTIONS\")\n",
    "print(\"=\"*70)\n",
    "for brand, selection in final_model_selection.items():\n",
    "    print(f\"{brand:>10}: {selection['model']} ({selection['holdout_mape']:.2f}% MAPE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee27d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Final Selection Visualization\n",
    "# ================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Set visuals\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VISUALIZING MODEL LEADERBOARD BY BRAND\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "brands = ['Apple', 'Samsung', 'Google', 'Motorola']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Access rankings from the selector object\n",
    "rankings = selector.model_rankings\n",
    "\n",
    "for idx, brand in enumerate(brands):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Extract data for this brand\n",
    "    brand_ranks = rankings[brand]\n",
    "    \n",
    "    # Create DataFrame for plotting\n",
    "    plot_data = []\n",
    "    for model_name, metrics in brand_ranks:\n",
    "        plot_data.append({\n",
    "            'Model': model_name,\n",
    "            'Total Score': metrics['total_score'],\n",
    "            'Holdout MAPE': metrics['holdout_score'] # Scaled score\n",
    "        })\n",
    "    \n",
    "    df_plot = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Color palette: Highlight the winner\n",
    "    colors = ['#2ecc71' if i == 0 else '#95a5a6' for i in range(len(df_plot))]\n",
    "    \n",
    "    # Plot Bar Chart (Total Score)\n",
    "    sns.barplot(data=df_plot, x='Total Score', y='Model', ax=ax, palette=colors)\n",
    "    \n",
    "    # Annotations\n",
    "    ax.set_title(f\"{brand} Model Leaderboard\", fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel(\"Weighted Score (0-100)\", fontsize=10)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlim(0, 110)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(df_plot['Total Score']):\n",
    "        ax.text(v + 1, i, f\"{v:.1f}\", color='black', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä INTERPRETATION:\")\n",
    "print(\"‚Ä¢ Green Bar: The selected 'Winner' for production.\")\n",
    "print(\"‚Ä¢ Gray Bars: The contenders.\")\n",
    "print(\"‚Ä¢ The score combines Accuracy (60%), Stability (25%), and Fit (15%).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc11ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Final Model Training on FULL DATA with Log-Scaling\n",
    "# ================================================================\n",
    "\n",
    "# ================================================================\n",
    "# CACHING & INITIALIZATION\n",
    "# ================================================================\n",
    "\n",
    "FINAL_MODELS_CACHE_FILE = 'final_production_models.pkl'\n",
    "run_training = True\n",
    "\n",
    "# Cache file mapping for loading pre-optimized params \n",
    "MODEL_CACHE_FILES = {\n",
    "    'SARIMAX': 'sarimax_results.pkl',\n",
    "    'XGBoost': 'xgboost_results.pkl',\n",
    "    'LightGBM': 'lightgbm_results.pkl',\n",
    "    'Prophet-Multi': 'prophet_results.pkl',\n",
    "    'Prophet-Uni': 'prophet_uni_results.pkl',\n",
    "    'CatBoost': 'catboost_results.pkl',\n",
    "    'GP': 'gp_results.pkl'\n",
    "}\n",
    "\n",
    "if os.path.exists(FINAL_MODELS_CACHE_FILE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING CACHED FINAL PRODUCTION MODELS\")\n",
    "    print(\"=\"*70)\n",
    "    with open(FINAL_MODELS_CACHE_FILE, 'rb') as f:\n",
    "        cached = pickle.load(f)\n",
    "    production_models = cached['production_models']\n",
    "    production_params = cached['production_params']\n",
    "    production_cv_performance = cached['production_cv_performance']\n",
    "    production_scalers = cached.get('production_scalers', {})\n",
    "    run_training = False\n",
    "    print(\"‚úÖ Loaded cached final production models\")\n",
    "    print(\"To retrain, delete:\", FINAL_MODELS_CACHE_FILE)\n",
    "else:\n",
    "    print(\"No cache found - training final models from scratch...\")\n",
    "    \n",
    "    # Load model selection if kernel was restarted\n",
    "    SELECTION_CACHE_FILE = 'model_selection.pkl'\n",
    "    if 'final_model_selection' not in globals():\n",
    "        if os.path.exists(SELECTION_CACHE_FILE):\n",
    "            with open(SELECTION_CACHE_FILE, 'rb') as f:\n",
    "                selection_data = pickle.load(f)\n",
    "                final_model_selection = selection_data.get('selected_models', selection_data)\n",
    "            print(\"‚úì Loaded model selection from cache\")\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Run Cell 13 first to select models!\")\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# MAIN TRAINER CLASS\n",
    "# ================================================================\n",
    "\n",
    "class FinalModelTrainer:\n",
    "    \"\"\"\n",
    "    Train final production models on FULL dataset (train + test combined)\n",
    "    \n",
    "    DESIGN:\n",
    "    - Single models: Optimize + fit on full data\n",
    "    - Ensemble: Load params from cache, fit ALL base models on full data\n",
    "    - NO model reuse \n",
    "    - All models see 2025 data for accurate 2026 forecasting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_full, stat_results):\n",
    "        self.df_full = df_full\n",
    "        self.stat_results = stat_results\n",
    "        self.final_models = {}\n",
    "        self.final_params = {}\n",
    "        self.cv_performance = {}\n",
    "        self.scalers = {}\n",
    "\n",
    "    # ================================================================\n",
    "    # PUBLIC API\n",
    "    # ================================================================\n",
    "    \n",
    "    def train_final_models(self, model_selection, n_trials=50):\n",
    "        \"\"\"Train final production models with log-scaling\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"FINAL PRODUCTION MODEL TRAINING (8 MODELS + LOG-SCALING)\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"‚öôÔ∏è  Training on FULL dataset (train + test combined)\")\n",
    "        print(\"üìä All models use log-transformed targets\")\n",
    "        print(f\"üîß Hyperparameter optimization: {n_trials} trials per brand\")\n",
    "        print(\"üìÖ Brand-specific regime filtering applied\")\n",
    "        print(\"üéØ Anchored walk-forward CV (ending at most recent data)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        brands = ['Apple', 'Samsung', 'Google', 'Motorola']\n",
    "        \n",
    "        for brand in brands:\n",
    "            selected_model = model_selection[brand]['model']\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"BRAND: {brand} | SELECTED: {selected_model}\")\n",
    "            print(f\"{'='*70}\")\n",
    "            \n",
    "            if selected_model == 'Ensemble':\n",
    "                self._train_final_ensemble(brand, n_trials)\n",
    "            elif selected_model == 'SARIMAX':\n",
    "                self._train_final_sarimax(brand, n_trials)\n",
    "            elif selected_model == 'XGBoost':\n",
    "                self._train_final_xgboost(brand, n_trials)\n",
    "            elif selected_model == 'LightGBM':\n",
    "                self._train_final_lightgbm(brand, n_trials)\n",
    "            elif selected_model == 'Prophet-Multi':\n",
    "                self._train_final_prophet(brand, n_trials, multivariate=True)\n",
    "            elif selected_model == 'Prophet-Uni':\n",
    "                self._train_final_prophet(brand, n_trials, multivariate=False)\n",
    "            elif selected_model == 'CatBoost':\n",
    "                self._train_final_catboost(brand, n_trials)\n",
    "            elif selected_model == 'GP':\n",
    "                self._train_final_gp(brand, n_trials)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model type: {selected_model}\")\n",
    "        \n",
    "        self._print_summary(model_selection)\n",
    "        return self.final_models, self.final_params, self.cv_performance\n",
    "\n",
    "    # ================================================================\n",
    "    # ENSEMBLE TRAINER (Fit-Only Mode for Base Models)\n",
    "    # ================================================================\n",
    "    \n",
    "    def _train_final_ensemble(self, brand, n_trials):\n",
    "        \"\"\"\n",
    "        Build ensemble by training ALL base models on full data\n",
    "        \"\"\"\n",
    "        \n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        print(f\"\\nüìÖ Production training: {start_date} (Ensemble - Fit-Only Mode)\")\n",
    "        \n",
    "        # 1. Load Ensemble Weights from Cell 12G\n",
    "        weights = self._load_ensemble_weights(brand)\n",
    "        \n",
    "        print(f\"‚úì Loaded ensemble weights from Cell 12G:\")\n",
    "        for model, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"    {model}: {weight:.4f}\")\n",
    "        \n",
    "        # 2. Train Base Models (Fit Only - Params from Cache)\n",
    "        base_models = {}\n",
    "        base_scalers = {}\n",
    "        \n",
    "        # Only train models with non-zero weights\n",
    "        active_models = [m for m, w in weights.items() if w > 0.0]\n",
    "        \n",
    "        print(f\"\\nüèóÔ∏è  Training {len(active_models)} base models on full data...\")\n",
    "        \n",
    "        for model_type in active_models:\n",
    "            print(f\"  ‚ûú {model_type}...\", end=\"\", flush=True)\n",
    "            \n",
    "            # Load pre-optimized params\n",
    "            params = self._load_params_from_cache(model_type, brand)\n",
    "            \n",
    "            # Fit model on FULL data\n",
    "            model, scaler = self._fit_model_on_full_data(brand, model_type, params)\n",
    "            \n",
    "            base_models[model_type] = model\n",
    "            if scaler:\n",
    "                base_scalers[model_type] = scaler\n",
    "            \n",
    "            print(\" ‚úì\")\n",
    "        \n",
    "        # 3. Store Ensemble Bundle\n",
    "        self.final_models[brand] = {\n",
    "            'type': 'ensemble',\n",
    "            'weights': weights,\n",
    "            'base_models': base_models  # Trained models stored here\n",
    "        }\n",
    "        \n",
    "        self.scalers[brand] = base_scalers  # Dict of scalers per base model\n",
    "        \n",
    "        self.final_params[brand] = {\n",
    "            'type': 'ensemble',\n",
    "            'weights': weights,\n",
    "            'start_date': start_date\n",
    "        }\n",
    "        \n",
    "        # Load CV score \n",
    "        cv_mape = self._load_ensemble_cv_score(brand)\n",
    "        self.cv_performance[brand] = cv_mape\n",
    "        \n",
    "        print(f\"\\n‚úì Ensemble built | {len(active_models)} base models | CV MAPE: {cv_mape:.2f}% (from Cell 12G)\")\n",
    "\n",
    "    # ================================================================\n",
    "    # SINGLE MODEL TRAINERS (Optimize + Fit)\n",
    "    # ================================================================\n",
    "    \n",
    "    def _train_final_sarimax(self, brand, n_trials):\n",
    "        \"\"\"Train SARIMAX with optimization\"\"\"\n",
    "        from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "        \n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_full = self.df_full[self.df_full['month'] >= start_date].copy()\n",
    "        print(f\"\\nüìÖ Production training: {start_date} ‚Üí {len(df_brand_full)} months\")\n",
    "        \n",
    "        target_col = self._get_target_col(brand)\n",
    "        y_raw = df_brand_full[target_col].values\n",
    "        y_log = transform_target(y_raw)\n",
    "        \n",
    "        exog_cols = [f'launch_{brand.lower()}', 'is_holiday_season', \n",
    "                     'is_back_to_school', 'is_black_friday', 'cpi_index']\n",
    "        exog_cols = [c for c in exog_cols if c in df_brand_full.columns]\n",
    "        X = df_brand_full[exog_cols].values if exog_cols else None\n",
    "        \n",
    "        recommended_d = self.stat_results['stationarity'][brand]['recommended_d']\n",
    "\n",
    "        def objective(trial):\n",
    "            p = trial.suggest_int('p', 0, 3)\n",
    "            q = trial.suggest_int('q', 0, 3)\n",
    "            P = trial.suggest_int('P', 0, 2)\n",
    "            Q = trial.suggest_int('Q', 0, 2)\n",
    "            \n",
    "            order = (p, recommended_d, q)\n",
    "            seasonal_order = (P, 1, Q, 12)\n",
    "            \n",
    "            splits = self._create_walk_forward_splits(len(y_log))\n",
    "            scores = []\n",
    "            \n",
    "            for s in splits:\n",
    "                try:\n",
    "                    mod = SARIMAX(\n",
    "                        y_log[s['train']], \n",
    "                        exog=X[s['train']] if X is not None else None,\n",
    "                        order=order, \n",
    "                        seasonal_order=seasonal_order, \n",
    "                        enforce_stationarity=False, \n",
    "                        enforce_invertibility=False\n",
    "                    )\n",
    "                    res = mod.fit(disp=False, maxiter=200, method='lbfgs')\n",
    "                    \n",
    "                    pred_log = res.forecast(\n",
    "                        steps=len(s['test']), \n",
    "                        exog=X[s['test']] if X is not None else None\n",
    "                    )\n",
    "                    \n",
    "                    pred_real = inverse_transform_target(pred_log)\n",
    "                    y_test_real = y_raw[s['test']]\n",
    "                    \n",
    "                    scores.append(mean_absolute_percentage_error(y_test_real, pred_real) * 100)\n",
    "                except:\n",
    "                    scores.append(999)\n",
    "            \n",
    "            return np.mean(scores) if scores else 999\n",
    "\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "        \n",
    "        bp = study.best_params\n",
    "        final_order = (bp['p'], recommended_d, bp['q'])\n",
    "        final_seasonal = (bp['P'], 1, bp['Q'], 12)\n",
    "        \n",
    "        final_model = SARIMAX(\n",
    "            y_log, \n",
    "            exog=X, \n",
    "            order=final_order, \n",
    "            seasonal_order=final_seasonal, \n",
    "            enforce_stationarity=False, \n",
    "            enforce_invertibility=False\n",
    "        ).fit(disp=False, maxiter=200, method='lbfgs')\n",
    "        \n",
    "        self.final_models[brand] = final_model\n",
    "        self.final_params[brand] = {\n",
    "            'order': final_order, \n",
    "            'seasonal_order': final_seasonal, \n",
    "            'exog_cols': exog_cols, \n",
    "            'target_col': target_col,\n",
    "            'start_date': start_date\n",
    "        }\n",
    "        self.cv_performance[brand] = study.best_value\n",
    "        print(f\"‚úì SARIMAX trained | CV MAPE: {study.best_value:.2f}% | Params: {final_order}\")\n",
    "\n",
    "    def _train_final_xgboost(self, brand, n_trials):\n",
    "        \"\"\"Train XGBoost with optimization\"\"\"\n",
    "        import xgboost as xgb\n",
    "        \n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_full = self.df_full[self.df_full['month'] >= start_date].copy()\n",
    "        print(f\"\\nüìÖ Production training: {start_date} ‚Üí {len(df_brand_full)} months\")\n",
    "        \n",
    "        X_raw, y_raw, features, target_col = self._get_ml_data(brand, df_brand_full)\n",
    "        y_log = transform_target(y_raw)\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "                'random_state': 42, 'n_jobs': -1\n",
    "            }\n",
    "            \n",
    "            splits = self._create_walk_forward_splits(len(X_raw))\n",
    "            scores = []\n",
    "            \n",
    "            for s in splits:\n",
    "                try:\n",
    "                    scaler = StandardScaler()\n",
    "                    X_train_sc = scaler.fit_transform(X_raw[s['train']])\n",
    "                    X_test_sc = scaler.transform(X_raw[s['test']])\n",
    "                    \n",
    "                    mod = xgb.XGBRegressor(**params)\n",
    "                    mod.fit(X_train_sc, y_log[s['train']], verbose=False)\n",
    "                    \n",
    "                    pred_log = mod.predict(X_test_sc)\n",
    "                    pred_real = inverse_transform_target(pred_log)\n",
    "                    \n",
    "                    scores.append(mean_absolute_percentage_error(y_raw[s['test']], pred_real) * 100)\n",
    "                except:\n",
    "                    scores.append(999)\n",
    "            \n",
    "            return np.mean(scores) if scores else 999\n",
    "\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_raw)\n",
    "        self.scalers[brand] = scaler\n",
    "        \n",
    "        final_model = xgb.XGBRegressor(**study.best_params, n_jobs=-1)\n",
    "        final_model.fit(X_scaled, y_log, verbose=False)\n",
    "        \n",
    "        self.final_models[brand] = final_model\n",
    "        self.final_params[brand] = {\n",
    "            'params': study.best_params, \n",
    "            'feature_cols': features, \n",
    "            'target_col': target_col,\n",
    "            'start_date': start_date\n",
    "        }\n",
    "        self.cv_performance[brand] = study.best_value\n",
    "        print(f\"‚úì XGBoost trained | CV MAPE: {study.best_value:.2f}%\")\n",
    "\n",
    "    def _train_final_lightgbm(self, brand, n_trials):\n",
    "        \"\"\"Train LightGBM with optimization\"\"\"\n",
    "        import lightgbm as lgb\n",
    "        \n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_full = self.df_full[self.df_full['month'] >= start_date].copy()\n",
    "        print(f\"\\nüìÖ Production training: {start_date} ‚Üí {len(df_brand_full)} months\")\n",
    "        \n",
    "        X_raw, y_raw, features, target_col = self._get_ml_data(brand, df_brand_full)\n",
    "        y_log = transform_target(y_raw)\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "                'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "                'random_state': 42, 'verbose': -1, 'n_jobs': -1\n",
    "            }\n",
    "            \n",
    "            splits = self._create_walk_forward_splits(len(X_raw))\n",
    "            scores = []\n",
    "            \n",
    "            for s in splits:\n",
    "                try:\n",
    "                    scaler = StandardScaler()\n",
    "                    X_train_sc = scaler.fit_transform(X_raw[s['train']])\n",
    "                    X_test_sc = scaler.transform(X_raw[s['test']])\n",
    "                    \n",
    "                    mod = lgb.LGBMRegressor(**params)\n",
    "                    mod.fit(X_train_sc, y_log[s['train']])\n",
    "                    \n",
    "                    pred_log = mod.predict(X_test_sc)\n",
    "                    pred_real = inverse_transform_target(pred_log)\n",
    "                    \n",
    "                    scores.append(mean_absolute_percentage_error(y_raw[s['test']], pred_real) * 100)\n",
    "                except:\n",
    "                    scores.append(999)\n",
    "            \n",
    "            return np.mean(scores) if scores else 999\n",
    "\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_raw)\n",
    "        self.scalers[brand] = scaler\n",
    "        \n",
    "        final_model = lgb.LGBMRegressor(**study.best_params, verbose=-1, n_jobs=-1)\n",
    "        final_model.fit(X_scaled, y_log)\n",
    "        \n",
    "        self.final_models[brand] = final_model\n",
    "        self.final_params[brand] = {\n",
    "            'params': study.best_params, \n",
    "            'feature_cols': features, \n",
    "            'target_col': target_col,\n",
    "            'start_date': start_date\n",
    "        }\n",
    "        self.cv_performance[brand] = study.best_value\n",
    "        print(f\"‚úì LightGBM trained | CV MAPE: {study.best_value:.2f}%\")\n",
    "\n",
    "    def _train_final_catboost(self, brand, n_trials):\n",
    "        \"\"\"Train CatBoost with optimization\"\"\"\n",
    "        from catboost import CatBoostRegressor\n",
    "        \n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_full = self.df_full[self.df_full['month'] >= start_date].copy()\n",
    "        print(f\"\\nüìÖ Production training: {start_date} ‚Üí {len(df_brand_full)} months\")\n",
    "        \n",
    "        target_col = self._get_target_col(brand)\n",
    "        prefix = brand if f'{brand}_lag1' in df_brand_full.columns else brand.lower()\n",
    "        \n",
    "        features = [\n",
    "            f'{prefix}_lag1', f'{prefix}_lag12', f'{prefix}_ma3', f'{prefix}_ma12',\n",
    "            f'launch_{brand.lower()}', 'is_holiday_season', 'is_back_to_school',\n",
    "            'is_black_friday', 'month_num', 'quarter', 'time_index', 'cpi_index'\n",
    "        ]\n",
    "        features = [c for c in features if c in df_brand_full.columns]\n",
    "        cat_features = [c for c in features if c in ['month_num', 'quarter']]\n",
    "        numeric_cols = [c for c in features if c not in cat_features]\n",
    "        \n",
    "        X_raw = df_brand_full[features].copy()\n",
    "        y_raw = df_brand_full[target_col].values\n",
    "        y_log = transform_target(y_raw)\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 100, 500),\n",
    "                'depth': trial.suggest_int('depth', 4, 8),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "                'random_strength': trial.suggest_float('random_strength', 0, 10),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "                'border_count': trial.suggest_int('border_count', 32, 128),\n",
    "                'verbose': False, 'random_state': 42, 'cat_features': cat_features\n",
    "            }\n",
    "            \n",
    "            splits = self._create_walk_forward_splits(len(X_raw))\n",
    "            scores = []\n",
    "            \n",
    "            for s in splits:\n",
    "                try:\n",
    "                    scaler = StandardScaler()\n",
    "                    X_train = X_raw.iloc[s['train']].copy()\n",
    "                    X_test = X_raw.iloc[s['test']].copy()\n",
    "                    \n",
    "                    X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "                    X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "                    \n",
    "                    mod = CatBoostRegressor(**params)\n",
    "                    mod.fit(X_train, y_log[s['train']])\n",
    "                    \n",
    "                    pred_log = mod.predict(X_test)\n",
    "                    pred_real = inverse_transform_target(pred_log)\n",
    "                    \n",
    "                    scores.append(mean_absolute_percentage_error(y_raw[s['test']], pred_real) * 100)\n",
    "                except:\n",
    "                    scores.append(999)\n",
    "            \n",
    "            return np.mean(scores) if scores else 999\n",
    "\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = X_raw.copy()\n",
    "        X_scaled[numeric_cols] = scaler.fit_transform(X_raw[numeric_cols])\n",
    "        self.scalers[brand] = scaler\n",
    "        \n",
    "        final_model = CatBoostRegressor(**study.best_params, verbose=False)\n",
    "        final_model.fit(X_scaled, y_log)\n",
    "        \n",
    "        self.final_models[brand] = final_model\n",
    "        self.final_params[brand] = {\n",
    "            'params': study.best_params, \n",
    "            'feature_cols': features, \n",
    "            'cat_features': cat_features, \n",
    "            'numeric_cols': numeric_cols,\n",
    "            'target_col': target_col,\n",
    "            'start_date': start_date\n",
    "        }\n",
    "        self.cv_performance[brand] = study.best_value\n",
    "        print(f\"‚úì CatBoost trained | CV MAPE: {study.best_value:.2f}%\")\n",
    "\n",
    "    def _train_final_gp(self, brand, n_trials):\n",
    "        \"\"\"Train GP with optimization\"\"\"\n",
    "        from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "        from sklearn.gaussian_process.kernels import (\n",
    "            RBF, Matern, RationalQuadratic, ExpSineSquared, \n",
    "            WhiteKernel, ConstantKernel as C\n",
    "        )\n",
    "        \n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_full = self.df_full[self.df_full['month'] >= start_date].copy()\n",
    "        print(f\"\\nüìÖ Production training: {start_date} ‚Üí {len(df_brand_full)} months\")\n",
    "        \n",
    "        X_raw, y_raw, features, target_col = self._get_ml_data(brand, df_brand_full)\n",
    "        y_log = transform_target(y_raw)\n",
    "\n",
    "        def build_kernel(p):\n",
    "            base = C(1.0, (1e-3, 1e3))\n",
    "            if p['kernel_type'] == 'RBF':\n",
    "                k = base * RBF(length_scale=p['length_scale'])\n",
    "            elif p['kernel_type'] == 'Matern':\n",
    "                k = base * Matern(length_scale=p['length_scale'], nu=p['nu'])\n",
    "            elif p['kernel_type'] == 'RationalQuadratic':\n",
    "                k = base * RationalQuadratic(length_scale=p['length_scale'], alpha=p['rq_alpha'])\n",
    "            else:\n",
    "                k = base * RBF(length_scale=p['length_scale']) + \\\n",
    "                    base * ExpSineSquared(length_scale=1.0, periodicity=p['period'])\n",
    "            return k + WhiteKernel(noise_level=p['alpha'])\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'kernel_type': trial.suggest_categorical('kernel_type', ['RBF', 'Matern', 'RationalQuadratic', 'RBF+Periodic']),\n",
    "                'length_scale': trial.suggest_float('length_scale', 0.1, 10.0, log=True),\n",
    "                'alpha': trial.suggest_float('alpha', 1e-6, 1e-1, log=True)\n",
    "            }\n",
    "            \n",
    "            if params['kernel_type'] == 'Matern':\n",
    "                params['nu'] = trial.suggest_categorical('nu', [0.5, 1.5, 2.5])\n",
    "            if params['kernel_type'] == 'RationalQuadratic':\n",
    "                params['rq_alpha'] = trial.suggest_float('rq_alpha', 0.1, 10.0)\n",
    "            if params['kernel_type'] == 'RBF+Periodic':\n",
    "                params['period'] = trial.suggest_float('period', 10.0, 14.0)\n",
    "            \n",
    "            kernel = build_kernel(params)\n",
    "            splits = self._create_walk_forward_splits(len(X_raw))\n",
    "            scores = []\n",
    "            \n",
    "            for s in splits:\n",
    "                try:\n",
    "                    scaler_X = StandardScaler()\n",
    "                    scaler_y = StandardScaler()\n",
    "                    \n",
    "                    train_idx = s['train'][-1000:] if len(s['train']) > 1000 else s['train']\n",
    "                    \n",
    "                    X_train_sc = scaler_X.fit_transform(X_raw[train_idx])\n",
    "                    X_test_sc = scaler_X.transform(X_raw[s['test']])\n",
    "                    y_train_sc = scaler_y.fit_transform(y_log[train_idx].reshape(-1, 1)).ravel()\n",
    "                    \n",
    "                    mod = GaussianProcessRegressor(kernel=kernel, alpha=params['alpha'], normalize_y=False, n_restarts_optimizer=0)\n",
    "                    mod.fit(X_train_sc, y_train_sc)\n",
    "                    \n",
    "                    pred_sc = mod.predict(X_test_sc)\n",
    "                    pred_log = scaler_y.inverse_transform(pred_sc.reshape(-1, 1)).ravel()\n",
    "                    pred_real = inverse_transform_target(pred_log)\n",
    "                    \n",
    "                    scores.append(mean_absolute_percentage_error(y_raw[s['test']], pred_real) * 100)\n",
    "                except:\n",
    "                    scores.append(999)\n",
    "            \n",
    "            return np.mean(scores) if scores else 999\n",
    "\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "        \n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "        \n",
    "        X_scaled = scaler_X.fit_transform(X_raw)\n",
    "        y_scaled = scaler_y.fit_transform(y_log.reshape(-1, 1)).ravel()\n",
    "        \n",
    "        self.scalers[brand] = {'X_scaler': scaler_X, 'y_scaler': scaler_y}\n",
    "        \n",
    "        final_kernel = build_kernel(study.best_params)\n",
    "        final_model = GaussianProcessRegressor(kernel=final_kernel, alpha=study.best_params['alpha'], normalize_y=False, n_restarts_optimizer=5)\n",
    "        final_model.fit(X_scaled, y_scaled)\n",
    "        \n",
    "        self.final_models[brand] = final_model\n",
    "        self.final_params[brand] = {\n",
    "            'params': study.best_params, \n",
    "            'feature_cols': features, \n",
    "            'target_col': target_col,\n",
    "            'start_date': start_date\n",
    "        }\n",
    "        self.cv_performance[brand] = study.best_value\n",
    "        print(f\"‚úì GP trained | CV MAPE: {study.best_value:.2f}% | Kernel: {study.best_params['kernel_type']}\")\n",
    "\n",
    "    def _train_final_prophet(self, brand, n_trials, multivariate):\n",
    "        \"\"\"Train Prophet with optimization\"\"\"\n",
    "        from prophet import Prophet\n",
    "        \n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_full = self.df_full[self.df_full['month'] >= start_date].copy()\n",
    "        \n",
    "        variant = \"Multi\" if multivariate else \"Uni\"\n",
    "        print(f\"\\nüìÖ Production training: {start_date} ‚Üí {len(df_brand_full)} months\")\n",
    "        \n",
    "        target_col = self._get_target_col(brand)\n",
    "        y_raw = df_brand_full[target_col].values\n",
    "        y_log = transform_target(y_raw)\n",
    "        \n",
    "        df_prophet = pd.DataFrame({'ds': df_brand_full['month'], 'y': y_log})\n",
    "        \n",
    "        regressors = []\n",
    "        if multivariate:\n",
    "            regressors = [f'launch_{brand.lower()}', 'is_holiday_season', 'is_back_to_school', 'is_black_friday', 'cpi_index']\n",
    "            for reg in regressors:\n",
    "                if reg in df_brand_full.columns:\n",
    "                    df_prophet[reg] = df_brand_full[reg].values\n",
    "            regressors = [r for r in regressors if r in df_prophet.columns]\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'changepoint_prior_scale': trial.suggest_float('changepoint_prior_scale', 0.001, 0.5, log=True),\n",
    "                'seasonality_prior_scale': trial.suggest_float('seasonality_prior_scale', 0.01, 10.0, log=True),\n",
    "                'seasonality_mode': trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative']),\n",
    "                'changepoint_range': trial.suggest_float('changepoint_range', 0.8, 0.95),\n",
    "                'yearly_seasonality': trial.suggest_categorical('yearly_seasonality', [True, False]) if multivariate else True\n",
    "            }\n",
    "            \n",
    "            splits = self._create_walk_forward_splits(len(df_prophet))\n",
    "            scores = []\n",
    "            \n",
    "            for s in splits:\n",
    "                try:\n",
    "                    model = Prophet(**params)\n",
    "                    for reg in regressors:\n",
    "                        model.add_regressor(reg)\n",
    "                    \n",
    "                    model.fit(df_prophet.iloc[s['train']])\n",
    "                    future = df_prophet.iloc[s['test']][['ds'] + regressors].copy()\n",
    "                    forecast = model.predict(future)\n",
    "                    \n",
    "                    pred_log = forecast['yhat'].values\n",
    "                    pred_real = inverse_transform_target(pred_log)\n",
    "                    \n",
    "                    scores.append(mean_absolute_percentage_error(y_raw[s['test']], pred_real) * 100)\n",
    "                except:\n",
    "                    scores.append(999)\n",
    "            \n",
    "            return np.mean(scores) if scores else 999\n",
    "\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "        \n",
    "        final_model = Prophet(**study.best_params)\n",
    "        for reg in regressors:\n",
    "            final_model.add_regressor(reg)\n",
    "        final_model.fit(df_prophet)\n",
    "        \n",
    "        self.final_models[brand] = final_model\n",
    "        self.final_params[brand] = {\n",
    "            'params': study.best_params, \n",
    "            'regressor_cols': regressors, \n",
    "            'target_col': target_col, \n",
    "            'multivariate': multivariate,\n",
    "            'start_date': start_date\n",
    "        }\n",
    "        self.cv_performance[brand] = study.best_value\n",
    "        print(f\"‚úì Prophet-{variant} trained | CV MAPE: {study.best_value:.2f}%\")\n",
    "\n",
    "    # ================================================================\n",
    "    # FIT-ONLY LOGIC (For Ensemble Base Models)\n",
    "    # ================================================================\n",
    "    \n",
    "    def _fit_model_on_full_data(self, brand, model_type, params):\n",
    "        \"\"\"\n",
    "        Fit a single model on FULL data using pre-optimized params\n",
    "        \"\"\"\n",
    "        \n",
    "        start_date = BRAND_START_DATES.get(brand, '2011-01-01')\n",
    "        df_brand_full = self.df_full[self.df_full['month'] >= start_date].copy()\n",
    "        \n",
    "        target_col = self._get_target_col(brand)\n",
    "        y_raw = df_brand_full[target_col].values\n",
    "        y_log = transform_target(y_raw)\n",
    "        \n",
    "        # Route to appropriate fitter\n",
    "        if model_type == 'SARIMAX':\n",
    "            return self._fit_sarimax(df_brand_full, y_log, params)\n",
    "        elif model_type == 'XGBoost':\n",
    "            return self._fit_xgboost(df_brand_full, y_log, params)\n",
    "        elif model_type == 'LightGBM':\n",
    "            return self._fit_lightgbm(df_brand_full, y_log, params)\n",
    "        elif model_type == 'CatBoost':\n",
    "            return self._fit_catboost(df_brand_full, y_log, params)\n",
    "        elif model_type.startswith('Prophet'):\n",
    "            return self._fit_prophet(df_brand_full, y_log, params, model_type=='Prophet-Multi')\n",
    "        elif model_type == 'GP':\n",
    "            return self._fit_gp(df_brand_full, y_log, params)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    def _fit_sarimax(self, df, y_log, params):\n",
    "        \"\"\"Fit SARIMAX on full data\"\"\"\n",
    "        from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "        \n",
    "        exog_cols = params['exog_cols']\n",
    "        X = df[exog_cols].values if exog_cols else None\n",
    "        \n",
    "        model = SARIMAX(\n",
    "            y_log, \n",
    "            exog=X, \n",
    "            order=params['order'], \n",
    "            seasonal_order=params['seasonal_order'],\n",
    "            enforce_stationarity=False, \n",
    "            enforce_invertibility=False\n",
    "        )\n",
    "        \n",
    "        return model.fit(disp=False, maxiter=200, method='lbfgs'), None\n",
    "    \n",
    "    def _fit_xgboost(self, df, y_log, params):\n",
    "        \"\"\"Fit XGBoost on full data\"\"\"\n",
    "        import xgboost as xgb\n",
    "        \n",
    "        features = params['feature_cols']\n",
    "        X_raw = df[features].values\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_raw)\n",
    "        \n",
    "        model = xgb.XGBRegressor(**params['params'], n_jobs=-1)\n",
    "        model.fit(X_scaled, y_log, verbose=False)\n",
    "        \n",
    "        return model, scaler\n",
    "    \n",
    "    def _fit_lightgbm(self, df, y_log, params):\n",
    "        \"\"\"Fit LightGBM on full data\"\"\"\n",
    "        import lightgbm as lgb\n",
    "        \n",
    "        features = params['feature_cols']\n",
    "        X_raw = df[features].values\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_raw)\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**params['params'], verbose=-1, n_jobs=-1)\n",
    "        model.fit(X_scaled, y_log)\n",
    "        \n",
    "        return model, scaler\n",
    "    \n",
    "    def _fit_catboost(self, df, y_log, params):\n",
    "        \"\"\"Fit CatBoost on full data\"\"\"\n",
    "        from catboost import CatBoostRegressor\n",
    "        \n",
    "        features = params['feature_cols']\n",
    "        cat_features = params['cat_features']\n",
    "        numeric_cols = params['numeric_cols']\n",
    "        \n",
    "        X_raw = df[features].copy()\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = X_raw.copy()\n",
    "        X_scaled[numeric_cols] = scaler.fit_transform(X_raw[numeric_cols])\n",
    "        \n",
    "        model = CatBoostRegressor(**params['params'], verbose=False, cat_features=cat_features)\n",
    "        model.fit(X_scaled, y_log)\n",
    "        \n",
    "        return model, scaler\n",
    "    \n",
    "    def _fit_prophet(self, df, y_log, params, multivariate):\n",
    "        \"\"\"\n",
    "        Fit Prophet on full data\n",
    "        \"\"\"\n",
    "        from prophet import Prophet\n",
    "        \n",
    "        df_prophet = pd.DataFrame({'ds': df['month'], 'y': y_log})\n",
    "        \n",
    "        # Check both possible key names for regressors\n",
    "        regressors = params.get('regressor_cols') or params.get('regressors', [])\n",
    "        \n",
    "        # Add regressor columns to prophet dataframe\n",
    "        for reg in regressors:\n",
    "            if reg in df.columns:\n",
    "                df_prophet[reg] = df[reg].values\n",
    "        \n",
    "        # Check both possible key names for hyperparameters\n",
    "        prophet_params = params.get('params') or params.get('hyperparams', {})\n",
    "        \n",
    "        # Build and fit model\n",
    "        model = Prophet(**prophet_params)\n",
    "        for reg in regressors:\n",
    "            if reg in df_prophet.columns:  # Extra safety check\n",
    "                model.add_regressor(reg)\n",
    "        \n",
    "        model.fit(df_prophet)\n",
    "        \n",
    "        return model, None\n",
    "    \n",
    "    def _fit_gp(self, df, y_log, params):\n",
    "        \"\"\"Fit GP on full data\"\"\"\n",
    "        from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "        from sklearn.gaussian_process.kernels import (\n",
    "            RBF, Matern, RationalQuadratic, ExpSineSquared, \n",
    "            WhiteKernel, ConstantKernel as C\n",
    "        )\n",
    "        \n",
    "        features = params['feature_cols']\n",
    "        X_raw = df[features].values\n",
    "        \n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "        \n",
    "        X_scaled = scaler_X.fit_transform(X_raw)\n",
    "        y_scaled = scaler_y.fit_transform(y_log.reshape(-1, 1)).ravel()\n",
    "        \n",
    "        # Rebuild kernel from params\n",
    "        p = params['params']\n",
    "        base = C(1.0, (1e-3, 1e3))\n",
    "        if p['kernel_type'] == 'RBF':\n",
    "            k = base * RBF(length_scale=p['length_scale'])\n",
    "        elif p['kernel_type'] == 'Matern':\n",
    "            k = base * Matern(length_scale=p['length_scale'], nu=p['nu'])\n",
    "        elif p['kernel_type'] == 'RationalQuadratic':\n",
    "            k = base * RationalQuadratic(length_scale=p['length_scale'], alpha=p['rq_alpha'])\n",
    "        else:\n",
    "            k = base * RBF(length_scale=p['length_scale']) + \\\n",
    "                base * ExpSineSquared(length_scale=1.0, periodicity=p['period'])\n",
    "        \n",
    "        kernel = k + WhiteKernel(noise_level=p['alpha'])\n",
    "        \n",
    "        model = GaussianProcessRegressor(kernel=kernel, alpha=p['alpha'], normalize_y=False, n_restarts_optimizer=5)\n",
    "        model.fit(X_scaled, y_scaled)\n",
    "        \n",
    "        return model, {'X_scaler': scaler_X, 'y_scaler': scaler_y}\n",
    "\n",
    "    # ================================================================\n",
    "    # HELPER METHODS\n",
    "    # ================================================================\n",
    "    \n",
    "    def _load_params_from_cache(self, model_type, brand):\n",
    "        \"\"\"Load pre-optimized params\"\"\"\n",
    "        \n",
    "        cache_file = MODEL_CACHE_FILES.get(model_type)\n",
    "        if not cache_file or not os.path.exists(cache_file):\n",
    "            raise FileNotFoundError(\n",
    "                f\"Cache file {cache_file} for {model_type} not found!\\n\"\n",
    "                f\"Action: Run Training Cell to generate all base model caches.\"\n",
    "            )\n",
    "        \n",
    "        with open(cache_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        return data['best_params'][brand]\n",
    "    \n",
    "    def _load_ensemble_weights(self, brand):\n",
    "        \"\"\"Load ensemble weights from the Training Cell\"\"\"\n",
    "        \n",
    "        if not os.path.exists('ensemble_results.pkl'):\n",
    "            raise FileNotFoundError(\n",
    "                \"ensemble_results.pkl not found! Run Training Cell first.\"\n",
    "            )\n",
    "        \n",
    "        with open('ensemble_results.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        return data['ensemble_weights'][brand]\n",
    "    \n",
    "    def _load_ensemble_cv_score(self, brand):\n",
    "        \"\"\"Load ensemble CV score from the Training Cell\"\"\"\n",
    "        \n",
    "        with open('ensemble_results.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        return data['cv_results'][brand]['cv_mape_mean']\n",
    "    \n",
    "    def _get_target_col(self, brand):\n",
    "        col = f'{brand}_units'\n",
    "        return col if col in self.df_full.columns else f'{brand.lower()}_units'\n",
    "    \n",
    "    def _get_ml_data(self, brand, df):\n",
    "        target_col = self._get_target_col(brand)\n",
    "        prefix = brand if f'{brand}_lag1' in df.columns else brand.lower()\n",
    "        \n",
    "        features = [\n",
    "            f'{prefix}_lag1', f'{prefix}_lag12', f'{prefix}_ma3', f'{prefix}_ma12',\n",
    "            f'launch_{brand.lower()}', 'is_holiday_season', 'is_back_to_school',\n",
    "            'is_black_friday', 'month_num', 'quarter', 'time_index', 'cpi_index'\n",
    "        ]\n",
    "        features = [c for c in features if c in df.columns]\n",
    "        \n",
    "        X = df[features].values\n",
    "        y = df[target_col].values\n",
    "        \n",
    "        return X, y, features, target_col\n",
    "    \n",
    "    def _create_walk_forward_splits(self, n_samples):\n",
    "        \"\"\"\n",
    "        Anchored walk-forward CV ending at most recent data\n",
    "        Last fold always tests the most recent 12 months\n",
    "        \"\"\"\n",
    "        test_size = 12\n",
    "        n_folds = 5\n",
    "        min_train = 60\n",
    "        \n",
    "        last_test_end = n_samples\n",
    "        last_test_start = last_test_end - test_size\n",
    "        \n",
    "        first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        if first_train_end < min_train:\n",
    "            max_possible_folds = (last_test_start - min_train) // test_size + 1\n",
    "            n_folds = max(2, int(max_possible_folds))\n",
    "            first_train_end = last_test_start - (test_size * (n_folds - 1))\n",
    "        \n",
    "        splits = []\n",
    "        for i in range(n_folds):\n",
    "            train_end = first_train_end + (i * test_size)\n",
    "            test_start = train_end\n",
    "            test_end = test_start + test_size\n",
    "            \n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "            \n",
    "            if train_end < min_train:\n",
    "                continue\n",
    "            \n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(test_start, test_end))\n",
    "            })\n",
    "        \n",
    "        if not splits:\n",
    "            train_end = max(min_train, n_samples - test_size)\n",
    "            splits.append({\n",
    "                'train': list(range(train_end)),\n",
    "                'test': list(range(train_end, n_samples))\n",
    "            })\n",
    "        \n",
    "        return splits\n",
    "    \n",
    "    def _print_summary(self, model_selection):\n",
    "        print(\"\\n\\n\" + \"=\"*70)\n",
    "        print(\"FINAL PRODUCTION MODELS SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary = []\n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            if brand in self.cv_performance:\n",
    "                start_date = self.final_params[brand].get('start_date', '2011-01-01')\n",
    "                df_brand = self.df_full[self.df_full['month'] >= start_date]\n",
    "                summary.append({\n",
    "                    'Brand': brand,\n",
    "                    'Model': model_selection[brand]['model'],\n",
    "                    'CV MAPE': f\"{self.cv_performance[brand]:.2f}%\",\n",
    "                    'Start': start_date,\n",
    "                    'Months': len(df_brand)\n",
    "                })\n",
    "        \n",
    "        print(\"\\n\" + pd.DataFrame(summary).to_string(index=False))\n",
    "        print(\"\\n‚úÖ All final production models trained\")\n",
    "        print(f\"üíæ Scalers saved for production forecasting\")\n",
    "        print(f\"üéØ Ready for 2026 forecasting\")\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTION\n",
    "# ================================================================\n",
    "\n",
    "if run_training:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STARTING FINAL PRODUCTION MODEL TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"‚è∞ Expected runtime: 10-40 minutes\")\n",
    "    print(\"  ‚Ä¢ Single models: 2-5 min each (with optimization)\")\n",
    "    print(\"  ‚Ä¢ Ensemble: 15-25 min (trains all 7 base models)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Combine train and test datasets\n",
    "    df_full_data = pd.concat([df_train, df_test], ignore_index=True)\n",
    "    df_full_data = df_full_data.sort_values('month').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\nFull dataset: {len(df_full_data)} months\")\n",
    "    print(f\"Date range: {df_full_data['month'].min().date()} to {df_full_data['month'].max().date()}\")\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = FinalModelTrainer(df_full_data, stat_validation_results)\n",
    "    \n",
    "    # Train final models (50 trials for optimization)\n",
    "    production_models, production_params, production_cv_performance = trainer.train_final_models(\n",
    "        final_model_selection,\n",
    "        n_trials=50\n",
    "    )\n",
    "    \n",
    "    # Store scalers\n",
    "    production_scalers = trainer.scalers\n",
    "    \n",
    "    # Save to cache\n",
    "    with open(FINAL_MODELS_CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'production_models': production_models,\n",
    "            'production_params': production_params,\n",
    "            'production_cv_performance': production_cv_performance,\n",
    "            'production_scalers': production_scalers\n",
    "        }, f)\n",
    "    \n",
    "    print(f\"\\nüíæ Saved final production models to {FINAL_MODELS_CACHE_FILE}\")\n",
    "    print(\"‚úÖ Training complete - variables ready:\")\n",
    "    print(\"   - production_models\")\n",
    "    print(\"   - production_params\")\n",
    "    print(\"   - production_cv_performance\")\n",
    "    print(\"   - production_scalers\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö° Skipped training (loaded from cache)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Create Future Dataframe with Regressors\n",
    "# ================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING DEPENDENCIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load df_full_data if needed\n",
    "if 'df_full_data' not in globals():\n",
    "    if os.path.exists('train_test_split.pkl'):\n",
    "        with open('train_test_split.pkl', 'rb') as f:\n",
    "            cached = pickle.load(f)\n",
    "        df_full_data = pd.concat([cached['df_train'], cached['df_test']], ignore_index=True)\n",
    "        df_full_data = df_full_data.sort_values('month').reset_index(drop=True)\n",
    "        print(f\"  ‚úì Loaded from cache ({len(df_full_data)} months)\")\n",
    "    elif 'df_features' in globals():\n",
    "        df_full_data = df_features.copy()\n",
    "        print(f\"  ‚úì Using df_features ({len(df_full_data)} months)\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Run Cell 10 or Cell 11 first!\")\n",
    "else:\n",
    "    print(f\"  ‚úì df_full_data already loaded ({len(df_full_data)} months)\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Configuration\n",
    "# ----------------------------------------------------------------\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "    'Accept': 'text/csv'\n",
    "}\n",
    "\n",
    "def find_col(df, candidates):\n",
    "    \"\"\"Find column by name (case-insensitive)\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    for col in df.columns:\n",
    "        if col.upper() in [c.upper() for c in candidates]:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Fetch Bank of Canada Actuals\n",
    "# ----------------------------------------------------------------\n",
    "def fetch_boc_actuals():\n",
    "    \"\"\"Get latest actual CPI from Bank of Canada\"\"\"\n",
    "    print(\"  üì° Fetching BoC actuals...\")\n",
    "    \n",
    "    url = \"https://www.bankofcanada.ca/valet/observations/V41690914/json\"\n",
    "    params = {\"start_date\": \"2024-01-01\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, params=params, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            cpi_data = []\n",
    "            for obs in data.get('observations', []):\n",
    "                cpi_data.append({\n",
    "                    'month': pd.to_datetime(obs['d']),\n",
    "                    'cpi_index': float(obs['V41690914']['v'])\n",
    "                })\n",
    "            df = pd.DataFrame(cpi_data).sort_values('month')\n",
    "            latest = df.iloc[-1]\n",
    "            print(f\"    ‚úì Latest: {latest['month'].date()} = {latest['cpi_index']:.2f}\")\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ö†Ô∏è Failed: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(columns=['month', 'cpi_index'])\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Fetch OECD Forecasts\n",
    "# ----------------------------------------------------------------\n",
    "def fetch_oecd_forecasts():\n",
    "    \"\"\"Get CPI forecasts from OECD\"\"\"\n",
    "    print(\"  üì° Fetching OECD forecasts...\")\n",
    "    \n",
    "    def process_csv(content, freq):\n",
    "        try:\n",
    "            df = pd.read_csv(StringIO(content))\n",
    "            \n",
    "            # Filter Canada\n",
    "            loc_col = find_col(df, ['LOCATION', 'Country', 'REF_AREA'])\n",
    "            if loc_col:\n",
    "                df = df[df[loc_col] == 'CAN']\n",
    "            \n",
    "            # Find time and value columns\n",
    "            t_col = find_col(df, ['TIME', 'Period', 'TIME_PERIOD'])\n",
    "            v_col = find_col(df, ['Value', 'ObsValue', 'OBS_VALUE'])\n",
    "            \n",
    "            if not t_col or not v_col:\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            df = df.rename(columns={t_col: 'time_raw', v_col: 'val'})\n",
    "            df = df[['time_raw', 'val']].dropna()\n",
    "            df = df.drop_duplicates(subset=['time_raw'], keep='last')\n",
    "            \n",
    "            # Parse dates\n",
    "            if freq == 'Q':\n",
    "                def parse_q(x):\n",
    "                    try:\n",
    "                        s = str(x).replace('-', '').upper().strip()\n",
    "                        y = int(s[:4])\n",
    "                        q = int(s[-1])\n",
    "                        return pd.Timestamp(year=y, month=q*3-1, day=15)\n",
    "                    except:\n",
    "                        return pd.NaT\n",
    "                df['date'] = df['time_raw'].apply(parse_q)\n",
    "            else:  # Annual\n",
    "                df['year'] = pd.to_numeric(df['time_raw'], errors='coerce')\n",
    "                df = df.dropna(subset=['year'])\n",
    "                df['date'] = df['year'].apply(lambda y: pd.Timestamp(year=int(y), month=7, day=1))\n",
    "            \n",
    "            df = df.dropna(subset=['date']).sort_values('date')\n",
    "            df = df[df['date'].dt.year >= 2025]  # Future only\n",
    "            \n",
    "            return df[['date', 'val']]\n",
    "        except:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    # Try quarterly first\n",
    "    url_q = \"https://stats.oecd.org/sdmx-json/data/EO/CAN.CPI.Q.PC/all?contentType=csv\"\n",
    "    try:\n",
    "        r = requests.get(url_q, headers=HEADERS, timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            df = process_csv(r.text, 'Q')\n",
    "            if not df.empty:\n",
    "                print(f\"    ‚úì Quarterly forecast: {len(df)} quarters\")\n",
    "                df = df.drop_duplicates(subset=['date'], keep='last')\n",
    "                df = df.set_index('date').resample('MS').interpolate(method='time').reset_index()\n",
    "                return df\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback to annual\n",
    "    print(\"    ‚ÑπÔ∏è Trying annual...\")\n",
    "    url_a = \"https://stats.oecd.org/sdmx-json/data/EO/CAN.CPI.A.PC/all?contentType=csv\"\n",
    "    try:\n",
    "        r = requests.get(url_a, headers=HEADERS, timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            df = process_csv(r.text, 'A')\n",
    "            if not df.empty:\n",
    "                print(f\"    ‚úì Annual forecast: {len(df)} years\")\n",
    "                df = df.drop_duplicates(subset=['date'], keep='last')\n",
    "                df = df.set_index('date').resample('MS').interpolate(method='time').reset_index()\n",
    "                return df\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"    ‚ö†Ô∏è OECD unavailable\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Build Future Dataframe\n",
    "# ----------------------------------------------------------------\n",
    "def build_future_dataframe(df_historical):\n",
    "    \"\"\"Build 12-month future dataframe with all regressors\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BUILDING FUTURE DATAFRAME (2026)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create future dates\n",
    "    last_date = df_historical['month'].max()\n",
    "    future_dates = pd.date_range(\n",
    "        start=last_date + pd.DateOffset(months=1),\n",
    "        periods=12,\n",
    "        freq='MS'\n",
    "    )\n",
    "    \n",
    "    df_future = pd.DataFrame({\n",
    "        'month': future_dates,\n",
    "        'month_num': future_dates.month,\n",
    "        'quarter': future_dates.quarter\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFuture period: {df_future['month'].min().date()} to {df_future['month'].max().date()}\")\n",
    "    \n",
    "    # Fetch CPI data\n",
    "    print(\"\\nStep 1: Fetching CPI data...\")\n",
    "    df_boc = fetch_boc_actuals()\n",
    "    df_oecd = fetch_oecd_forecasts()\n",
    "    \n",
    "    # Set anchor point\n",
    "    current_cpi = df_historical['cpi_index'].iloc[-1]\n",
    "    print(f\"\\n  ‚öì Starting CPI: {current_cpi:.2f}\")\n",
    "    \n",
    "    # Update anchor if BoC has newer data\n",
    "    if not df_boc.empty:\n",
    "        latest_boc = df_boc.iloc[-1]\n",
    "        if latest_boc['month'] > last_date:\n",
    "            current_cpi = latest_boc['cpi_index']\n",
    "            print(f\"  ‚öì Updated to BoC latest: {current_cpi:.2f} ({latest_boc['month'].date()})\")\n",
    "    \n",
    "    # Calculate fallback growth rate (smart fallback from historical trend)\n",
    "    last_12m_growth = df_historical['cpi_index'].pct_change(12).iloc[-1]\n",
    "    fallback_monthly_rate = (1 + last_12m_growth) ** (1/12)\n",
    "    fallback_monthly_rate = min(fallback_monthly_rate, 1.004)  # Cap at ~5% annual\n",
    "    \n",
    "    # Project CPI forward\n",
    "    print(\"\\nStep 2: Projecting CPI forward...\")\n",
    "    cpi_series = []\n",
    "    \n",
    "    for i, row in df_future.iterrows():\n",
    "        forecast_date = row['month']\n",
    "        \n",
    "        # Check if BoC has actual for this month\n",
    "        boc_match = df_boc[df_boc['month'] == forecast_date]\n",
    "        if not boc_match.empty:\n",
    "            val = boc_match.iloc[0]['cpi_index']\n",
    "            cpi_series.append(val)\n",
    "            current_cpi = val\n",
    "            continue\n",
    "        \n",
    "        # Use OECD forecast if available\n",
    "        monthly_mult = fallback_monthly_rate\n",
    "        \n",
    "        if not df_oecd.empty:\n",
    "            # Find closest forecast\n",
    "            match = df_oecd.iloc[(df_oecd['date'] - forecast_date).abs().argsort()[:1]]\n",
    "            if not match.empty:\n",
    "                raw_val = match.iloc[0]['val']\n",
    "                \n",
    "                # Check if it's a rate (not index)\n",
    "                if raw_val < 15.0:  # It's a percentage rate\n",
    "                    rate = max(-2.0, min(10.0, raw_val))  # Clamp to reasonable range\n",
    "                    monthly_mult = (1 + rate/100) ** (1/12)\n",
    "        \n",
    "        # Apply growth\n",
    "        new_val = current_cpi * monthly_mult\n",
    "        cpi_series.append(new_val)\n",
    "        current_cpi = new_val\n",
    "    \n",
    "    df_future['cpi_index'] = cpi_series\n",
    "    \n",
    "    if df_oecd.empty:\n",
    "        implied_annual = ((fallback_monthly_rate**12)-1)*100\n",
    "        print(f\"  ‚ÑπÔ∏è Used historical trend fallback ({implied_annual:.1f}% annual)\")\n",
    "    \n",
    "    print(f\"  ‚úì CPI range: {df_future['cpi_index'].min():.2f} to {df_future['cpi_index'].max():.2f}\")\n",
    "    \n",
    "    # Add launch indicators\n",
    "    print(\"\\nStep 3: Adding product launches...\")\n",
    "    launches = {\n",
    "    'apple':    [9, 3],  # Sep (Flagship), Mar (Spring Refresh) \n",
    "    'samsung':  [2, 7],  # Feb (S25/S26 Reality), Jul (Foldables) \n",
    "    'google':   [8, 2],  # Aug (Pixel Flagship), Feb (Pixel 'a' Shift) \n",
    "    'motorola': [1, 7]   # Jan (Budget Wave), Jul (Razr) \n",
    "    }\n",
    "    \n",
    "    for brand, months in launches.items():\n",
    "        col = f'launch_{brand}'\n",
    "        df_future[col] = df_future['month_num'].isin(months).astype(int)\n",
    "    \n",
    "    print(\"  ‚úì Launch indicators added\")\n",
    "    \n",
    "    # Add time features\n",
    "    print(\"\\nStep 4: Adding time features...\")\n",
    "    df_future['is_holiday_season'] = df_future['month_num'].isin([11, 12]).astype(int)\n",
    "    df_future['is_back_to_school'] = df_future['month_num'].isin([8, 9]).astype(int)\n",
    "    df_future['is_black_friday'] = (df_future['month_num'] == 11).astype(int)\n",
    "\n",
    "    # Handle time_index \n",
    "    if 'time_index' in df_historical.columns:\n",
    "        last_idx = df_historical['time_index'].max()\n",
    "        df_future['time_index'] = range(int(last_idx)+1, int(last_idx)+13)\n",
    "    else:\n",
    "        # Create based on dataset length\n",
    "        last_idx = len(df_historical) - 1\n",
    "        df_future['time_index'] = range(last_idx+1, last_idx+13)\n",
    "        print(f\"  ‚ÑπÔ∏è Created time_index (column not found in historical data)\")\n",
    "\n",
    "    print(\"  ‚úì Time features added\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FUTURE DATAFRAME COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Rows: {len(df_future)}\")\n",
    "    print(f\"Columns: {len(df_future.columns)}\")\n",
    "    print(f\"\\nPreview:\")\n",
    "    print(df_future[['month', 'cpi_index', 'launch_apple', 'is_holiday_season']].head(3))\n",
    "    \n",
    "    return df_future\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Execute\n",
    "# ----------------------------------------------------------------\n",
    "df_future_2026 = build_future_dataframe(df_full_data)\n",
    "\n",
    "print(\"\\n‚úÖ Future dataframe ready: df_future_2026\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Generate 2026 Forecasts with Production Models\n",
    "# ================================================================\n",
    "\n",
    "# Suppress library-specific warnings\n",
    "import logging\n",
    "logging.getLogger('prophet').setLevel(logging.WARNING)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING DEPENDENCIES FOR FORECASTING (LOG-SCALING AWARE)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ================================================================\n",
    "# DEPENDENCY LOADING & VALIDATION\n",
    "# ================================================================\n",
    "\n",
    "# 1. Load production models AND SCALERS\n",
    "if 'production_models' not in globals():\n",
    "    FINAL_MODELS_CACHE = 'final_production_models.pkl'\n",
    "    if os.path.exists(FINAL_MODELS_CACHE):\n",
    "        with open(FINAL_MODELS_CACHE, 'rb') as f:\n",
    "            cached = pickle.load(f)\n",
    "        production_models = cached['production_models']\n",
    "        production_params = cached['production_params']\n",
    "        production_scalers = cached.get('production_scalers', {})\n",
    "        print(\"‚úì Loaded production models & scalers from cache\")\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"Production models not found. Run training on full dataset cell first!\\n\"\n",
    "            \"Expected file: final_production_models.pkl\"\n",
    "        )\n",
    "else:\n",
    "    print(\"‚úì Production models already in memory\")\n",
    "\n",
    "# 2. Load model selection\n",
    "if 'final_model_selection' not in globals():\n",
    "    SELECTION_CACHE = 'model_selection.pkl'\n",
    "    if os.path.exists(SELECTION_CACHE):\n",
    "        with open(SELECTION_CACHE, 'rb') as f:\n",
    "            selection_data = pickle.load(f)\n",
    "            final_model_selection = selection_data.get('selected_models', selection_data)\n",
    "        print(\"‚úì Loaded model selection from cache\")\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"Model selection not found. Run Model Selection cell first!\\n\"\n",
    "            \"Expected file: model_selection.pkl\"\n",
    "        )\n",
    "else:\n",
    "    print(\"‚úì Model selection already in memory\")\n",
    "\n",
    "# 3. Load historical data\n",
    "if 'df_full_data' not in globals():\n",
    "    if os.path.exists('train_test_split.pkl'):\n",
    "        with open('train_test_split.pkl', 'rb') as f:\n",
    "            cached = pickle.load(f)\n",
    "        df_train = cached['df_train']\n",
    "        df_test = cached['df_test']\n",
    "        \n",
    "        # Combine train + test for full history\n",
    "        df_full_data = pd.concat([df_train, df_test], ignore_index=True)\n",
    "        df_full_data = df_full_data.sort_values('month').reset_index(drop=True)\n",
    "        print(f\"‚úì Loaded historical data: {len(df_full_data)} months\")\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"Historical data not found. Run Train-Test Split cell first!\\n\"\n",
    "            \"Expected file: train_test_split.pkl\"\n",
    "        )\n",
    "else:\n",
    "    print(f\"‚úì Historical data already loaded: {len(df_full_data)} months\")\n",
    "\n",
    "# 4. Load future dataframe\n",
    "if 'df_future_2026' not in globals():\n",
    "    raise RuntimeError(\n",
    "        \"Future dataframe not found. Run Build Future Dataframe cell first!\\n\"\n",
    "        \"Expected variable: df_future_2026\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"‚úì Future data loaded: {len(df_future_2026)} months\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# ================================================================\n",
    "# PRODUCTION FORECASTER CLASS\n",
    "# ================================================================\n",
    "\n",
    "class ProductionForecaster:\n",
    "    \"\"\"\n",
    "    Production forecaster with full LOG-SCALING pipeline\n",
    "    \n",
    "    ARCHITECTURE:\n",
    "    - All models trained on log-transformed targets\n",
    "    - SARIMAX: Exog variables scaled (numerical stability)\n",
    "    - Tree models: Features scaled (standard practice)\n",
    "    - GP: Double scaling (X and y)\n",
    "    - Prophet: No scaling (handles internally)\n",
    "    - All predictions inverse-transformed to original scale\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df_historical, df_future, production_models, \n",
    "                 production_params, model_selection, scalers):\n",
    "        self.df_historical = df_historical\n",
    "        self.df_future = df_future\n",
    "        self.production_models = production_models\n",
    "        self.production_params = production_params\n",
    "        self.model_selection = model_selection\n",
    "        self.scalers = scalers\n",
    "        self.forecasts = {}\n",
    "        \n",
    "        self._validate_dependencies()\n",
    "    \n",
    "    def _validate_dependencies(self):\n",
    "        \"\"\"Validate all required dependencies are present\"\"\"\n",
    "        \n",
    "        print(\"üîç Validating dependencies...\")\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            if brand not in self.model_selection:\n",
    "                raise RuntimeError(f\"Model selection missing for {brand}\")\n",
    "            \n",
    "            if brand not in self.production_models:\n",
    "                raise RuntimeError(f\"Production model missing for {brand}\")\n",
    "            \n",
    "            if brand not in self.production_params:\n",
    "                raise RuntimeError(f\"Production params missing for {brand}\")\n",
    "            \n",
    "            model_type = self.model_selection[brand]['model']\n",
    "            \n",
    "            # Validate scaler requirements\n",
    "            if model_type == 'SARIMAX':\n",
    "                # SARIMAX requires scaler for exog variables\n",
    "                if brand not in self.scalers:\n",
    "                    # Check if model has exog variables\n",
    "                    params = self.production_params[brand]\n",
    "                    if params.get('exog_cols'):\n",
    "                        raise RuntimeError(\n",
    "                            f\"SARIMAX for {brand} has exog variables but scaler missing. \"\n",
    "                            f\"Re-run Cell 14 to generate scalers.\"\n",
    "                        )\n",
    "            \n",
    "            elif model_type == 'GP':\n",
    "                # GP requires both X and y scalers\n",
    "                if brand not in self.scalers:\n",
    "                    raise RuntimeError(\n",
    "                        f\"GP model for {brand} requires scalers. \"\n",
    "                        f\"Re-run Cell 14 to generate scalers.\"\n",
    "                    )\n",
    "                if not isinstance(self.scalers[brand], dict):\n",
    "                    raise RuntimeError(\n",
    "                        f\"GP scalers for {brand} malformed (expected dict with X_scaler, y_scaler)\"\n",
    "                    )\n",
    "            \n",
    "            elif model_type in ['XGBoost', 'LightGBM', 'CatBoost']:\n",
    "                # Tree models should have scalers\n",
    "                if brand not in self.scalers:\n",
    "                    print(f\"‚ö†Ô∏è  Warning: {model_type} for {brand} missing scaler\")\n",
    "                    print(f\"    Will attempt unscaled inference (may reduce accuracy)\")\n",
    "            \n",
    "            elif model_type == 'Ensemble':\n",
    "                # Ensemble requires base model scalers\n",
    "                ensemble_data = self.production_models[brand]\n",
    "                if 'base_models' not in ensemble_data:\n",
    "                    raise RuntimeError(\n",
    "                        f\"Ensemble for {brand} missing base_models. \"\n",
    "                        f\"Re-run Cell 14 to train ensemble properly.\"\n",
    "                    )\n",
    "        \n",
    "        print(\"‚úÖ All dependencies validated\\n\")\n",
    "    \n",
    "    def generate_all_forecasts(self):\n",
    "        \"\"\"Generate 2026 forecasts for all brands (ORIGINAL SCALE output)\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"GENERATING 2026 FORECASTS\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"üìä Pipeline: LOG-SPACE prediction ‚Üí INVERSE TRANSFORM ‚Üí Real units\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        brands = ['Apple', 'Samsung', 'Google', 'Motorola']\n",
    "        \n",
    "        for brand in brands:\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "            print(f\"FORECASTING: {brand}\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "            \n",
    "            model_type = self.model_selection[brand]['model']\n",
    "            print(f\"  Selected Model: {model_type}\")\n",
    "            \n",
    "            model = self.production_models[brand]\n",
    "            params = self.production_params[brand]\n",
    "            \n",
    "            # Route to appropriate forecasting method\n",
    "            try:\n",
    "                if model_type == 'SARIMAX':\n",
    "                    forecast = self._forecast_sarimax(brand, model, params)\n",
    "                elif model_type == 'XGBoost':\n",
    "                    forecast = self._forecast_ml_recursive(brand, model, params, 'XGBoost')\n",
    "                elif model_type == 'LightGBM':\n",
    "                    forecast = self._forecast_ml_recursive(brand, model, params, 'LightGBM')\n",
    "                elif model_type == 'CatBoost':\n",
    "                    forecast = self._forecast_catboost(brand, model, params)\n",
    "                elif model_type == 'GP':\n",
    "                    forecast = self._forecast_gp(brand, model, params)\n",
    "                elif model_type in ['Prophet-Multi', 'Prophet-Uni']:\n",
    "                    forecast = self._forecast_prophet(brand, model, params)\n",
    "                elif model_type == 'Ensemble':\n",
    "                    forecast = self._forecast_ensemble(brand, model, params)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "                \n",
    "                self.forecasts[brand] = forecast\n",
    "                \n",
    "                # Summary statistics\n",
    "                total = forecast['forecast'].sum()\n",
    "                avg = forecast['forecast'].mean()\n",
    "                peak = forecast['forecast'].max()\n",
    "                peak_month = forecast['forecast'].argmax() + 1\n",
    "                \n",
    "                print(f\"  ‚úÖ Forecast complete (ORIGINAL SCALE)\")\n",
    "                print(f\"     Total 2026: {total:,.0f} units\")\n",
    "                print(f\"     Monthly Avg: {avg:,.0f} units\")\n",
    "                print(f\"     Peak: {peak:,.0f} units (Month {peak_month})\")\n",
    "                print()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå ERROR: {e}\")\n",
    "                print(f\"     Falling back to historical average\")\n",
    "                \n",
    "                # Fallback forecast\n",
    "                target_col = self._get_target_col(brand)\n",
    "                hist_avg = self.df_historical[target_col].tail(12).mean()\n",
    "                fallback = np.full(12, hist_avg)\n",
    "                \n",
    "                self.forecasts[brand] = {\n",
    "                    'forecast': fallback,\n",
    "                    'lower_bound': fallback * 0.85,\n",
    "                    'upper_bound': fallback * 1.15,\n",
    "                    'confidence_intervals': False,\n",
    "                    'error': str(e)\n",
    "                }\n",
    "                print()\n",
    "        \n",
    "        self._print_summary()\n",
    "        self._validate_forecasts()\n",
    "        \n",
    "        return self.forecasts\n",
    "    \n",
    "    # ================================================================\n",
    "    # MODEL-SPECIFIC FORECASTING METHODS\n",
    "    # ================================================================\n",
    "    \n",
    "    def _forecast_sarimax(self, brand, model, params):\n",
    "        \"\"\"\n",
    "        SARIMAX forecast with scaled exog + inverse log-transform\n",
    "        \"\"\"\n",
    "        \n",
    "        exog_cols = params['exog_cols']\n",
    "        \n",
    "        # ================================================================\n",
    "        # Scale exog variables (same as training)\n",
    "        # ================================================================\n",
    "        if exog_cols:\n",
    "            if brand in self.scalers and self.scalers[brand] is not None:\n",
    "                X_future_raw = self.df_future[exog_cols].values\n",
    "                X_future = self.scalers[brand].transform(X_future_raw)\n",
    "            else:\n",
    "                # Fallback: unscaled (may reduce accuracy)\n",
    "                X_future = self.df_future[exog_cols].values\n",
    "                print(f\"  ‚ö†Ô∏è  Warning: Using unscaled exog (scaler missing)\")\n",
    "        else:\n",
    "            X_future = None\n",
    "        \n",
    "        # ================================================================\n",
    "        # Forecast in LOG-SPACE\n",
    "        # ================================================================\n",
    "        pred_log = model.forecast(steps=12, exog=X_future)\n",
    "        \n",
    "        # Handle pandas Series vs numpy array\n",
    "        if hasattr(pred_log, 'values'):\n",
    "            pred_log_arr = pred_log.values\n",
    "        else:\n",
    "            pred_log_arr = np.array(pred_log)\n",
    "        \n",
    "        # ================================================================\n",
    "        # INVERSE TRANSFORM to original scale\n",
    "        # ================================================================\n",
    "        pred_real = inverse_transform_target(pred_log_arr)\n",
    "        \n",
    "        # ================================================================\n",
    "        # Get confidence intervals (in log-space)\n",
    "        # ================================================================\n",
    "        try:\n",
    "            forecast_obj = model.get_forecast(steps=12, exog=X_future)\n",
    "            ci = forecast_obj.conf_int(alpha=0.2)  # 80% CI\n",
    "            \n",
    "            # Handle DataFrame vs array\n",
    "            if hasattr(ci, 'iloc'):\n",
    "                lower_log = ci.iloc[:, 0].values\n",
    "                upper_log = ci.iloc[:, 1].values\n",
    "            else:\n",
    "                lower_log = ci[:, 0]\n",
    "                upper_log = ci[:, 1]\n",
    "            \n",
    "            # Inverse transform CI bounds\n",
    "            lower_real = inverse_transform_target(lower_log)\n",
    "            upper_real = inverse_transform_target(upper_log)\n",
    "            \n",
    "            has_ci = True\n",
    "        except:\n",
    "            # Fallback: approximate CI\n",
    "            lower_real = pred_real * 0.85\n",
    "            upper_real = pred_real * 1.15\n",
    "            has_ci = False\n",
    "        \n",
    "        return {\n",
    "            'forecast': pred_real,\n",
    "            'lower_bound': lower_real,\n",
    "            'upper_bound': upper_real,\n",
    "            'confidence_intervals': has_ci\n",
    "        }\n",
    "    \n",
    "    def _forecast_ml_recursive(self, brand, model, params, model_name):\n",
    "        \"\"\"\n",
    "        Recursive ML forecasting (XGBoost/LightGBM)\n",
    "        \"\"\"\n",
    "        \n",
    "        feature_cols = params['feature_cols']\n",
    "        forecast_values = []  # Store REAL values for feature building\n",
    "        \n",
    "        for i in range(12):\n",
    "            # ================================================================\n",
    "            # Build features using history + previous forecasts\n",
    "            # ================================================================\n",
    "            feats = self._build_ml_features(brand, i, forecast_values, feature_cols)\n",
    "            X_row = np.array([[feats[col] for col in feature_cols]])\n",
    "            \n",
    "            # ================================================================\n",
    "            # Scale input features\n",
    "            # ================================================================\n",
    "            if brand in self.scalers:\n",
    "                X_row_scaled = self.scalers[brand].transform(X_row)\n",
    "            else:\n",
    "                X_row_scaled = X_row\n",
    "                if i == 0:  # Only warn once\n",
    "                    print(f\"  ‚ö†Ô∏è  {model_name}: Using unscaled features (scaler missing)\")\n",
    "            \n",
    "            # ================================================================\n",
    "            # Predict in LOG-SPACE\n",
    "            # ================================================================\n",
    "            pred_log = model.predict(X_row_scaled)[0]\n",
    "            \n",
    "            # ================================================================\n",
    "            # INVERSE TRANSFORM to original scale\n",
    "            # ================================================================\n",
    "            pred_real = inverse_transform_target(np.array([pred_log]))[0]\n",
    "            \n",
    "            # Ensure non-negative\n",
    "            forecast_values.append(max(0, pred_real))\n",
    "        \n",
    "        forecast_arr = np.array(forecast_values)\n",
    "        \n",
    "        # Approximate confidence intervals (¬±15%)\n",
    "        return {\n",
    "            'forecast': forecast_arr,\n",
    "            'lower_bound': forecast_arr * 0.85,\n",
    "            'upper_bound': forecast_arr * 1.15,\n",
    "            'confidence_intervals': False\n",
    "        }\n",
    "    \n",
    "    def _forecast_catboost(self, brand, model, params):\n",
    "        \"\"\"\n",
    "        CatBoost recursive forecasting\n",
    "        \"\"\"\n",
    "        \n",
    "        feature_cols = params['feature_cols']\n",
    "        cat_features = params.get('cat_features', [])\n",
    "        numeric_cols = params.get('numeric_cols', [c for c in feature_cols if c not in cat_features])\n",
    "        \n",
    "        forecast_values = []  # REAL values\n",
    "        \n",
    "        for i in range(12):\n",
    "            # Build features\n",
    "            feats = self._build_ml_features(brand, i, forecast_values, feature_cols)\n",
    "            \n",
    "            # Create DataFrame for CatBoost (preserves categorical types)\n",
    "            X_row = pd.DataFrame([feats])[feature_cols]\n",
    "            \n",
    "            # ================================================================\n",
    "            # Scale ONLY numeric columns\n",
    "            # ================================================================\n",
    "            if brand in self.scalers and numeric_cols:\n",
    "                scaler = self.scalers[brand]\n",
    "                X_row[numeric_cols] = scaler.transform(X_row[numeric_cols])\n",
    "            elif i == 0 and numeric_cols:\n",
    "                print(f\"  ‚ö†Ô∏è  CatBoost: Using unscaled features (scaler missing)\")\n",
    "            \n",
    "            # Ensure categorical columns are properly typed\n",
    "            for cat_col in cat_features:\n",
    "                if cat_col in X_row.columns:\n",
    "                    X_row[cat_col] = X_row[cat_col].astype(int)\n",
    "            \n",
    "            # ================================================================\n",
    "            # Predict in LOG-SPACE\n",
    "            # ================================================================\n",
    "            pred_log = model.predict(X_row)[0]\n",
    "            \n",
    "            # ================================================================\n",
    "            # INVERSE TRANSFORM to original scale\n",
    "            # ================================================================\n",
    "            pred_real = inverse_transform_target(np.array([pred_log]))[0]\n",
    "            \n",
    "            forecast_values.append(max(0, pred_real))\n",
    "        \n",
    "        forecast_arr = np.array(forecast_values)\n",
    "        \n",
    "        return {\n",
    "            'forecast': forecast_arr,\n",
    "            'lower_bound': forecast_arr * 0.85,\n",
    "            'upper_bound': forecast_arr * 1.15,\n",
    "            'confidence_intervals': False\n",
    "        }\n",
    "    \n",
    "    def _forecast_gp(self, brand, model, params):\n",
    "        \"\"\"\n",
    "        Gaussian Process forecasting with TWO-STEP inverse transform\n",
    "        \"\"\"\n",
    "        \n",
    "        feature_cols = params['feature_cols']\n",
    "        \n",
    "        if brand not in self.scalers:\n",
    "            raise RuntimeError(f\"GP requires scalers for {brand}\")\n",
    "        \n",
    "        scaler_X = self.scalers[brand]['X_scaler']\n",
    "        scaler_y = self.scalers[brand]['y_scaler']\n",
    "        \n",
    "        forecast_values = []  # REAL values\n",
    "        stds_real = []\n",
    "        \n",
    "        for i in range(12):\n",
    "            # Build features\n",
    "            feats = self._build_ml_features(brand, i, forecast_values, feature_cols)\n",
    "            X_raw = np.array([[feats[col] for col in feature_cols]])\n",
    "            \n",
    "            # ================================================================\n",
    "            # STEP 1: Scale X\n",
    "            # ================================================================\n",
    "            X_scaled = scaler_X.transform(X_raw)\n",
    "            \n",
    "            # ================================================================\n",
    "            # STEP 2: Predict (returns SCALED log-space value + std)\n",
    "            # ================================================================\n",
    "            pred_scaled, std_scaled = model.predict(X_scaled, return_std=True)\n",
    "            \n",
    "            # ================================================================\n",
    "            # STEP 3: Inverse scale (scaled log ‚Üí log)\n",
    "            # ================================================================\n",
    "            pred_log = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1)).ravel()[0]\n",
    "            \n",
    "            # ================================================================\n",
    "            # STEP 4: Inverse log-transform (log ‚Üí real)\n",
    "            # ================================================================\n",
    "            pred_real = inverse_transform_target(np.array([pred_log]))[0]\n",
    "            \n",
    "            # ================================================================\n",
    "            # Transform uncertainty to real-space\n",
    "            # ================================================================\n",
    "            std_log = std_scaled[0] * scaler_y.scale_[0]\n",
    "            \n",
    "            # std in log ‚Üí std in real \n",
    "            std_real = std_log * np.exp(pred_log)\n",
    "            \n",
    "            forecast_values.append(max(0, pred_real))\n",
    "            stds_real.append(std_real)\n",
    "        \n",
    "        forecast_arr = np.array(forecast_values)\n",
    "        stds_arr = np.array(stds_real)\n",
    "        \n",
    "        # 80% CI (1.28œÉ for normal distribution)\n",
    "        return {\n",
    "            'forecast': forecast_arr,\n",
    "            'lower_bound': np.maximum(0, forecast_arr - (1.28 * stds_arr)),\n",
    "            'upper_bound': forecast_arr + (1.28 * stds_arr),\n",
    "            'confidence_intervals': True\n",
    "        }\n",
    "    \n",
    "    def _forecast_prophet(self, brand, model, params):\n",
    "        \"\"\"\n",
    "        Prophet forecast with inverse log-transform\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare future dataframe\n",
    "        future = self.df_future[['month']].copy()\n",
    "        future.columns = ['ds']\n",
    "        \n",
    "        # Add regressors\n",
    "        regressor_cols = params.get('regressor_cols', [])\n",
    "        for reg in regressor_cols:\n",
    "            if reg in self.df_future.columns:\n",
    "                future[reg] = self.df_future[reg].values\n",
    "        \n",
    "        # ================================================================\n",
    "        # Predict (returns LOG-SPACE values)\n",
    "        # ================================================================\n",
    "        fcst = model.predict(future)\n",
    "        \n",
    "        pred_log = fcst['yhat'].values\n",
    "        lower_log = fcst['yhat_lower'].values\n",
    "        upper_log = fcst['yhat_upper'].values\n",
    "        \n",
    "        # ================================================================\n",
    "        # INVERSE TRANSFORM to original scale\n",
    "        # ================================================================\n",
    "        pred_real = inverse_transform_target(pred_log)\n",
    "        lower_real = inverse_transform_target(lower_log)\n",
    "        upper_real = inverse_transform_target(upper_log)\n",
    "        \n",
    "        return {\n",
    "            'forecast': pred_real,\n",
    "            'lower_bound': lower_real,\n",
    "            'upper_bound': upper_real,\n",
    "            'confidence_intervals': True\n",
    "        }\n",
    "    \n",
    "    def _forecast_ensemble(self, brand, model_bundle, params):\n",
    "        \"\"\"\n",
    "        Ensemble forecasting - generates predictions from all base models\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"  Ensemble composition:\")\n",
    "        \n",
    "        weights = model_bundle.get('weights', {})\n",
    "        base_models = model_bundle.get('base_models', {})\n",
    "        \n",
    "        if not base_models:\n",
    "            raise RuntimeError(\n",
    "                f\"Ensemble for {brand} has no base_models. \"\n",
    "                f\"Re-run Cell 14 to train ensemble properly.\"\n",
    "            )\n",
    "        \n",
    "        # Display weights\n",
    "        for model_name, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):\n",
    "            if weight > 0:\n",
    "                print(f\"    {model_name}: {weight:.3f}\")\n",
    "        \n",
    "        # ================================================================\n",
    "        # Generate predictions from each base model\n",
    "        # ================================================================\n",
    "        base_forecasts_log = {}\n",
    "        \n",
    "        for model_name, weight in weights.items():\n",
    "            if weight <= 0:\n",
    "                continue\n",
    "            \n",
    "            if model_name not in base_models:\n",
    "                print(f\"  ‚ö†Ô∏è  Warning: {model_name} not in base_models, skipping\")\n",
    "                continue\n",
    "            \n",
    "            base_model = base_models[model_name]\n",
    "            \n",
    "            try:\n",
    "                # Get base model params from cached results\n",
    "                base_params = self._get_base_model_params(brand, model_name)\n",
    "                \n",
    "                # Generate forecast based on model type\n",
    "                if model_name == 'SARIMAX':\n",
    "                    forecast = self._forecast_sarimax(brand, base_model, base_params)\n",
    "                elif model_name == 'XGBoost':\n",
    "                    forecast = self._forecast_ml_recursive(brand, base_model, base_params, 'XGBoost')\n",
    "                elif model_name == 'LightGBM':\n",
    "                    forecast = self._forecast_ml_recursive(brand, base_model, base_params, 'LightGBM')\n",
    "                elif model_name == 'CatBoost':\n",
    "                    forecast = self._forecast_catboost(brand, base_model, base_params)\n",
    "                elif model_name == 'GP':\n",
    "                    forecast = self._forecast_gp(brand, base_model, base_params)\n",
    "                elif model_name.startswith('Prophet'):\n",
    "                    forecast = self._forecast_prophet(brand, base_model, base_params)\n",
    "                else:\n",
    "                    print(f\"  ‚ö†Ô∏è  Unknown base model type: {model_name}, skipping\")\n",
    "                    continue\n",
    "                \n",
    "                # Convert back to log-space for averaging\n",
    "                pred_real = forecast['forecast']\n",
    "                pred_log = transform_target(pred_real)\n",
    "                base_forecasts_log[model_name] = pred_log\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è  {model_name} failed: {e}, skipping\")\n",
    "                continue\n",
    "        \n",
    "        if not base_forecasts_log:\n",
    "            raise RuntimeError(f\"Ensemble for {brand} - all base models failed\")\n",
    "        \n",
    "        # ================================================================\n",
    "        # Average predictions in LOG-SPACE (weighted)\n",
    "        # ================================================================\n",
    "        ensemble_pred_log = np.zeros(12)\n",
    "        total_weight = sum(weights[m] for m in base_forecasts_log.keys())\n",
    "        \n",
    "        for model_name, pred_log in base_forecasts_log.items():\n",
    "            weight = weights[model_name] / total_weight  # Normalize\n",
    "            ensemble_pred_log += weight * pred_log\n",
    "        \n",
    "        # ================================================================\n",
    "        # INVERSE TRANSFORM to original scale\n",
    "        # ================================================================\n",
    "        ensemble_pred_real = inverse_transform_target(ensemble_pred_log)\n",
    "        \n",
    "        # Approximate CI from base model variance\n",
    "        base_reals = np.array([inverse_transform_target(p) for p in base_forecasts_log.values()])\n",
    "        ensemble_std = np.std(base_reals, axis=0)\n",
    "        \n",
    "        return {\n",
    "            'forecast': ensemble_pred_real,\n",
    "            'lower_bound': np.maximum(0, ensemble_pred_real - (1.28 * ensemble_std)),\n",
    "            'upper_bound': ensemble_pred_real + (1.28 * ensemble_std),\n",
    "            'confidence_intervals': True,\n",
    "            'base_models_used': list(base_forecasts_log.keys())\n",
    "        }\n",
    "    \n",
    "    # ================================================================\n",
    "    # HELPER METHODS\n",
    "    # ================================================================\n",
    "    \n",
    "    def _get_base_model_params(self, brand, model_name):\n",
    "        \"\"\"Load base model params from cached results\"\"\"\n",
    "        \n",
    "        cache_files = {\n",
    "            'SARIMAX': 'sarimax_results.pkl',\n",
    "            'XGBoost': 'xgboost_results.pkl',\n",
    "            'LightGBM': 'lightgbm_results.pkl',\n",
    "            'CatBoost': 'catboost_results.pkl',\n",
    "            'GP': 'gp_results.pkl',\n",
    "            'Prophet-Multi': 'prophet_results.pkl',\n",
    "            'Prophet-Uni': 'prophet_uni_results.pkl'\n",
    "        }\n",
    "        \n",
    "        cache_file = cache_files.get(model_name)\n",
    "        if not cache_file or not os.path.exists(cache_file):\n",
    "            raise RuntimeError(f\"Cache file {cache_file} not found for {model_name}\")\n",
    "        \n",
    "        with open(cache_file, 'rb') as f:\n",
    "            cached = pickle.load(f)\n",
    "        \n",
    "        return cached['best_params'][brand]\n",
    "    \n",
    "    def _build_ml_features(self, brand, month_idx, forecast_values, feature_cols):\n",
    "        \"\"\"\n",
    "        Build features for recursive ML forecasting\n",
    "        Forecast_values are in ORIGINAL SCALE (not log)\n",
    "        \"\"\"\n",
    "        \n",
    "        future_row = self.df_future.iloc[month_idx]\n",
    "        \n",
    "        # Get historical data (ORIGINAL SCALE)\n",
    "        target_col = self._get_target_col(brand)\n",
    "        history = self.df_historical[target_col].tolist()\n",
    "        \n",
    "        # Combine history + forecasts (all in ORIGINAL SCALE)\n",
    "        current_series = history + forecast_values\n",
    "        \n",
    "        # Calculate lags and moving averages (on ORIGINAL SCALE)\n",
    "        lag1 = current_series[-1]\n",
    "        lag12 = current_series[-12] if len(current_series) >= 12 else np.mean(current_series)\n",
    "        ma3 = np.mean(current_series[-3:])\n",
    "        ma12 = np.mean(current_series[-12:]) if len(current_series) >= 12 else np.mean(current_series)\n",
    "        \n",
    "        # Build feature dictionary \n",
    "        features = {\n",
    "            f'{brand}_lag1': lag1,\n",
    "            f'{brand}_lag12': lag12,\n",
    "            f'{brand}_ma3': ma3,\n",
    "            f'{brand}_ma12': ma12,\n",
    "            f'{brand.lower()}_lag1': lag1,\n",
    "            f'{brand.lower()}_lag12': lag12,\n",
    "            f'{brand.lower()}_ma3': ma3,\n",
    "            f'{brand.lower()}_ma12': ma12,\n",
    "            f'launch_{brand.lower()}': future_row.get(f'launch_{brand.lower()}', 0),\n",
    "            'is_holiday_season': future_row.get('is_holiday_season', 0),\n",
    "            'is_back_to_school': future_row.get('is_back_to_school', 0),\n",
    "            'is_black_friday': future_row.get('is_black_friday', 0),\n",
    "            'month_num': future_row['month_num'],\n",
    "            'quarter': future_row['quarter'],\n",
    "            'time_index': future_row['time_index'],\n",
    "            'cpi_index': future_row['cpi_index']\n",
    "        }\n",
    "        \n",
    "        # Return only requested features\n",
    "        return {k: v for k, v in features.items() if k in feature_cols}\n",
    "    \n",
    "    def _get_target_col(self, brand):\n",
    "        \"\"\"Auto-detect target column name\"\"\"\n",
    "        col = f'{brand}_units'\n",
    "        return col if col in self.df_historical.columns else f'{brand.lower()}_units'\n",
    "    \n",
    "    # ================================================================\n",
    "    # OUTPUT & VALIDATION\n",
    "    # ================================================================\n",
    "    \n",
    "    def _print_summary(self):\n",
    "        \"\"\"Print comprehensive forecast summary\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"2026 FORECAST SUMMARY (ORIGINAL SCALE)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        summary = []\n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            f = self.forecasts[brand]\n",
    "            \n",
    "            # Check for errors\n",
    "            if 'error' in f:\n",
    "                summary.append({\n",
    "                    'Brand': brand,\n",
    "                    'Model': self.model_selection[brand]['model'],\n",
    "                    'Status': '‚ö†Ô∏è  FALLBACK',\n",
    "                    'Total 2026': f\"{f['forecast'].sum():,.0f}\",\n",
    "                    'Avg Monthly': f\"{f['forecast'].mean():,.0f}\",\n",
    "                    'CI': '~'\n",
    "                })\n",
    "            else:\n",
    "                ci_symbol = '‚úì' if f['confidence_intervals'] else '~'\n",
    "                \n",
    "                summary.append({\n",
    "                    'Brand': brand,\n",
    "                    'Model': self.model_selection[brand]['model'],\n",
    "                    'Status': '‚úÖ OK',\n",
    "                    'Total 2026': f\"{f['forecast'].sum():,.0f}\",\n",
    "                    'Avg Monthly': f\"{f['forecast'].mean():,.0f}\",\n",
    "                    'Peak Month': f\"{f['forecast'].max():,.0f}\",\n",
    "                    'CI': ci_symbol\n",
    "                })\n",
    "        \n",
    "        df_summary = pd.DataFrame(summary)\n",
    "        print(\"\\n\" + df_summary.to_string(index=False))\n",
    "        \n",
    "        # Market totals\n",
    "        total_market = sum(f['forecast'].sum() for f in self.forecasts.values())\n",
    "        print(f\"\\nüìä Total Canadian Market 2026: {total_market:,.0f} units\")\n",
    "        \n",
    "        # Brand market share\n",
    "        print(f\"\\nüìà Market Share (2026):\")\n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            brand_total = self.forecasts[brand]['forecast'].sum()\n",
    "            share = (brand_total / total_market) * 100\n",
    "            print(f\"   {brand}: {share:.1f}% ({brand_total:,.0f} units)\")\n",
    "        \n",
    "        print(\"\\n‚úÖ All forecasts in ORIGINAL SCALE (real units, not log)\")\n",
    "    \n",
    "    def _validate_forecasts(self):\n",
    "        \"\"\"Validate forecast sanity\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(\"VALIDATION CHECKS\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        issues = []\n",
    "        \n",
    "        for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "            forecast = self.forecasts[brand]['forecast']\n",
    "            \n",
    "            # Check 1: Non-negative\n",
    "            if forecast.min() < 0:\n",
    "                issues.append(f\"‚ùå {brand}: Negative forecasts detected (check inverse transform)\")\n",
    "            \n",
    "            # Check 2: Reasonable magnitude\n",
    "            if forecast.max() > 500000:\n",
    "                issues.append(f\"‚ö†Ô∏è  {brand}: Very high forecasts (check log-scaling)\")\n",
    "            \n",
    "            if forecast.max() < 100:\n",
    "                issues.append(f\"‚ö†Ô∏è  {brand}: Very low forecasts (check inverse transform)\")\n",
    "            \n",
    "            # Check 3: Variance\n",
    "            cv = np.std(forecast) / np.mean(forecast)\n",
    "            if cv > 0.5:\n",
    "                issues.append(f\"‚ö†Ô∏è  {brand}: High variance (CV={cv:.2f}, check model stability)\")\n",
    "            \n",
    "            # Check 4: Historical comparison\n",
    "            target_col = self._get_target_col(brand)\n",
    "            hist_avg = self.df_historical[target_col].tail(12).mean()\n",
    "            forecast_avg = forecast.mean()\n",
    "            change_pct = ((forecast_avg - hist_avg) / hist_avg) * 100\n",
    "            \n",
    "            if abs(change_pct) > 50:\n",
    "                issues.append(\n",
    "                    f\"‚ö†Ô∏è  {brand}: Large change from historical \"\n",
    "                    f\"({change_pct:+.1f}%, review if expected)\"\n",
    "                )\n",
    "        \n",
    "        if not issues:\n",
    "            print(\"‚úÖ All validation checks passed\")\n",
    "        else:\n",
    "            print(\"Issues detected:\")\n",
    "            for issue in issues:\n",
    "                print(f\"  {issue}\")\n",
    "        \n",
    "        print(f\"{'‚îÄ'*70}\\n\")\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE FORECASTING\n",
    "# ================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING FORECAST GENERATION\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Initialize forecaster\n",
    "forecaster = ProductionForecaster(\n",
    "    df_full_data,\n",
    "    df_future_2026,\n",
    "    production_models,\n",
    "    production_params,\n",
    "    final_model_selection,\n",
    "    production_scalers\n",
    ")\n",
    "\n",
    "# Generate forecasts (output in ORIGINAL SCALE)\n",
    "forecasts_2026 = forecaster.generate_all_forecasts()\n",
    "\n",
    "print(\"\\n‚úÖ Forecasts complete - stored in: forecasts_2026\")\n",
    "\n",
    "# ================================================================\n",
    "# EXPORT RESULTS\n",
    "# ================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EXPORTING RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Create output dataframe\n",
    "df_forecast_output = df_future_2026[['month']].copy()\n",
    "\n",
    "for brand in ['Apple', 'Samsung', 'Google', 'Motorola']:\n",
    "    df_forecast_output[f'{brand}_forecast'] = forecasts_2026[brand]['forecast']\n",
    "    df_forecast_output[f'{brand}_lower'] = forecasts_2026[brand]['lower_bound']\n",
    "    df_forecast_output[f'{brand}_upper'] = forecasts_2026[brand]['upper_bound']\n",
    "\n",
    "print(\"\\nüìä Forecast dataframe created: df_forecast_output\")\n",
    "print(\"   Shape:\", df_forecast_output.shape)\n",
    "print(\"   Columns:\", list(df_forecast_output.columns))\n",
    "print(\"\\nFirst 3 months:\")\n",
    "print(df_forecast_output.head(3).to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'forecast_2026_final.csv'\n",
    "df_forecast_output.to_csv(output_file, index=False)\n",
    "print(f\"\\nüíæ Saved to: {output_file}\")\n",
    "\n",
    "# Save forecasts object (for advanced analysis)\n",
    "forecasts_file = 'forecasts_2026_detailed.pkl'\n",
    "with open(forecasts_file, 'wb') as f:\n",
    "    pickle.dump(forecasts_2026, f)\n",
    "print(f\"üíæ Saved detailed forecasts to: {forecasts_file}\")\n",
    "\n",
    "# Final summary\n",
    "total_2026 = df_forecast_output[[f'{b}_forecast' for b in ['Apple', 'Samsung', 'Google', 'Motorola']]].sum().sum()\n",
    "print(f\"\\n‚úÖ Total 2026 forecast: {total_2026:,.0f} units (ORIGINAL SCALE)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FORECAST GENERATION COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd892014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Business Impact Analysis\n",
    "# ================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Translating forecasts into operational guidance\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ================================================================\n",
    "# VALIDATION: Ensure prerequisites exist\n",
    "# ================================================================\n",
    "\n",
    "if 'forecasts_2026' not in globals():\n",
    "    raise RuntimeError(\n",
    "        \"‚ùå ERROR: forecasts_2026 not found.\\n\"\n",
    "        \"   Action: Run Cell 16 (Forecast Generation) first!\"\n",
    "    )\n",
    "\n",
    "if 'final_model_selection' not in globals():\n",
    "    raise RuntimeError(\n",
    "        \"‚ùå ERROR: final_model_selection not found.\\n\"\n",
    "        \"   Action: Run Cell 13 (Model Selection) first!\"\n",
    "    )\n",
    "\n",
    "# ================================================================\n",
    "# CONFIGURATION\n",
    "# ================================================================\n",
    "\n",
    "BRANDS = CONF.get('TARGET_BRANDS', ['Apple', 'Samsung', 'Google', 'Motorola'])\n",
    "\n",
    "# ================================================================\n",
    "# BUSINESS IMPACT CALCULATOR\n",
    "# ================================================================\n",
    "\n",
    "class BusinessImpactAnalyzer:\n",
    "    \"\"\"\n",
    "    Calculate operational impact of forecast uncertainty\n",
    "    \n",
    "    Metrics:\n",
    "    - Overstock risk (units that might not sell)\n",
    "    - Stockout risk (units we might need but didn't order)\n",
    "    - Safety stock recommendation\n",
    "    - Forecast accuracy implications\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, forecasts_dict, model_selection):\n",
    "        self.forecasts = forecasts_dict\n",
    "        self.model_selection = model_selection\n",
    "        self.impact_analysis = {}\n",
    "        self.monthly_breakdown = {}\n",
    "        self.recommendations = {}\n",
    "    \n",
    "    def analyze_all_brands(self):\n",
    "        \"\"\"\n",
    "        Run complete business impact analysis for all brands\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"BRAND-LEVEL IMPACT ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for brand in BRANDS:\n",
    "            if brand not in self.forecasts:\n",
    "                print(f\"\\n‚ö†Ô∏è  {brand}: No forecast data available\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n{'‚îÄ'*70}\")\n",
    "            print(f\"{brand}\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "            \n",
    "            # Calculate impact metrics\n",
    "            impact = self._calculate_brand_impact(brand)\n",
    "            \n",
    "            # Store results\n",
    "            self.impact_analysis[brand] = impact\n",
    "            \n",
    "            # Generate monthly breakdown\n",
    "            monthly = self._create_monthly_breakdown(brand)\n",
    "            self.monthly_breakdown[brand] = monthly\n",
    "            \n",
    "            # Generate recommendations\n",
    "            rec = self._generate_recommendations(brand, impact)\n",
    "            self.recommendations[brand] = rec\n",
    "            \n",
    "            # Display summary\n",
    "            self._print_brand_summary(brand, impact, rec)\n",
    "        \n",
    "        # Portfolio-level analysis\n",
    "        self._analyze_portfolio()\n",
    "        \n",
    "        return self.impact_analysis\n",
    "    \n",
    "    def _calculate_brand_impact(self, brand):\n",
    "        \"\"\"\n",
    "        Calculate impact metrics for a single brand\n",
    "        \"\"\"\n",
    "        \n",
    "        forecast_data = self.forecasts[brand]\n",
    "        \n",
    "        # Extract forecast components\n",
    "        forecast = forecast_data['forecast']\n",
    "        lower_bound = forecast_data['lower_bound']\n",
    "        upper_bound = forecast_data['upper_bound']\n",
    "        \n",
    "        # Annual totals\n",
    "        annual_forecast = forecast.sum()\n",
    "        annual_lower = lower_bound.sum()\n",
    "        annual_upper = upper_bound.sum()\n",
    "        \n",
    "        # Risk calculations\n",
    "        overstock_risk = annual_forecast - annual_lower\n",
    "        stockout_risk = annual_upper - annual_forecast\n",
    "        \n",
    "        # Uncertainty metrics\n",
    "        total_uncertainty = annual_upper - annual_lower\n",
    "        uncertainty_pct = (total_uncertainty / annual_forecast) * 100\n",
    "        \n",
    "        # Monthly volatility\n",
    "        monthly_uncertainty = upper_bound - lower_bound\n",
    "        max_monthly_uncertainty = monthly_uncertainty.max()\n",
    "        avg_monthly_uncertainty = monthly_uncertainty.mean()\n",
    "        \n",
    "        # Asymmetry (is risk skewed toward overstock or stockout?)\n",
    "        risk_asymmetry = (stockout_risk - overstock_risk) / total_uncertainty\n",
    "        \n",
    "        # Safety stock calculation (covers both directions)\n",
    "        safety_stock_units = total_uncertainty / 4  \n",
    "        \n",
    "        # Model confidence\n",
    "        selected_model = self.model_selection[brand]['model']\n",
    "        holdout_mape = self.model_selection[brand]['holdout_mape']\n",
    "        \n",
    "        return {\n",
    "            # Core forecast\n",
    "            'annual_forecast': annual_forecast,\n",
    "            'annual_lower': annual_lower,\n",
    "            'annual_upper': annual_upper,\n",
    "            \n",
    "            # Risk metrics\n",
    "            'overstock_risk': overstock_risk,\n",
    "            'stockout_risk': stockout_risk,\n",
    "            'total_uncertainty': total_uncertainty,\n",
    "            'uncertainty_pct': uncertainty_pct,\n",
    "            \n",
    "            # Volatility\n",
    "            'max_monthly_uncertainty': max_monthly_uncertainty,\n",
    "            'avg_monthly_uncertainty': avg_monthly_uncertainty,\n",
    "            \n",
    "            # Asymmetry\n",
    "            'risk_asymmetry': risk_asymmetry,\n",
    "            \n",
    "            # Recommendations\n",
    "            'safety_stock': safety_stock_units,\n",
    "            \n",
    "            # Model info\n",
    "            'model': selected_model,\n",
    "            'mape': holdout_mape\n",
    "        }\n",
    "    \n",
    "    def _create_monthly_breakdown(self, brand):\n",
    "        \"\"\"\n",
    "        Create month-by-month breakdown of risks\n",
    "        \"\"\"\n",
    "        \n",
    "        forecast_data = self.forecasts[brand]\n",
    "        \n",
    "        forecast = forecast_data['forecast']\n",
    "        lower = forecast_data['lower_bound']\n",
    "        upper = forecast_data['upper_bound']\n",
    "        if 'months' in forecast_data:\n",
    "            months = forecast_data['months']\n",
    "        else:\n",
    "            # Fallback to the global dataframe from Cell 15\n",
    "            months = df_future_2026['month']\n",
    "        \n",
    "        # Calculate monthly risks\n",
    "        monthly_data = []\n",
    "        \n",
    "        for i, month in enumerate(months):\n",
    "            monthly_data.append({\n",
    "                'month': month,\n",
    "                'forecast': forecast[i],\n",
    "                'lower_bound': lower[i],\n",
    "                'upper_bound': upper[i],\n",
    "                'overstock_risk': forecast[i] - lower[i],\n",
    "                'stockout_risk': upper[i] - forecast[i],\n",
    "                'total_uncertainty': upper[i] - lower[i],\n",
    "                'uncertainty_pct': ((upper[i] - lower[i]) / forecast[i]) * 100 if forecast[i] > 0 else 0\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(monthly_data)\n",
    "    \n",
    "    def _generate_recommendations(self, brand, impact):\n",
    "        \"\"\"\n",
    "        Generate actionable operational recommendations\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # 1. Overall strategy\n",
    "        if impact['uncertainty_pct'] < 20:\n",
    "            strategy = \"LOW UNCERTAINTY: Order close to forecast with minimal buffer\"\n",
    "            risk_level = \"Low\"\n",
    "        elif impact['uncertainty_pct'] < 35:\n",
    "            strategy = \"MODERATE UNCERTAINTY: Standard safety stock approach\"\n",
    "            risk_level = \"Moderate\"\n",
    "        else:\n",
    "            strategy = \"HIGH UNCERTAINTY: Conservative ordering + agile replenishment\"\n",
    "            risk_level = \"High\"\n",
    "        \n",
    "        recommendations.append({\n",
    "            'category': 'Overall Strategy',\n",
    "            'recommendation': strategy,\n",
    "            'risk_level': risk_level\n",
    "        })\n",
    "        \n",
    "        # 2. Safety stock guidance\n",
    "        safety_stock_pct = (impact['safety_stock'] / impact['annual_forecast']) * 100\n",
    "        \n",
    "        if safety_stock_pct < 10:\n",
    "            safety_rec = f\"Maintain {impact['safety_stock']:,.0f} units (~{safety_stock_pct:.1f}% buffer)\"\n",
    "        elif safety_stock_pct < 20:\n",
    "            safety_rec = f\"Carry {impact['safety_stock']:,.0f} units ({safety_stock_pct:.1f}% buffer) - standard for this uncertainty\"\n",
    "        else:\n",
    "            safety_rec = f\"High buffer needed ({impact['safety_stock']:,.0f} units, {safety_stock_pct:.1f}%) - consider demand-driven replenishment\"\n",
    "        \n",
    "        recommendations.append({\n",
    "            'category': 'Safety Stock',\n",
    "            'recommendation': safety_rec,\n",
    "            'risk_level': 'High' if safety_stock_pct > 20 else 'Moderate'\n",
    "        })\n",
    "        \n",
    "        # 3. Risk asymmetry guidance\n",
    "        if impact['risk_asymmetry'] > 0.2:\n",
    "            asym_rec = \"Higher stockout risk - bias ordering upward or improve lead times\"\n",
    "            asym_risk = \"High\"\n",
    "        elif impact['risk_asymmetry'] < -0.2:\n",
    "            asym_rec = \"Higher overstock risk - conservative ordering or flexible inventory\"\n",
    "            asym_risk = \"High\"\n",
    "        else:\n",
    "            asym_rec = \"Balanced risk profile - standard procurement approach\"\n",
    "            asym_risk = \"Low\"\n",
    "        \n",
    "        recommendations.append({\n",
    "            'category': 'Risk Profile',\n",
    "            'recommendation': asym_rec,\n",
    "            'risk_level': asym_risk\n",
    "        })\n",
    "        \n",
    "        # 4. Model confidence guidance\n",
    "        if impact['mape'] < 15:\n",
    "            model_rec = f\"High forecast confidence ({impact['model']}, {impact['mape']:.1f}% MAPE) - trust the forecast\"\n",
    "        elif impact['mape'] < 25:\n",
    "            model_rec = f\"Moderate confidence ({impact['model']}, {impact['mape']:.1f}% MAPE) - monitor actuals closely\"\n",
    "        else:\n",
    "            model_rec = f\"Lower confidence ({impact['model']}, {impact['mape']:.1f}% MAPE) - frequent forecast updates recommended\"\n",
    "        \n",
    "        recommendations.append({\n",
    "            'category': 'Forecast Confidence',\n",
    "            'recommendation': model_rec,\n",
    "            'risk_level': 'High' if impact['mape'] > 25 else 'Low'\n",
    "        })\n",
    "        \n",
    "        # 5. Peak period guidance\n",
    "        monthly = self.monthly_breakdown[brand]\n",
    "        peak_month = monthly.loc[monthly['forecast'].idxmax()]\n",
    "        \n",
    "        peak_rec = f\"Peak demand: {peak_month['month'].strftime('%B %Y')} ({peak_month['forecast']:,.0f} units, ¬±{peak_month['total_uncertainty']:,.0f})\"\n",
    "        \n",
    "        recommendations.append({\n",
    "            'category': 'Peak Planning',\n",
    "            'recommendation': peak_rec,\n",
    "            'risk_level': 'High' if peak_month['uncertainty_pct'] > 30 else 'Moderate'\n",
    "        })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _print_brand_summary(self, brand, impact, recommendations):\n",
    "        \"\"\"\n",
    "        Print formatted summary for a brand\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"\\nüìä 2026 Forecast: {impact['annual_forecast']:>12,.0f} units\")\n",
    "        print(f\"   Range:        {impact['annual_lower']:>12,.0f} - {impact['annual_upper']:>12,.0f} units\")\n",
    "        print(f\"   Model:        {impact['model']:>12s} ({impact['mape']:.1f}% MAPE)\")\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  Risk Analysis:\")\n",
    "        print(f\"   Overstock Risk:  {impact['overstock_risk']:>10,.0f} units (if demand = lower bound)\")\n",
    "        print(f\"   Stockout Risk:   {impact['stockout_risk']:>10,.0f} units (if demand = upper bound)\")\n",
    "        print(f\"   Total Uncertainty: {impact['total_uncertainty']:>8,.0f} units (¬±{impact['uncertainty_pct']:.1f}%)\")\n",
    "        \n",
    "        # Risk interpretation\n",
    "        if impact['uncertainty_pct'] < 20:\n",
    "            risk_status = \"‚úÖ Low uncertainty\"\n",
    "        elif impact['uncertainty_pct'] < 35:\n",
    "            risk_status = \"‚úì Moderate uncertainty\"\n",
    "        else:\n",
    "            risk_status = \"‚ö†Ô∏è  High uncertainty\"\n",
    "        \n",
    "        print(f\"   Status: {risk_status}\")\n",
    "        \n",
    "        print(f\"\\nüí° Recommended Safety Stock: {impact['safety_stock']:,.0f} units\")\n",
    "        print(f\"   (Hedges both overstock and stockout risk)\")\n",
    "        \n",
    "        # Print top 2 recommendations\n",
    "        print(f\"\\nüéØ Key Recommendations:\")\n",
    "        for i, rec in enumerate(recommendations[:2], 1):\n",
    "            print(f\"   {i}. {rec['recommendation']}\")\n",
    "    \n",
    "    def _analyze_portfolio(self):\n",
    "        \"\"\"\n",
    "        Portfolio-level analysis across all brands\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\n\\n\" + \"=\"*70)\n",
    "        print(\"PORTFOLIO-LEVEL ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Aggregate metrics\n",
    "        total_forecast = sum(imp['annual_forecast'] for imp in self.impact_analysis.values())\n",
    "        total_lower = sum(imp['annual_lower'] for imp in self.impact_analysis.values())\n",
    "        total_upper = sum(imp['annual_upper'] for imp in self.impact_analysis.values())\n",
    "        total_safety_stock = sum(imp['safety_stock'] for imp in self.impact_analysis.values())\n",
    "        \n",
    "        total_overstock_risk = sum(imp['overstock_risk'] for imp in self.impact_analysis.values())\n",
    "        total_stockout_risk = sum(imp['stockout_risk'] for imp in self.impact_analysis.values())\n",
    "        \n",
    "        weighted_uncertainty = sum(\n",
    "            imp['uncertainty_pct'] * imp['annual_forecast'] \n",
    "            for imp in self.impact_analysis.values()\n",
    "        ) / total_forecast\n",
    "        \n",
    "        print(f\"\\nüìä Total 2026 Forecast: {total_forecast:,.0f} units\")\n",
    "        print(f\"   Confidence Range:    {total_lower:,.0f} - {total_upper:,.0f} units\")\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  Portfolio Risk:\")\n",
    "        print(f\"   Total Overstock Risk:  {total_overstock_risk:>10,.0f} units\")\n",
    "        print(f\"   Total Stockout Risk:   {total_stockout_risk:>10,.0f} units\")\n",
    "        print(f\"   Weighted Uncertainty:  {weighted_uncertainty:>10.1f}%\")\n",
    "        \n",
    "        print(f\"\\nüí° Recommended Total Safety Stock: {total_safety_stock:,.0f} units\")\n",
    "        print(f\"   ({(total_safety_stock/total_forecast)*100:.1f}% of forecast)\")\n",
    "        \n",
    "        # Brand contribution to risk\n",
    "        print(f\"\\nüéØ Risk Contributors (by absolute uncertainty):\")\n",
    "        brand_risks = sorted(\n",
    "            [(b, imp['total_uncertainty']) for b, imp in self.impact_analysis.items()],\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        for brand, risk in brand_risks:\n",
    "            pct = (risk / (total_upper - total_lower)) * 100\n",
    "            print(f\"   {brand:>10}: {risk:>10,.0f} units ({pct:>5.1f}% of total uncertainty)\")\n",
    "        \n",
    "        # Store portfolio summary\n",
    "        self.impact_analysis['portfolio'] = {\n",
    "            'total_forecast': total_forecast,\n",
    "            'total_lower': total_lower,\n",
    "            'total_upper': total_upper,\n",
    "            'total_overstock_risk': total_overstock_risk,\n",
    "            'total_stockout_risk': total_stockout_risk,\n",
    "            'total_safety_stock': total_safety_stock,\n",
    "            'weighted_uncertainty_pct': weighted_uncertainty\n",
    "        }\n",
    "\n",
    "# ================================================================\n",
    "# EXECUTE ANALYSIS\n",
    "# ================================================================\n",
    "\n",
    "analyzer = BusinessImpactAnalyzer(forecasts_2026, final_model_selection)\n",
    "business_impact = analyzer.analyze_all_brands()\n",
    "\n",
    "# ================================================================\n",
    "# CREATE SUMMARY TABLES FOR STREAMLIT\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING SUMMARY TABLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Table 1: Brand-level summary\n",
    "brand_summary_data = []\n",
    "\n",
    "for brand in BRANDS:\n",
    "    if brand not in business_impact:\n",
    "        continue\n",
    "    \n",
    "    imp = business_impact[brand]\n",
    "    \n",
    "    brand_summary_data.append({\n",
    "        'Brand': brand,\n",
    "        'Forecast': f\"{imp['annual_forecast']:,.0f}\",\n",
    "        'Range': f\"{imp['annual_lower']:,.0f} - {imp['annual_upper']:,.0f}\",\n",
    "        'Overstock Risk': f\"{imp['overstock_risk']:,.0f}\",\n",
    "        'Stockout Risk': f\"{imp['stockout_risk']:,.0f}\",\n",
    "        'Safety Stock': f\"{imp['safety_stock']:,.0f}\",\n",
    "        'Uncertainty': f\"{imp['uncertainty_pct']:.1f}%\",\n",
    "        'Model': imp['model'],\n",
    "        'MAPE': f\"{imp['mape']:.1f}%\"\n",
    "    })\n",
    "\n",
    "df_brand_summary = pd.DataFrame(brand_summary_data)\n",
    "\n",
    "print(\"\\nüìä Brand Summary Table:\")\n",
    "print(df_brand_summary.to_string(index=False))\n",
    "\n",
    "# Table 2: Recommendations summary\n",
    "recommendations_data = []\n",
    "\n",
    "for brand in BRANDS:\n",
    "    if brand not in analyzer.recommendations:\n",
    "        continue\n",
    "    \n",
    "    for rec in analyzer.recommendations[brand]:\n",
    "        recommendations_data.append({\n",
    "            'Brand': brand,\n",
    "            'Category': rec['category'],\n",
    "            'Recommendation': rec['recommendation'],\n",
    "            'Risk Level': rec['risk_level']\n",
    "        })\n",
    "\n",
    "df_recommendations = pd.DataFrame(recommendations_data)\n",
    "\n",
    "# ================================================================\n",
    "# STORE IN CONF FOR STATE FREEZING\n",
    "# ================================================================\n",
    "\n",
    "CONF['BUSINESS_IMPACT'] = {\n",
    "    'brand_analysis': business_impact,\n",
    "    'monthly_breakdown': {brand: df.to_dict('records') \n",
    "                         for brand, df in analyzer.monthly_breakdown.items()},\n",
    "    'recommendations': analyzer.recommendations,\n",
    "    'summary_table': df_brand_summary.to_dict('records'),\n",
    "    'recommendations_table': df_recommendations.to_dict('records')\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ Business impact analysis stored in CONF['BUSINESS_IMPACT']\")\n",
    "\n",
    "# ================================================================\n",
    "# VISUALIZATION: Monthly Risk Profile\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MONTHLY RISK VISUALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "    \n",
    "    # Create figure with subplots for each brand\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, brand in enumerate(BRANDS):\n",
    "        if brand not in analyzer.monthly_breakdown:\n",
    "            continue\n",
    "        \n",
    "        ax = axes[idx]\n",
    "        monthly = analyzer.monthly_breakdown[brand]\n",
    "        \n",
    "        months = range(len(monthly))\n",
    "        \n",
    "        # Plot forecast with uncertainty bands\n",
    "        ax.plot(months, monthly['forecast'], 'b-', linewidth=2, label='Forecast')\n",
    "        ax.fill_between(\n",
    "            months, \n",
    "            monthly['lower_bound'], \n",
    "            monthly['upper_bound'],\n",
    "            alpha=0.3, \n",
    "            color='blue',\n",
    "            label='Confidence Interval'\n",
    "        )\n",
    "        \n",
    "        # Highlight peak months (top 3)\n",
    "        peak_months = monthly.nlargest(3, 'forecast').index\n",
    "        for peak_idx in peak_months:\n",
    "            ax.axvline(x=peak_idx, color='red', linestyle='--', alpha=0.3, linewidth=1)\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_title(f'{brand} - 2026 Monthly Forecast', fontsize=12, weight='bold')\n",
    "        ax.set_xlabel('Month', fontsize=10)\n",
    "        ax.set_ylabel('Units', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(loc='upper left', fontsize=9)\n",
    "        \n",
    "        # Format y-axis\n",
    "        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}K'))\n",
    "        \n",
    "        # Add uncertainty percentage as text\n",
    "        avg_unc = monthly['uncertainty_pct'].mean()\n",
    "        ax.text(0.98, 0.02, f'Avg Uncertainty: ¬±{avg_unc:.1f}%', \n",
    "                transform=ax.transAxes, ha='right', va='bottom',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "                fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('business_impact_monthly_risk.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\n‚úÖ Saved visualization: business_impact_monthly_risk.png\")\n",
    "    plt.close()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è  Matplotlib not available - skipping visualization\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  Visualization error: {e}\")\n",
    "\n",
    "# ================================================================\n",
    "# FINAL SUMMARY\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BUSINESS IMPACT ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'portfolio' in business_impact:\n",
    "    portfolio = business_impact['portfolio']\n",
    "    \n",
    "    print(f\"\\nüìà Portfolio Metrics:\")\n",
    "    print(f\"   Total Forecast: {portfolio['total_forecast']:>14,.0f} units\")\n",
    "    print(f\"   Safety Stock:   {portfolio['total_safety_stock']:>14,.0f} units\")\n",
    "    print(f\"   Uncertainty:    {portfolio['weighted_uncertainty_pct']:>14.1f}%\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  Risk Exposure:\")\n",
    "    print(f\"   Overstock:      {portfolio['total_overstock_risk']:>14,.0f} units\")\n",
    "    print(f\"   Stockout:       {portfolio['total_stockout_risk']:>14,.0f} units\")\n",
    "\n",
    "print(f\"\\n‚úÖ Results stored in:\")\n",
    "print(f\"   - CONF['BUSINESS_IMPACT']: Complete analysis\")\n",
    "print(f\"   - df_brand_summary: Brand-level table\")\n",
    "print(f\"   - df_recommendations: Action items\")\n",
    "print(f\"   - analyzer.monthly_breakdown: Month-by-month data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a66be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Freezing state with dill\n",
    "# ================================================================\n",
    "\n",
    "import dill  # Required for Ensemble models and custom classes\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRODUCTION STATE FREEZING - DILL ENGINE\")\n",
    "print(\"=\"*70)\n",
    "print(\"Supporting 8 models: SARIMAX, XGBoost, LightGBM, CatBoost, GP, Prophet√ó2, Ensemble\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ================================================================\n",
    "# 1. SMART PATH DETECTION\n",
    "# ================================================================\n",
    "\n",
    "try:\n",
    "    if '__file__' in globals():\n",
    "        base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    else:\n",
    "        base_dir = os.getcwd()\n",
    "except:\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "if 'notebooks' in base_dir.lower():\n",
    "    project_root = os.path.dirname(base_dir)\n",
    "else:\n",
    "    project_root = base_dir\n",
    "\n",
    "output_dir = os.path.join(project_root, 'outputs')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output Directory: {output_dir}\")\n",
    "\n",
    "# ================================================================\n",
    "# 2. VALIDATION\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n[1/6] Validating required variables...\")\n",
    "\n",
    "required_vars = [\n",
    "    'df_full_data', \n",
    "    'df_future_2026', \n",
    "    'forecasts_2026', \n",
    "    'final_model_selection', \n",
    "    'production_models',\n",
    "    'production_params'\n",
    "]\n",
    "\n",
    "# Optional but recommended variables\n",
    "optional_vars = {\n",
    "    'production_scalers': 'Scalers for SARIMAX/GP/ML models',\n",
    "    'production_cv_performance': 'Cross-validation performance metrics',\n",
    "    'stat_validation_results': 'Statistical validation results',\n",
    "    'BRAND_START_DATES': 'Brand-specific regime start dates',\n",
    "    'ENHANCED_METRICS': 'Business metrics (bias, directional accuracy)',\n",
    "    'BASELINE_COMPARISON': 'ML vs baseline comparison',\n",
    "    'BASELINE_RESULTS': 'Detailed baseline performance',\n",
    "    'BASELINE_TARGETS': 'Best baseline per brand',\n",
    "    'BUSINESS_IMPACT': 'Unit mismatch and safety stock analysis'\n",
    "}\n",
    "\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "\n",
    "if missing:\n",
    "    print(f\"‚ùå Missing required variables: {', '.join(missing)}\")\n",
    "    print(\"\\nRequired variables:\")\n",
    "    for var in required_vars:\n",
    "        status = \"‚úì\" if var in globals() else \"‚úó\"\n",
    "        print(f\"  {status} {var}\")\n",
    "    raise RuntimeError(\"Run all training and forecasting cells before freezing!\")\n",
    "\n",
    "print(\"‚úì All required variables present\")\n",
    "\n",
    "# Check optional variables\n",
    "missing_optional = []\n",
    "for var, description in optional_vars.items():\n",
    "    # Check both globals and CONF dict\n",
    "    if var not in globals() and (var not in CONF if 'CONF' in globals() else True):\n",
    "        missing_optional.append(f\"{var} ({description})\")\n",
    "        \n",
    "if missing_optional:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing optional variables:\")\n",
    "    for var in missing_optional:\n",
    "        print(f\"  ‚Ä¢ {var}\")\n",
    "    print(\"  App will work but with reduced functionality\")\n",
    "\n",
    "# ================================================================\n",
    "# 3. DATA INTEGRITY CHECKS\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n[2/6] Performing data integrity checks...\")\n",
    "\n",
    "# Check forecast structure\n",
    "brands = ['Apple', 'Samsung', 'Google', 'Motorola']\n",
    "for brand in brands:\n",
    "    if brand not in forecasts_2026:\n",
    "        raise ValueError(f\"Missing forecast for {brand}\")\n",
    "    \n",
    "    forecast = forecasts_2026[brand]\n",
    "    \n",
    "    # Check required keys\n",
    "    required_keys = ['forecast', 'lower_bound', 'upper_bound', 'confidence_intervals']\n",
    "    missing_keys = [k for k in required_keys if k not in forecast]\n",
    "    if missing_keys:\n",
    "        raise ValueError(f\"{brand} forecast missing keys: {missing_keys}\")\n",
    "    \n",
    "    # Check forecast length\n",
    "    if len(forecast['forecast']) != 12:\n",
    "        raise ValueError(f\"{brand} forecast wrong length: {len(forecast['forecast'])} (expected 12)\")\n",
    "    \n",
    "    # Check for NaN values\n",
    "    if np.isnan(forecast['forecast']).any():\n",
    "        raise ValueError(f\"{brand} forecast contains NaN values!\")\n",
    "    \n",
    "    # Check for negative values \n",
    "    if (forecast['forecast'] < 0).any():\n",
    "        print(f\"  ‚ö†Ô∏è  Warning: {brand} has negative forecasts. Clipping to 0.\")\n",
    "        forecast['forecast'] = np.maximum(0, forecast['forecast'])\n",
    "        forecast['lower_bound'] = np.maximum(0, forecast['lower_bound'])\n",
    "\n",
    "print(\"‚úì All forecasts validated\")\n",
    "\n",
    "# Check model selection\n",
    "for brand in brands:\n",
    "    if brand not in final_model_selection:\n",
    "        raise ValueError(f\"Missing model selection for {brand}\")\n",
    "    \n",
    "    selection = final_model_selection[brand]\n",
    "    if 'model' not in selection:\n",
    "        raise ValueError(f\"{brand} selection missing 'model' key\")\n",
    "\n",
    "print(\"‚úì Model selections validated\")\n",
    "\n",
    "# Check models and params match\n",
    "for brand in brands:\n",
    "    if brand not in production_models:\n",
    "        raise ValueError(f\"Missing production model for {brand}\")\n",
    "    if brand not in production_params:\n",
    "        raise ValueError(f\"Missing production params for {brand}\")\n",
    "\n",
    "print(\"‚úì Production models and params validated\")\n",
    "\n",
    "# ================================================================\n",
    "# Validate Ensemble models have proper structure\n",
    "# ================================================================\n",
    "\n",
    "ensemble_brands = [b for b in brands if final_model_selection[b]['model'] == 'Ensemble']\n",
    "if ensemble_brands:\n",
    "    print(f\"\\n[Ensemble Validation] Checking {len(ensemble_brands)} ensemble model(s)...\")\n",
    "    \n",
    "    for brand in ensemble_brands:\n",
    "        model_data = production_models[brand]\n",
    "        \n",
    "        # Validate structure\n",
    "        if not isinstance(model_data, dict):\n",
    "            raise TypeError(f\"Ensemble model for {brand} must be dict, got {type(model_data)}\")\n",
    "        \n",
    "        if model_data.get('type') != 'ensemble':\n",
    "            raise ValueError(f\"Model for {brand} claims to be Ensemble but type is '{model_data.get('type')}'\")\n",
    "        \n",
    "        if 'weights' not in model_data:\n",
    "            raise ValueError(\n",
    "                f\"‚ùå CRITICAL: Ensemble model for {brand} missing 'weights' key!\\n\"\n",
    "                f\"   This means Final Training cell failed to load weights from Model Training Cell.\\n\"\n",
    "                f\"   Action: Re-run previsous cells.\"\n",
    "            )\n",
    "        \n",
    "        if 'base_models' not in model_data:\n",
    "            raise ValueError(\n",
    "                f\"‚ùå CRITICAL: Ensemble model for {brand} missing 'base_models' key!\\n\"\n",
    "                f\"   This means Final Training cell failed to train base models.\\n\"\n",
    "                f\"   Action: Re-run Final Training cell with proper ensemble training.\"\n",
    "            )\n",
    "        \n",
    "        weights = model_data['weights']\n",
    "        base_models = model_data['base_models']\n",
    "        \n",
    "        # Validate weights structure\n",
    "        if not isinstance(weights, dict):\n",
    "            raise TypeError(f\"Ensemble weights for {brand} must be dict, got {type(weights)}\")\n",
    "        \n",
    "        if len(weights) == 0:\n",
    "            raise ValueError(f\"Ensemble weights for {brand} are empty\")\n",
    "        \n",
    "        # Validate weights sum to ~1.0\n",
    "        weight_sum = sum(weights.values())\n",
    "        if not (0.99 <= weight_sum <= 1.01):\n",
    "            raise ValueError(\n",
    "                f\"Ensemble weights for {brand} sum to {weight_sum:.4f}, expected ~1.0\\n\"\n",
    "                f\"   Weights: {weights}\\n\"\n",
    "                f\"   This indicates corrupted ensemble optimization in Training Cell.\"\n",
    "            )\n",
    "        \n",
    "        # Validate all weights are positive\n",
    "        negative_weights = {k: v for k, v in weights.items() if v < 0}\n",
    "        if negative_weights:\n",
    "            raise ValueError(f\"Ensemble for {brand} has negative weights: {negative_weights}\")\n",
    "        \n",
    "        # Validate base models exist\n",
    "        active_models = [m for m, w in weights.items() if w > 0]\n",
    "        missing_base = [m for m in active_models if m not in base_models]\n",
    "        if missing_base:\n",
    "            raise ValueError(\n",
    "                f\"Ensemble for {brand} references base models not in base_models dict: {missing_base}\"\n",
    "            )\n",
    "        \n",
    "        print(f\"  ‚úì {brand}: {len(active_models)} active base models, weights sum to {weight_sum:.4f}\")\n",
    "        for model, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):\n",
    "            if weight > 0:\n",
    "                print(f\"      {model}: {weight:.4f}\")\n",
    "\n",
    "    print(f\"‚úì All ensemble models validated\")\n",
    "\n",
    "# ================================================================\n",
    "# CRITICAL: Validate scalers for models that require them\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n[Scaler Validation]\")\n",
    "\n",
    "if 'production_scalers' not in globals():\n",
    "    print(\"  ‚ö†Ô∏è  WARNING: production_scalers not found in globals\")\n",
    "    print(\"     SARIMAX/GP/ML models may fail during inference\")\n",
    "    print(\"     Action: Re-run Final Training cell to generate scalers\")\n",
    "    production_scalers = {}  # Create empty dict to avoid crashes\n",
    "else:\n",
    "    print(\"  ‚úì production_scalers found\")\n",
    "    \n",
    "    # Check specific model requirements\n",
    "    for brand in brands:\n",
    "        model_type = final_model_selection[brand]['model']\n",
    "        \n",
    "        # SARIMAX requires scaler if it has exog variables\n",
    "        if model_type == 'SARIMAX':\n",
    "            params = production_params[brand]\n",
    "            if params.get('exog_cols'):\n",
    "                if brand not in production_scalers or production_scalers[brand] is None:\n",
    "                    print(f\"  ‚ö†Ô∏è  {brand}: SARIMAX has exog vars but scaler missing\")\n",
    "                else:\n",
    "                    print(f\"  ‚úì {brand}: SARIMAX scaler present\")\n",
    "        \n",
    "        # GP requires both X and y scalers\n",
    "        elif model_type == 'GP':\n",
    "            if brand not in production_scalers:\n",
    "                print(f\"  ‚ö†Ô∏è  {brand}: GP model missing scalers\")\n",
    "            elif not isinstance(production_scalers[brand], dict):\n",
    "                print(f\"  ‚ö†Ô∏è  {brand}: GP scaler malformed (expected dict)\")\n",
    "            elif 'X_scaler' not in production_scalers[brand] or 'y_scaler' not in production_scalers[brand]:\n",
    "                print(f\"  ‚ö†Ô∏è  {brand}: GP scaler incomplete (missing X_scaler or y_scaler)\")\n",
    "            else:\n",
    "                print(f\"  ‚úì {brand}: GP scalers present (X and y)\")\n",
    "        \n",
    "        # Tree models should have scalers\n",
    "        elif model_type in ['XGBoost', 'LightGBM', 'CatBoost']:\n",
    "            if brand not in production_scalers:\n",
    "                print(f\"  ‚ö†Ô∏è  {brand}: {model_type} missing scaler (inference may be suboptimal)\")\n",
    "            else:\n",
    "                print(f\"  ‚úì {brand}: {model_type} scaler present\")\n",
    "        \n",
    "        # Ensemble requires base model scalers\n",
    "        elif model_type == 'Ensemble':\n",
    "            # Check if base models have scalers (if they need them)\n",
    "            if brand not in production_scalers or not isinstance(production_scalers[brand], dict):\n",
    "                print(f\"  ‚ö†Ô∏è  {brand}: Ensemble may be missing base model scalers\")\n",
    "            else:\n",
    "                print(f\"  ‚úì {brand}: Ensemble base model scalers present\")\n",
    "\n",
    "# ================================================================\n",
    "# 4. PACKAGE CORE DATA \n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n[3/6] Packaging core data...\")\n",
    "\n",
    "# Calculate market statistics\n",
    "total_market_2026 = sum(forecasts_2026[b]['forecast'].sum() for b in brands)\n",
    "brand_totals = {b: forecasts_2026[b]['forecast'].sum() for b in brands}\n",
    "brand_shares = {b: (total / total_market_2026 * 100) for b, total in brand_totals.items()}\n",
    "\n",
    "# Core data with DEEP COPY of all arrays\n",
    "core_data = {\n",
    "    'df_historical': df_full_data.copy(),\n",
    "    'df_future_baseline': df_future_2026.copy(),\n",
    "    \n",
    "    # CRITICAL: Deep copy all numpy arrays to prevent mutation\n",
    "    'forecasts_baseline': {\n",
    "        brand: {\n",
    "            'forecast': forecasts_2026[brand]['forecast'].copy(),\n",
    "            'lower_bound': forecasts_2026[brand]['lower_bound'].copy(),\n",
    "            'upper_bound': forecasts_2026[brand]['upper_bound'].copy(),\n",
    "            'confidence_intervals': forecasts_2026[brand]['confidence_intervals']\n",
    "        }\n",
    "        for brand in brands\n",
    "    },\n",
    "    \n",
    "    'model_selection': final_model_selection.copy(),\n",
    "    \n",
    "    # Comprehensive metadata for debugging and validation\n",
    "    'metadata': {\n",
    "        'generated': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'python_version': sys.version,\n",
    "        'forecast_period': f\"{df_future_2026['month'].min().date()} to {df_future_2026['month'].max().date()}\",\n",
    "        'historical_period': f\"{df_full_data['month'].min().date()} to {df_full_data['month'].max().date()}\",\n",
    "        'total_market_2026': total_market_2026,\n",
    "        'brand_totals_2026': brand_totals,\n",
    "        'brand_market_shares_2026': brand_shares,\n",
    "        'models_used': {b: final_model_selection[b]['model'] for b in brands},\n",
    "        'data_points': {\n",
    "            'historical_months': len(df_full_data),\n",
    "            'forecast_months': len(df_future_2026)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ================================================================\n",
    "# Add enhanced metrics and baseline comparison\n",
    "# ================================================================\n",
    "\n",
    "# 1. Enhanced metrics (bias, directional accuracy, etc.)\n",
    "if 'CONF' in globals() and 'ENHANCED_METRICS' in CONF:\n",
    "    core_data['enhanced_metrics'] = CONF['ENHANCED_METRICS']\n",
    "    print(\"  ‚úì Added enhanced_metrics (bias, directional accuracy, Q4, launch)\")\n",
    "else:\n",
    "    enhanced = globals().get('ENHANCED_METRICS')\n",
    "    if enhanced is not None:\n",
    "        core_data['enhanced_metrics'] = enhanced\n",
    "        print(\"  ‚úì Added enhanced_metrics (bias, directional accuracy, Q4, launch)\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  enhanced_metrics not found - skipping\")\n",
    "\n",
    "# 2. Baseline comparison results\n",
    "if 'CONF' in globals() and 'BASELINE_COMPARISON' in CONF:\n",
    "    core_data['baseline_comparison'] = CONF['BASELINE_COMPARISON']\n",
    "    print(\"  ‚úì Added baseline_comparison (ML vs SPLY/MA)\")\n",
    "else:\n",
    "    baseline_comp = globals().get('BASELINE_COMPARISON')\n",
    "    if baseline_comp is not None:\n",
    "        core_data['baseline_comparison'] = baseline_comp\n",
    "        print(\"  ‚úì Added baseline_comparison (ML vs SPLY/MA)\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  baseline_comparison not found - skipping\")\n",
    "\n",
    "# 3. Baseline targets (best baseline per brand)\n",
    "if 'CONF' in globals() and 'BASELINE_TARGETS' in CONF:\n",
    "    core_data['baseline_targets'] = CONF['BASELINE_TARGETS']\n",
    "    print(\"  ‚úì Added baseline_targets (best baseline per brand)\")\n",
    "else:\n",
    "    baseline_targ = globals().get('BASELINE_TARGETS')\n",
    "    if baseline_targ is not None:\n",
    "        core_data['baseline_targets'] = baseline_targ\n",
    "        print(\"  ‚úì Added baseline_targets (best baseline per brand)\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  baseline_targets not found - skipping\")\n",
    "\n",
    "# 4. Baseline results (detailed metrics for all methods)\n",
    "if 'CONF' in globals() and 'BASELINE_RESULTS' in CONF:\n",
    "    core_data['baseline_results'] = CONF['BASELINE_RESULTS']\n",
    "    print(\"  ‚úì Added baseline_results (full baseline evaluation)\")\n",
    "else:\n",
    "    baseline_res = globals().get('BASELINE_RESULTS')\n",
    "    if baseline_res is not None:\n",
    "        core_data['baseline_results'] = baseline_res\n",
    "        print(\"  ‚úì Added baseline_results (full baseline evaluation)\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  baseline_results not found - skipping\")\n",
    "\n",
    "# 5. Business impact analysis\n",
    "if 'CONF' in globals() and 'BUSINESS_IMPACT' in CONF:\n",
    "    core_data['business_impact'] = CONF['BUSINESS_IMPACT']\n",
    "    print(\"  ‚úì Added business_impact (overstock/stockout risk, safety stock)\")\n",
    "else:\n",
    "    business_imp = globals().get('BUSINESS_IMPACT')\n",
    "    if business_imp is not None:\n",
    "        core_data['business_impact'] = business_imp\n",
    "        print(\"  ‚úì Added business_impact (overstock/stockout risk, safety stock)\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  business_impact not found - skipping\")\n",
    "\n",
    "# 6. Test data for reference (optional but useful)\n",
    "if 'df_test' in globals():\n",
    "    core_data['df_test'] = df_test.copy()\n",
    "    print(\"  ‚úì Added df_test (for verification)\")\n",
    "\n",
    "print(\"‚úì Core data packaged\")\n",
    "print(f\"  ‚Ä¢ Historical: {len(df_full_data)} months\")\n",
    "print(f\"  ‚Ä¢ Forecast: {len(df_future_2026)} months\")\n",
    "print(f\"  ‚Ä¢ Total 2026: {total_market_2026:,.0f} units\")\n",
    "\n",
    "# ================================================================\n",
    "# 5. PACKAGE MODELS AND PARAMS (DILL)\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n[4/6] Packaging models and parameters...\")\n",
    "\n",
    "# Models package (Dill will handle custom classes, Prophet, GP, etc.)\n",
    "models_data = {\n",
    "    'production_models': production_models,\n",
    "    'production_params': production_params,\n",
    "    'production_scalers': production_scalers  \n",
    "}\n",
    "\n",
    "# Add CV performance if available\n",
    "if 'production_cv_performance' in globals():\n",
    "    models_data['production_cv_performance'] = production_cv_performance\n",
    "    print(\"  ‚úì Included CV performance metrics\")\n",
    "\n",
    "print(\"‚úì Models and params packaged\")\n",
    "\n",
    "# ================================================================\n",
    "# 6. PACKAGE FEATURE CONFIGURATION\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n[5/6] Packaging feature configuration...\")\n",
    "\n",
    "# Ensure BRAND_START_DATES exists \n",
    "if 'BRAND_START_DATES' not in globals():\n",
    "    print(\"  ‚ö†Ô∏è  BRAND_START_DATES not found in globals. Using defaults.\")\n",
    "    BRAND_START_DATES = {\n",
    "        'Apple': '2011-01-01',\n",
    "        'Samsung': '2011-01-01',\n",
    "        'Google': '2016-10-01',   # Pixel Era\n",
    "        'Motorola': '2014-01-01'  # Lenovo Era\n",
    "    }\n",
    "\n",
    "# Enhanced feature config with validation data\n",
    "feature_config = {\n",
    "    'brands': brands,\n",
    "    \n",
    "    # Save regime cut dates for the app\n",
    "    'brand_start_dates': BRAND_START_DATES,\n",
    "    \n",
    "    # Historical launch months \n",
    "    'launch_defaults': {\n",
    "        'Apple': [9, 3],      # Sept (main), March (secondary)\n",
    "        'Samsung': [2, 7],    # Feb (S-series), Jul (Z-series)\n",
    "        'Google': [8, 2],     # Aug (Pixel flagship), Feb (Pixel 'a')\n",
    "        'Motorola': [1, 7]    # Jan (budget wave), Jul (Razr)\n",
    "    },\n",
    "    \n",
    "    # Feature columns used \n",
    "    'feature_types': {\n",
    "        'temporal': ['month_num', 'quarter', 'year', 'time_index'],\n",
    "        'seasonal': ['is_holiday_season', 'is_back_to_school', 'is_black_friday'],\n",
    "        'economic': ['cpi_index'],\n",
    "        'brand_specific': ['launch_{brand}', '{brand}_lag1', '{brand}_lag12', '{brand}_ma3', '{brand}_ma12']\n",
    "    },\n",
    "    \n",
    "    # Statistical validation results if available\n",
    "    'validation_stats': stat_validation_results if 'stat_validation_results' in globals() else None\n",
    "}\n",
    "\n",
    "print(\"‚úì Feature configuration packaged\")\n",
    "print(f\"  ‚Ä¢ Regime dates: {BRAND_START_DATES}\")\n",
    "\n",
    "# ================================================================\n",
    "# 7. SAVE WITH DILL\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n[6/6] Saving files with dill...\")\n",
    "\n",
    "# Save core data\n",
    "core_data_path = os.path.join(output_dir, 'app_core_data.pkl')\n",
    "try:\n",
    "    with open(core_data_path, 'wb') as f:\n",
    "        dill.dump(core_data, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "    file_size = os.path.getsize(core_data_path) / (1024 * 1024)\n",
    "    print(f\"  ‚úì app_core_data.pkl ({file_size:.1f} MB)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚úó Failed to save core data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Save models and params\n",
    "models_path = os.path.join(output_dir, 'app_models.pkl')\n",
    "try:\n",
    "    with open(models_path, 'wb') as f:\n",
    "        dill.dump(models_data, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "    file_size = os.path.getsize(models_path) / (1024 * 1024)\n",
    "    print(f\"  ‚úì app_models.pkl ({file_size:.1f} MB)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚úó Failed to save models: {e}\")\n",
    "    raise\n",
    "\n",
    "# Save feature config\n",
    "config_path = os.path.join(output_dir, 'app_feature_config.pkl')\n",
    "try:\n",
    "    with open(config_path, 'wb') as f:\n",
    "        dill.dump(feature_config, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "    file_size = os.path.getsize(config_path) / (1024 * 1024)\n",
    "    print(f\"  ‚úì app_feature_config.pkl ({file_size:.1f} MB)\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚úó Failed to save feature config: {e}\")\n",
    "    raise\n",
    "\n",
    "# ================================================================\n",
    "# 8. COPY UTILS.PY \n",
    "# ================================================================\n",
    "\n",
    "print(\"\\nCopying utils.py...\")\n",
    "\n",
    "utils_paths = [\n",
    "    os.path.join(base_dir, 'utils.py'),\n",
    "    os.path.join(project_root, 'utils.py'),\n",
    "    'utils.py'\n",
    "]\n",
    "\n",
    "utils_found = False\n",
    "for path in utils_paths:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            shutil.copy(path, os.path.join(output_dir, 'utils.py'))\n",
    "            print(f\"  ‚úì Copied from: {path}\")\n",
    "            utils_found = True\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Failed to copy from {path}: {e}\")\n",
    "\n",
    "if not utils_found:\n",
    "    print(\"  ‚ÑπÔ∏è  utils.py not found (optional - app may not need it)\")\n",
    "\n",
    "# ================================================================\n",
    "# 9. COMPREHENSIVE VERIFICATION\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICATION & INTEGRITY CHECKS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "verification_passed = True\n",
    "\n",
    "# Test 1: Load core data\n",
    "print(\"\\n[Test 1/5] Loading core data...\")\n",
    "try:\n",
    "    with open(core_data_path, 'rb') as f:\n",
    "        test_core = dill.load(f)\n",
    "    print(\"  ‚úì Core data loads successfully\")\n",
    "    \n",
    "    # Check structure\n",
    "    required_keys = ['df_historical', 'df_future_baseline', 'forecasts_baseline', 'model_selection', 'metadata']\n",
    "    missing_keys = [k for k in required_keys if k not in test_core]\n",
    "    if missing_keys:\n",
    "        print(f\"  ‚úó Missing keys: {missing_keys}\")\n",
    "        verification_passed = False\n",
    "    else:\n",
    "        print(\"  ‚úì All required keys present\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  ‚úó Failed to load core data: {e}\")\n",
    "    verification_passed = False\n",
    "\n",
    "# Test 2: Load models\n",
    "print(\"\\n[Test 2/5] Loading models...\")\n",
    "try:\n",
    "    with open(models_path, 'rb') as f:\n",
    "        test_models = dill.load(f)\n",
    "    print(\"  ‚úì Models load successfully\")\n",
    "    \n",
    "    # Check all brands have models\n",
    "    for brand in brands:\n",
    "        if brand not in test_models['production_models']:\n",
    "            print(f\"  ‚úó Missing model for {brand}\")\n",
    "            verification_passed = False\n",
    "        if brand not in test_models['production_params']:\n",
    "            print(f\"  ‚úó Missing params for {brand}\")\n",
    "            verification_passed = False\n",
    "    \n",
    "    if verification_passed:\n",
    "        print(\"  ‚úì All brand models and params present\")\n",
    "    \n",
    "    # Verify scalers included (even if empty)\n",
    "    if 'production_scalers' not in test_models:\n",
    "        print(f\"  ‚úó production_scalers key missing from models file\")\n",
    "        verification_passed = False\n",
    "    else:\n",
    "        print(f\"  ‚úì production_scalers key present\")\n",
    "    \n",
    "    # CRITICAL: Verify ensemble models\n",
    "    ensemble_brands = [b for b in brands if final_model_selection[b]['model'] == 'Ensemble']\n",
    "    if ensemble_brands:\n",
    "        for brand in ensemble_brands:\n",
    "            model_data = test_models['production_models'][brand]\n",
    "            \n",
    "            if 'weights' not in model_data:\n",
    "                print(f\"  ‚úó Ensemble for {brand} missing weights\")\n",
    "                verification_passed = False\n",
    "            elif 'base_models' not in model_data:\n",
    "                print(f\"  ‚úó Ensemble for {brand} missing base_models\")\n",
    "                verification_passed = False\n",
    "            else:\n",
    "                weights = model_data['weights']\n",
    "                weight_sum = sum(weights.values())\n",
    "                if not (0.99 <= weight_sum <= 1.01):\n",
    "                    print(f\"  ‚úó Ensemble weights for {brand} sum to {weight_sum:.4f}\")\n",
    "                    verification_passed = False\n",
    "        \n",
    "        if verification_passed and ensemble_brands:\n",
    "            print(f\"  ‚úì Ensemble models validated: {ensemble_brands}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  ‚úó Failed to load models: {e}\")\n",
    "    verification_passed = False\n",
    "\n",
    "# Test 3: Load feature config\n",
    "print(\"\\n[Test 3/5] Loading feature config...\")\n",
    "try:\n",
    "    with open(config_path, 'rb') as f:\n",
    "        test_config = dill.load(f)\n",
    "    print(\"  ‚úì Feature config loads successfully\")\n",
    "    \n",
    "    # CRITICAL: Verify brand_start_dates\n",
    "    if 'brand_start_dates' not in test_config:\n",
    "        print(\"  ‚úó CRITICAL: brand_start_dates missing!\")\n",
    "        verification_passed = False\n",
    "    else:\n",
    "        print(\"  ‚úì brand_start_dates present\")\n",
    "        for brand, start_date in test_config['brand_start_dates'].items():\n",
    "            print(f\"      {brand}: {start_date}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  ‚úó Failed to load feature config: {e}\")\n",
    "    verification_passed = False\n",
    "\n",
    "# Test 4: Forecast data integrity\n",
    "print(\"\\n[Test 4/5] Verifying forecast data integrity...\")\n",
    "try:\n",
    "    for brand in brands:\n",
    "        forecast = test_core['forecasts_baseline'][brand]['forecast']\n",
    "        \n",
    "        # Check length\n",
    "        if len(forecast) != 12:\n",
    "            print(f\"  ‚úó {brand}: Wrong length ({len(forecast)} != 12)\")\n",
    "            verification_passed = False\n",
    "            continue\n",
    "        \n",
    "        # Check for NaN\n",
    "        if np.isnan(forecast).any():\n",
    "            print(f\"  ‚úó {brand}: Contains NaN values\")\n",
    "            verification_passed = False\n",
    "            continue\n",
    "        \n",
    "        # Check for negative values\n",
    "        if (forecast < 0).any():\n",
    "            print(f\"  ‚úó {brand}: Contains negative values\")\n",
    "            verification_passed = False\n",
    "            continue\n",
    "        \n",
    "        # Check bounds consistency\n",
    "        lower = test_core['forecasts_baseline'][brand]['lower_bound']\n",
    "        upper = test_core['forecasts_baseline'][brand]['upper_bound']\n",
    "        \n",
    "        if not (lower <= forecast).all():\n",
    "            print(f\"  ‚ö†Ô∏è  {brand}: Forecast below lower bound (may be OK)\")\n",
    "        \n",
    "        if not (forecast <= upper).all():\n",
    "            print(f\"  ‚ö†Ô∏è  {brand}: Forecast above upper bound (may be OK)\")\n",
    "    \n",
    "    if verification_passed:\n",
    "        print(\"  ‚úì All forecasts pass integrity checks\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  ‚úó Forecast verification failed: {e}\")\n",
    "    verification_passed = False\n",
    "\n",
    "# Test 5: NEW - Enhanced metrics verification\n",
    "print(\"\\n[Test 5/5] Verifying enhanced metrics...\")\n",
    "try:\n",
    "    if 'enhanced_metrics' in test_core:\n",
    "        print(f\"  ‚úì Enhanced metrics loaded: {len(test_core['enhanced_metrics'])} brands\")\n",
    "        \n",
    "        # Quick sanity check\n",
    "        for brand, metrics in test_core['enhanced_metrics'].items():\n",
    "            required_keys = ['mape', 'bias', 'directional_accuracy']\n",
    "            missing = [k for k in required_keys if k not in metrics]\n",
    "            if missing:\n",
    "                print(f\"  ‚ö†Ô∏è  {brand} missing keys: {missing}\")\n",
    "            else:\n",
    "                print(f\"  ‚úì {brand}: MAPE={metrics['mape']:.1f}%, Bias={metrics['bias']:+.1f}%, DirAcc={metrics['directional_accuracy']*100:.1f}%\")\n",
    "    else:\n",
    "        print(\"  ‚ÑπÔ∏è  Enhanced metrics not found in core_data\")\n",
    "        \n",
    "    if 'baseline_comparison' in test_core:\n",
    "        print(f\"  ‚úì Baseline comparison loaded: {len(test_core['baseline_comparison'])} entries\")\n",
    "        \n",
    "        # Show improvement summary\n",
    "        for brand, comp in test_core['baseline_comparison'].items():\n",
    "            if brand == 'overall':\n",
    "                continue\n",
    "            improvement = comp.get('improvement_pct', 0)\n",
    "            verdict = comp.get('verdict', 'Unknown')\n",
    "            print(f\"  ‚úì {brand}: {improvement:+.1f}% improvement ({verdict})\")\n",
    "    else:\n",
    "        print(\"  ‚ÑπÔ∏è  Baseline comparison not found in core_data (optional)\")\n",
    "    \n",
    "    if 'business_impact' in test_core:\n",
    "        print(f\"  ‚úì Business impact analysis loaded\")\n",
    "        \n",
    "        # Show portfolio summary if available\n",
    "        if 'brand_analysis' in test_core['business_impact']:\n",
    "            if 'portfolio' in test_core['business_impact']['brand_analysis']:\n",
    "                portfolio = test_core['business_impact']['brand_analysis']['portfolio']\n",
    "                print(f\"      Portfolio forecast: {portfolio['total_forecast']:,.0f} units\")\n",
    "                print(f\"      Safety stock: {portfolio['total_safety_stock']:,.0f} units\")\n",
    "    else:\n",
    "        print(\"  ‚ÑπÔ∏è  Business impact not found in core_data (optional)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö†Ô∏è  Enhanced metrics verification warning: {e}\")\n",
    "\n",
    "# ================================================================\n",
    "# 10. GENERATE SUMMARY REPORT\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FREEZE SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# File inventory\n",
    "print(\"\\nFiles Created:\")\n",
    "for filename in ['app_core_data.pkl', 'app_models.pkl', 'app_feature_config.pkl']:\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath) / (1024 * 1024)\n",
    "        print(f\"  ‚úì {filename} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ‚úó {filename} (MISSING)\")\n",
    "\n",
    "if utils_found:\n",
    "    print(f\"  ‚úì utils.py\")\n",
    "else:\n",
    "    print(f\"  ‚ÑπÔ∏è  utils.py (not found)\")\n",
    "\n",
    "# Data summary\n",
    "print(\"\\nData Summary:\")\n",
    "print(f\"  ‚Ä¢ Historical: {len(df_full_data)} months ({df_full_data['month'].min().date()} to {df_full_data['month'].max().date()})\")\n",
    "print(f\"  ‚Ä¢ Forecast: {len(df_future_2026)} months ({df_future_2026['month'].min().date()} to {df_future_2026['month'].max().date()})\")\n",
    "print(f\"  ‚Ä¢ Total 2026: {total_market_2026:,.0f} units\")\n",
    "\n",
    "# Model summary\n",
    "print(\"\\nModels by Brand:\")\n",
    "for brand in brands:\n",
    "    model = final_model_selection[brand]['model']\n",
    "    total = brand_totals[brand]\n",
    "    share = brand_shares[brand]\n",
    "    mape = final_model_selection[brand].get('holdout_mape', 'N/A')\n",
    "    print(f\"  ‚Ä¢ {brand:10s}: {model:15s} | {total:>9,.0f} units ({share:>5.1f}%) | MAPE: {mape}\")\n",
    "\n",
    "# NEW: Enhanced metrics summary\n",
    "if 'enhanced_metrics' in core_data:\n",
    "    print(\"\\nEnhanced Metrics Included:\")\n",
    "    print(\"  ‚úì Bias detection (over/underforecasting)\")\n",
    "    print(\"  ‚úì Directional accuracy (growth/decline calls)\")\n",
    "    print(\"  ‚úì Seasonal error (Q4 vs overall)\")\n",
    "    print(\"  ‚úì Launch month error (new product spikes)\")\n",
    "\n",
    "if 'baseline_comparison' in core_data:\n",
    "    print(\"\\nBaseline Comparison Included:\")\n",
    "    print(\"  ‚úì ML vs SPLY comparison\")\n",
    "    print(\"  ‚úì ML vs Moving Average comparison\")\n",
    "    print(\"  ‚úì Improvement percentages\")\n",
    "\n",
    "if 'business_impact' in core_data:\n",
    "    print(\"\\nBusiness Impact Analysis Included:\")\n",
    "    print(\"  ‚úì Overstock/Stockout risk calculations\")\n",
    "    print(\"  ‚úì Safety stock recommendations\")\n",
    "    print(\"  ‚úì Monthly breakdown of risks\")\n",
    "    print(\"  ‚úì Operational guidance\")\n",
    "\n",
    "# Verification status\n",
    "print(\"\\nVerification Status:\")\n",
    "if verification_passed:\n",
    "    print(\"  ‚úÖ ALL CHECKS PASSED\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  SOME CHECKS FAILED - Review warnings above\")\n",
    "\n",
    "# ================================================================\n",
    "# 11. CREATE DEPLOYMENT CHECKLIST\n",
    "# ================================================================\n",
    "\n",
    "checklist_path = os.path.join(output_dir, 'DEPLOYMENT_CHECKLIST.txt')\n",
    "try:\n",
    "    with open(checklist_path, 'w') as f:\n",
    "        f.write(\"=\"*70 + \"\\n\")\n",
    "        f.write(\"DEPLOYMENT CHECKLIST\\n\")\n",
    "        f.write(\"=\"*70 + \"\\n\\n\")\n",
    "        f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Required Files:\\n\")\n",
    "        f.write(f\"  {'‚úì' if os.path.exists(core_data_path) else '‚úó'} app_core_data.pkl\\n\")\n",
    "        f.write(f\"  {'‚úì' if os.path.exists(models_path) else '‚úó'} app_models.pkl\\n\")\n",
    "        f.write(f\"  {'‚úì' if os.path.exists(config_path) else '‚úó'} app_feature_config.pkl\\n\")\n",
    "        f.write(f\"  {'‚úì' if utils_found else '‚ÑπÔ∏è'} utils.py (optional)\\n\\n\")\n",
    "        \n",
    "        f.write(\"Model Coverage:\\n\")\n",
    "        for brand in brands:\n",
    "            model = final_model_selection[brand]['model']\n",
    "            f.write(f\"  ‚úì {brand}: {model}\\n\")\n",
    "        \n",
    "        f.write(\"\\nData Validation:\\n\")\n",
    "        f.write(f\"  {'‚úì' if verification_passed else '‚úó'} All integrity checks passed\\n\")\n",
    "        \n",
    "        f.write(\"\\nEnhanced Features:\\n\")\n",
    "        f.write(f\"  {'‚úì' if 'enhanced_metrics' in core_data else '‚úó'} Enhanced metrics (bias, direction)\\n\")\n",
    "        f.write(f\"  {'‚úì' if 'baseline_comparison' in core_data else '‚úó'} Baseline comparison\\n\")\n",
    "        f.write(f\"  {'‚úì' if 'business_impact' in core_data else '‚úó'} Business impact analysis\\n\")\n",
    "        \n",
    "        f.write(\"\\nDeployment Notes:\\n\")\n",
    "        f.write(\"  1. Copy all .pkl files to Streamlit app directory\\n\")\n",
    "        f.write(\"  2. Ensure app has dill, numpy, pandas installed\\n\")\n",
    "        f.write(\"  3. Test app locally before production deployment\\n\")\n",
    "        f.write(f\"\\nTotal 2026 Forecast: {int(total_market_2026):,} units\\n\")\n",
    "    \n",
    "    print(f\"\\nüìã Deployment checklist: {checklist_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  Could not create checklist: {e}\")\n",
    "\n",
    "# ================================================================\n",
    "# 12. FINAL STATUS\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if verification_passed:\n",
    "    print(\"‚úÖ STATE FREEZING COMPLETE - PRODUCTION READY\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  STATE FREEZING COMPLETE - WITH WARNINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüì¶ Output directory: {output_dir}\")\n",
    "print(f\"üìä Total 2026 forecast: {int(total_market_2026):,} units\")\n",
    "print(f\"üìÖ Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "if verification_passed:\n",
    "    print(\"\\nüöÄ Ready for Streamlit app deployment!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Review warnings before deploying\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Stable)",
   "language": "python",
   "name": "stock_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
